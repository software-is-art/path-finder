{
  "tasks": [
    {
      "id": 1,
      "title": "S-Expression Lexer and Parser Implementation",
      "description": "Implement the lexer and parser for PathFinder LISP's S-expression syntax, adhering to Scheme conventions and case-sensitive identifiers. This forms the foundational input processing layer.",
      "details": "Implement using recursive descent or a parser combinator library. Define tokens for '(', ')', symbols (case-sensitive), numbers (integers, potentially floats later), booleans (#t, #f), strings. The parser should transform a sequence of tokens into an Abstract Syntax Tree (AST) representing S-expressions (nested lists and atoms). Ensure proper handling of comments (e.g., using ';'). AST nodes should include types like `Atom(Symbol)`, `Atom(Number)`, `Atom(String)`, `Atom(Boolean)`, `SExpr(List[ASTNode])`.",
      "testStrategy": "Unit tests with a comprehensive suite of S-expressions: simple atoms, empty list, nested lists, lists with mixed atom types, comments, and edge cases (e.g., mismatched parentheses, invalid tokens). Validate the structure of the generated AST for each test case.",
      "priority": "medium",
      "dependencies": [
        "21"
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Define Token Types and AST Node Structures",
          "description": "Define the core data structures for tokens (e.g., LPAREN, RPAREN, SYMBOL, NUMBER, BOOLEAN, STRING, EOF) and Abstract Syntax Tree (AST) nodes (Atom(Symbol), Atom(Number), Atom(String), Atom(Boolean), SExpr(List[ASTNode])). This establishes the vocabulary for the lexer and parser.",
          "dependencies": [],
          "details": "Create enums or classes for token types, including their potential value payloads (e.g., string value for SYMBOL, numeric value for NUMBER). For AST nodes, define a base class/interface (e.g., `ASTNode`) and specific derived classes for each atom type and for S-expressions. `Atom(Symbol)` should store its string value preserving case. `SExpr` should hold a list of `ASTNode` children.",
          "status": "done",
          "testStrategy": "No direct executable tests for definitions, but these structures will be validated implicitly by tests for lexer and parser. Optionally, create simple instantiation tests to ensure constructors and properties work as expected."
        },
        {
          "id": 2,
          "title": "Implement Lexer: Basic Tokenization (Parentheses, Symbols, Numbers, Booleans)",
          "description": "Implement the lexer to scan an input string and produce a sequence of tokens. This subtask focuses on recognizing parentheses `(` and `)`, case-sensitive symbols (identifiers), integers, and booleans (`#t`, `#f`). Handle whitespace (spaces, tabs, newlines) as delimiters, which should be ignored and not produce tokens.",
          "dependencies": [
            1
          ],
          "details": "The lexer function should take a string as input and return a list of Token objects. Implement using character-by-character scanning or regular expressions. For symbols, ensure they are captured case-sensitively. For numbers, initially support integers. Booleans `#t` and `#f` should be recognized as distinct keywords/tokens. Ensure proper handling of end-of-input (e.g., an EOF token).",
          "status": "done",
          "testStrategy": "Unit test with various input strings: `(add 1 2)`, `#t`, `my-Symbol`, `(  symbol1   #f  123 )`. Verify the correct sequence, type, and value of tokens produced. Test edge cases like empty input, input with only whitespace, and input ending abruptly."
        },
        {
          "id": 3,
          "title": "Extend Lexer: Add String Literal and Comment Handling",
          "description": "Enhance the lexer to correctly tokenize string literals enclosed in double quotes (e.g., `\"hello world\"`), including support for basic escape characters (e.g., `\\\"` for a double quote within the string, `\\\\` for a backslash). Implement logic to identify and ignore single-line comments starting with `;` until the end of the line.",
          "dependencies": [
            2
          ],
          "details": "For string literals, parse content between double quotes. Implement support for `\\\"` and `\\\\` escape sequences. The string token's value should be the unescaped content. For comments, when a `;` is encountered, the lexer should skip all subsequent characters on that line. Comments should not produce any tokens.",
          "status": "done",
          "testStrategy": "Unit test inputs with strings: `(\"a string\")`, `(\"with \\\"quotes\\\" and \\\\backslash\\\\\")`. Test inputs with comments: `(add 1 2) ; this is a comment`, `; entire line comment`, `(define x \"value\" ; comment after string\n  y 10)`. Verify correct token stream and that comments are ignored."
        },
        {
          "id": 4,
          "title": "Implement Parser: Atomic Expressions and Simple S-Expressions",
          "description": "Develop the initial parser logic to consume tokens produced by the lexer and build an AST. This subtask focuses on parsing atomic expressions (symbols, numbers, booleans, strings) into their corresponding `Atom` AST nodes, and parsing simple, non-nested S-expressions (e.g., `(a b c)`) into `SExpr` AST nodes containing a list of `Atom` nodes.",
          "dependencies": [
            1,
            3
          ],
          "details": "Implement using recursive descent or a parser combinator library. Create a main `parse` function that takes a list of tokens. A helper function, say `parse_expression`, will determine if the next token(s) form an atom or an S-expression. If it's an atom, convert the token to the appropriate `Atom` AST node. If it's an `LPAREN` token, start parsing an S-expression: consume subsequent tokens as atoms until an `RPAREN` is found. Handle errors for unexpected tokens or premature end of input (e.g., missing `RPAREN`).",
          "status": "done",
          "testStrategy": "Unit test with token streams representing: `my-symbol`, `123`, `#t`, `\"a string\"`, `(one two three)`. Verify the generated AST structure is correct (e.g., `Atom(Symbol(\"my-symbol\"))`, `SExpr([Atom(Symbol(\"one\")), Atom(Symbol(\"two\")), Atom(Symbol(\"three\"))])`). Test error handling for mismatched parentheses at this simple level (e.g., `(a b` or `a b)`)."
        },
        {
          "id": 5,
          "title": "Extend Parser: Nested S-Expressions and Full AST Construction",
          "description": "Enhance the parser to handle arbitrarily nested S-expressions (e.g., `(a (b (c)) d)`). This involves making the S-expression parsing rule fully recursive, allowing S-expressions to contain other S-expressions as elements, in addition to atoms. Ensure the AST correctly represents the hierarchical structure.",
          "dependencies": [
            4
          ],
          "details": "Modify the S-expression parsing logic (e.g., within the part that handles `LPAREN`) to recursively call the `parse_expression` function for each element found before the closing `RPAREN`. This `parse_expression` function should now be capable of returning either an `Atom` node or an `SExpr` node. This recursive structure will naturally handle nesting. Ensure proper error handling for malformed nested structures.",
          "status": "done",
          "testStrategy": "Unit test with token streams representing nested S-expressions: `(a (b c) d)`, `((()))`, `(list 1 (quote (a b)) \"str\")`, `()`. Verify the deeply nested AST structure is accurately constructed. Test error handling for complex mismatched parentheses or unexpected tokens within nested structures (e.g., `(a (b c d)`)."
        }
      ]
    },
    {
      "id": 2,
      "title": "Core AST Definition and Basic Evaluation Engine",
      "description": "Define the core Abstract Syntax Tree (AST) structures for all language constructs and implement a basic evaluation engine for simple functional expressions, variable definitions, and lookups within a lexical scope.",
      "details": "AST nodes should cover: literals (numbers, booleans, strings), symbols (variables), function calls `(f arg1 arg2)`, lambda definitions `(lambda (params) body)`, variable definitions `(define x value)`, conditional expressions `(if cond then-expr else-expr)`. Implement an environment model for lexical scoping (e.g., a chain of hash maps). The evaluator will recursively walk the AST. For `(define x value)`, store `value` in the current environment. For symbols, look them up. For `(lambda ...)`, create a closure object capturing the current environment. For function calls, evaluate arguments, extend environment with params, and evaluate body.",
      "testStrategy": "Test evaluation of simple arithmetic and boolean expressions. Test variable definition and lookup in global and local scopes. Test lambda creation and application. Verify correct evaluation of conditional expressions. Test basic error handling for unbound variables.",
      "priority": "medium",
      "dependencies": [
        1
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Define Core AST Node Structures",
          "description": "Implement the data structures for all required Abstract Syntax Tree (AST) nodes: Literals (Number, Boolean, String), Symbol, FunctionCall, Lambda, Define, and If. These structures will represent the parsed code.",
          "dependencies": [],
          "details": "Use classes, structs, or algebraic data types for each AST node. For example: `LiteralNode(value)`, `SymbolNode(name)`, `FunctionCallNode(callee: ASTNode, arguments: List[ASTNode])`, `LambdaNode(params: List[SymbolNode], body: ASTNode)`, `DefineNode(name: SymbolNode, value: ASTNode)`, `IfNode(condition: ASTNode, thenBranch: ASTNode, elseBranch: ASTNode)`. Consider a common base type or interface `ASTNode`.",
          "status": "done",
          "testStrategy": "Unit test each AST node constructor to ensure correct initialization and storage of its components. Verify that node types can be distinguished."
        },
        {
          "id": 2,
          "title": "Implement Environment Model for Lexical Scoping",
          "description": "Create an `Environment` class or structure to manage variable bindings and lexical scopes. It should support defining variables, looking up variable values, and creating nested scopes.",
          "dependencies": [
            1
          ],
          "details": "Implement the environment as a chain of hash maps (dictionaries). Each `Environment` instance should have a local store for bindings and a reference to an optional parent (outer) environment. Key methods: `define(name: String, value: Any)`, `lookup(name: String) -> Any`, `extend() -> Environment`. `lookup` should search the current environment, then delegate to the parent if not found, throwing an error if the variable is undefined.",
          "status": "done",
          "testStrategy": "Unit test `Environment` operations: define a variable and look it up in the same scope. Look up a variable defined in an outer scope from an inner scope. Test extending scopes and ensuring inner scope definitions do not affect outer scopes. Test lookup of an undefined variable."
        },
        {
          "id": 3,
          "title": "Implement Basic Evaluator for Literals, Symbols, and `define`",
          "description": "Develop the initial `evaluate` function that takes an AST node and an environment. Implement evaluation logic for Literal nodes, Symbol lookups, and `(define x value)` expressions.",
          "dependencies": [
            1,
            2
          ],
          "details": "The `evaluate(node: ASTNode, env: Environment)` function will use pattern matching or type checking on the `node` to dispatch to specific evaluation logic. \n- Literals: Return their intrinsic value (e.g., number, boolean, string).\n- Symbols: Use `env.lookup(symbolName)` to retrieve the variable's value.\n- `DefineNode`: Evaluate the `value` sub-expression using `evaluate(defineNode.value, env)`. Then, use `env.define(defineNode.name.name, evaluatedValue)`. The `define` expression could return a special confirmation value or the evaluated value.",
          "status": "done",
          "testStrategy": "Unit test evaluation of: number, string, boolean literals. Test `define`: evaluate `(define x 10)`, then evaluate `x` to check if it returns 10. Test error handling for unbound symbols."
        },
        {
          "id": 4,
          "title": "Implement Evaluator for `lambda` Expressions and Closure Creation",
          "description": "Extend the evaluator to handle `(lambda (params) body)` expressions. This involves creating `Closure` objects that capture the current lexical environment.",
          "dependencies": [
            3
          ],
          "details": "When `evaluate` encounters a `LambdaNode`, it should create a `Closure` object (or an equivalent data structure). This `Closure` must store: \n1. The lambda's parameters (list of symbol names).\n2. The lambda's body (the ASTNode representing the function body).\n3. A reference to the environment active at the point of the lambda's definition (this is crucial for lexical scoping). \nThe `Closure` object itself is the runtime value representing the function.",
          "status": "done",
          "testStrategy": "Unit test `lambda` evaluation: ensure a `Closure` object is returned. Verify that the closure correctly captures the parameters, body, and the defining environment (e.g., by inspecting the closure or by simple calls in later tests)."
        },
        {
          "id": 5,
          "title": "Implement Evaluator for Function Calls and `if` Expressions",
          "description": "Complete the core evaluation engine by implementing logic for `FunctionCallNode` (evaluating function calls) and `IfNode` (conditional execution).",
          "dependencies": [
            4
          ],
          "details": "For `FunctionCallNode`:\n1. Evaluate the `callee` sub-expression. This should yield a `Closure` (from subtask 4).\n2. Evaluate each `argument` sub-expression in the *current* environment to get argument values.\n3. Create a new `Environment` for the function execution. This new environment's parent should be the `Closure`'s captured environment.\n4. Bind the `Closure`'s parameter names to the evaluated argument values in this new environment.\n5. Evaluate the `Closure`'s body ASTNode within this new, extended environment. The result of this evaluation is the result of the function call.\nFor `IfNode`:\n1. Evaluate the `condition` sub-expression.\n2. If the result is truthy (e.g., not `false`), evaluate and return the result of the `thenBranch`.\n3. Otherwise, evaluate and return the result of the `elseBranch`.",
          "status": "done",
          "testStrategy": "Unit test `if` expressions: test both true and false conditions. Unit test function calls: \n- Simple call: `((lambda (x) x) 10)` should yield 10.\n- Closure behavior: `(define y 5) (define f (lambda (x) (+ x y))) (f 10)` should yield 15 (assuming `+` is predefined or part of a later task; for now, can test with identity or simple operations).\n- Argument evaluation order (if relevant, though typically left-to-right).\n- Recursive calls if the language structure allows for it (e.g., `(define fac (lambda (n) (if (= n 0) 1 (* n (fac (- n 1)))))) (fac 3)`)."
        }
      ]
    },
    {
      "id": 3,
      "title": "Basic Type System Implementation (Primitive Types & Function Types)",
      "description": "Implement the foundational components of the HoTT-based type system, including representations for basic predefined types (e.g., `Nat`, `Bool`, `String`) and simple function types.",
      "details": "Define data structures to represent types, e.g., `TypeAtom(name)`, `FunctionType(param_types, return_type)`. Predefine instances for `Nat`, `Bool`, `String`. The type system should be able to represent these types and allow for their comparison (equality of types). This does not yet include type checking logic, only the representation.",
      "testStrategy": "Unit tests for creating and representing basic types (`Nat`, `Bool`) and function types (e.g., `(-> Nat Bool)`, `(-> Nat Nat Nat)`). Verify that type representations are distinct and can be compared for equality.",
      "priority": "medium",
      "dependencies": [
        2
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Define Base 'Type' Interface/Enum",
          "description": "Establish the core data structure or enumeration that will serve as the basis for all type representations in the system. This will define the common contract for different kinds of types.",
          "dependencies": [],
          "details": "Define an abstract base class, interface, or an enum (e.g., using a tagged union or sum type pattern if the language supports it well) named `Type`. This structure should be designed to be extensible for future type kinds (e.g., product types, sum types). For now, it just needs to be a common ancestor or variant type that `TypeAtom` and `FunctionType` can conform to or be variants of.",
          "status": "done",
          "testStrategy": "Verify that the `Type` definition exists and can be referenced. Static analysis or compilation success is sufficient at this stage."
        },
        {
          "id": 2,
          "title": "Implement 'TypeAtom' Structure for Primitive Types",
          "description": "Create the data structure for representing atomic, predefined types like `Nat`, `Bool`, `String`. This structure will hold the name of the atomic type.",
          "dependencies": [
            1
          ],
          "details": "Define a class or struct `TypeAtom` that inherits from or implements the base `Type` (from subtask 1). It must contain a `name` field (e.g., a string) to store the identifier of the atomic type (e.g., 'Nat', 'Bool'). Ensure it can be instantiated.",
          "status": "done",
          "testStrategy": "Instantiate `TypeAtom` with different names (e.g., 'Nat', 'TestType'). Verify that the `name` property is correctly stored and accessible. Check that `TypeAtom` instances are considered instances of the base `Type`."
        },
        {
          "id": 3,
          "title": "Implement 'FunctionType' Structure",
          "description": "Create the data structure for representing function types, which consist of a list of parameter types and a single return type.",
          "dependencies": [
            1
          ],
          "details": "Define a class or struct `FunctionType` that inherits from or implements the base `Type` (from subtask 1). It should contain: \n1. `parameter_types`: A list or array of `Type` instances representing the types of the function's parameters. \n2. `return_type`: A `Type` instance representing the function's return type. \nEnsure it can be instantiated with appropriate `Type` instances (which could be `TypeAtom` or other `FunctionType` instances) for its fields.",
          "status": "done",
          "testStrategy": "Instantiate `FunctionType` using mock `Type` instances (or `TypeAtom` instances if subtask 2 is testable in isolation first) for parameter and return types. For example, `FunctionType([mockType1, mockType2], mockReturnType)`. Verify that `parameter_types` and `return_type` are correctly stored and accessible. Check that `FunctionType` instances are considered instances of the base `Type`."
        },
        {
          "id": 4,
          "title": "Predefine Constant Instances for Nat, Bool, String",
          "description": "Create and store globally accessible constant instances for the primitive types `Nat`, `Bool`, and `String` using the `TypeAtom` structure.",
          "dependencies": [
            2
          ],
          "details": "In a suitable module or globally accessible scope, define constant instances of `TypeAtom` for 'Nat', 'Bool', and 'String'. For example: `const TYPE_NAT = new TypeAtom('Nat');`, `const TYPE_BOOL = new TypeAtom('Bool');`, `const TYPE_STRING = new TypeAtom('String');`. These should be readily available for use throughout the type system.",
          "status": "done",
          "testStrategy": "Verify that the predefined instances `TYPE_NAT`, `TYPE_BOOL`, `TYPE_STRING` exist, are of type `TypeAtom` (and thus `Type`), and have the correct names ('Nat', 'Bool', 'String' respectively)."
        },
        {
          "id": 5,
          "title": "Implement Type Equality Comparison Logic",
          "description": "Implement a mechanism to compare two type instances for structural equality. This must handle `TypeAtom` and `FunctionType` correctly.",
          "dependencies": [
            2,
            3
          ],
          "details": "Implement an equality comparison method or function that can take two `Type` instances. \n- For `TypeAtom`: Two `TypeAtom` instances are equal if their `name` fields are identical (case-sensitive). \n- For `FunctionType`: Two `FunctionType` instances are equal if: \n    1. They have the same number of parameter types. \n    2. Each corresponding parameter type is equal (recursively using this equality logic). \n    3. Their return types are equal (recursively). \n- If comparing types of different kinds (e.g., `TypeAtom` vs `FunctionType`), they are not equal. \nThis comparison should be part of the `Type` interface/base class or a dispatching utility function.",
          "status": "done",
          "testStrategy": "Test cases using predefined types (from subtask 4) and custom ones: \n1. `TYPE_NAT` == `TYPE_NAT`. \n2. `TYPE_NAT` != `TYPE_BOOL`. \n3. `new TypeAtom('Nat')` == `TYPE_NAT`. \n4. `FunctionType([TYPE_NAT], TYPE_BOOL)` == `FunctionType([TYPE_NAT], TYPE_BOOL)`. \n5. `FunctionType([TYPE_NAT], TYPE_BOOL)` != `FunctionType([TYPE_NAT], TYPE_STRING)`. \n6. `FunctionType([TYPE_NAT], TYPE_BOOL)` != `FunctionType([TYPE_STRING], TYPE_BOOL)`. \n7. `FunctionType([TYPE_NAT, TYPE_BOOL], TYPE_STRING)` != `FunctionType([TYPE_NAT], TYPE_STRING)`. \n8. `TYPE_NAT` != `FunctionType([], TYPE_NAT)`."
        }
      ]
    },
    {
      "id": 4,
      "title": "Type Checker for Simple Types and Functions",
      "description": "Develop a type checker that can validate expressions involving basic types and simple (non-dependent) function definitions and applications. It should infer types where possible and report type errors.",
      "details": "Implement a type checking algorithm, potentially bidirectional (checking and inference). For `(define x value)`, infer type of `value` and assign to `x`. For `(lambda (p1 p2) body)`, if param types are annotated, use them; otherwise, attempt inference. Type check `body` against expected return type. For `(f arg1 arg2)`, check that `f` is a function, and `arg` types match `f`'s param types. The type checker will operate on the AST and use the type representations from Task 3. Error messages should be clear about type mismatches.",
      "testStrategy": "Test with well-typed programs (e.g., `(define (add (x Nat) (y Nat)) (+ x y))`, `(add 1 2)`). Test with ill-typed programs (e.g., applying a number as a function, wrong argument types, incorrect return type in function body). Verify correct type inference for simple cases and accurate error reporting for mismatches.",
      "priority": "medium",
      "dependencies": [
        3
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Type Checking for Literals and Variable References",
          "description": "Develop the core logic to determine the types of basic literals (e.g., integers, booleans) and to look up types of variables from a type environment. This forms the foundation for checking more complex expressions.",
          "dependencies": [],
          "details": "Create a `TypeEnvironment` class/structure to store variable-to-type mappings (scoped, if necessary, for later features like let-bindings or nested functions). Implement a `check(ast_node, environment)` or `infer(ast_node, environment)` method. For literal AST nodes (e.g., `NumberNode`, `BooleanNode`), this method should return their corresponding `Type` objects (e.g., `NumberType`, `BooleanType` from Task 3). For `VariableNode`, it should look up the variable's name in the `TypeEnvironment`. If not found, this is an unbound variable situation (actual error reporting will be refined in a later subtask, but the condition should be detectable).",
          "status": "done",
          "testStrategy": "Test with AST nodes for various literals (e.g., `1`, `true`). Test variable lookups in environments with and without the variable defined. Ensure correct `Type` objects are returned."
        },
        {
          "id": 2,
          "title": "Implement Type Checking for `define` Expressions",
          "description": "Extend the type checker to handle `(define x value)` expressions. This involves inferring the type of the `value` expression and updating the type environment with this new binding for `x`.",
          "dependencies": [
            1
          ],
          "details": "For a `DefineNode(name, value_expr)`: 1. Recursively call the type checker (e.g., `infer(value_expr, environment)`) on the `value_expr` to determine its type. 2. If `value_expr` type checking fails, propagate the error. 3. Otherwise, update the current `TypeEnvironment` by adding a mapping from `name` (a string) to the inferred type. The `define` expression itself might be considered to have a special `Void` type or the type of the variable being defined; clarify this or focus on the environment side-effect. Ensure the updated environment is used for subsequent expressions at the same scope.",
          "status": "done",
          "testStrategy": "Test `(define x 10)` and verify that `x` is subsequently typed as `NumberType`. Test `(define y true)` for `BooleanType`. Test `(define z x)` after `x` is defined, ensuring `z` gets `x`'s type. Test cases where `value` expression has a type error."
        },
        {
          "id": 3,
          "title": "Implement Type Checking for `lambda` Expressions (Function Definitions)",
          "description": "Implement type checking for function definitions `(lambda (param1 param2 ...) body)`. This includes processing parameter type annotations, creating a new scope for the function body, and inferring the function's return type by checking the body. The result is a function type.",
          "dependencies": [
            1
          ],
          "details": "For a `LambdaNode(params, body_expr)`: 1. Create a new, extended `TypeEnvironment` that inherits from the current environment. 2. For each parameter in `params`: If type annotations are present (e.g., `(x : Int)`), add the parameter name and its annotated type to this new environment. If annotations are absent, for this initial implementation, either require annotations or assume a default 'Unknown/Any' type, or prepare for more complex inference if specified. 3. Recursively call the type checker (e.g., `infer(body_expr, new_environment)`) on `body_expr` to determine its type. This is the function's return type. 4. The type of the `lambda` expression itself is a `FunctionType` (from Task 3) composed of the list of parameter types and the inferred return type.",
          "status": "done",
          "testStrategy": "Test `(lambda ((x : Int)) x)` should result in a `FunctionType(param_types=[IntType], return_type=IntType)`. Test `(lambda ((a : Bool) (b : Int)) b)` resulting in `FunctionType(param_types=[BoolType, IntType], return_type=IntType)`. Test cases where the body has a type error based on its own structure or use of parameters."
        },
        {
          "id": 4,
          "title": "Implement Type Checking for Function Applications",
          "description": "Implement type checking for function application expressions `(f arg1 arg2 ...)`. This involves ensuring `f` evaluates to a function type, the number of arguments matches the function's arity, and each argument's type is compatible with the corresponding parameter type. The type of the application is the function's return type.",
          "dependencies": [
            1,
            3
          ],
          "details": "For an `ApplicationNode(function_expr, arg_exprs)`: 1. Recursively call the type checker on `function_expr` to get its type. Verify this is a `FunctionType`. If not, it's a type error ('not a function'). 2. Compare the number of `arg_exprs` with the arity (number of parameters) of the `FunctionType`. If they don't match, it's an arity mismatch error. 3. For each `arg_expr` and its corresponding parameter type from the `FunctionType`: a. Recursively call the type checker on `arg_expr` to get its type. b. Check if the argument's actual type is assignable to/compatible with the expected parameter type. If not, it's a type mismatch error. 4. If all checks pass, the type of the `ApplicationNode` expression is the return type specified in the `FunctionType` of `function_expr`.",
          "status": "done",
          "testStrategy": "Given `(define myfun (lambda ((a : Int) (b : Bool)) a))`: Test `(myfun 1 true)` should type check to `IntType`. Test `(myfun 1 2)` (argument type mismatch). Test `(myfun 1)` (arity mismatch). Test `(1 2 3)` ('not a function' error for `1`)."
        },
        {
          "id": 5,
          "title": "Implement Clear Type Error Reporting and System Integration",
          "description": "Develop a robust error reporting mechanism that generates clear, user-friendly messages for all detected type errors (e.g., mismatches, unbound variables, arity errors). Integrate the type checker to operate on a full AST and collect all errors.",
          "dependencies": [
            1,
            2,
            3,
            4
          ],
          "details": "1. Define a `TypeError` class or structure to encapsulate error details: message, AST node location (for line/column numbers if available), expected type, actual type, etc. 2. Modify all type checking functions (from subtasks 1-4) to generate and return/collect these `TypeError` objects when an issue is detected, instead of throwing exceptions or immediately halting (to allow for collecting multiple errors). 3. Create a main driver function for the type checker that traverses the entire program AST. This driver should invoke the appropriate checking logic for each node type and accumulate any `TypeError` objects. 4. Format error messages clearly, e.g., \"Type Error: Expected 'Int' but found 'Bool' for parameter 'y' in function call 'f'. (line X, col Y)\". Ensure messages distinguish between different kinds of errors.",
          "status": "done",
          "testStrategy": "Create a suite of small programs, each designed to trigger specific type errors: unbound variable, type mismatch in definition, type mismatch in function argument, calling a non-function, incorrect arity in function call. Verify that the type checker identifies all errors and that the reported messages are accurate, informative, and (if possible) point to the source location."
        }
      ]
    },
    {
      "id": 5,
      "title": "Canonical Instantiation Functions (CIFs) - Pure Product and Sum Types",
      "description": "Implement the `deftype` syntax for defining simple product types (struct-like) and sum types (enum-like). Generate and evaluate pure Canonical Instantiation Functions (CIFs) for these types. No effects or complex constraints at this stage.",
      "details": "Extend parser for `(deftype Name (fields...) ...)` for product types (e.g., `(deftype Point ((x Nat) (y Nat)))`) and `(deftype Name (Variant1 type1) (Variant2 type2) ...)` for sum types (e.g., `(deftype Shape (Circle Nat) (Rectangle Nat Nat)))`). The type checker must register these new types. CIFs are implicitly defined by the type name (e.g., `(Point 1 2)`, `(Circle 5)`). The evaluator needs to handle instantiation of these custom types, creating record-like or tagged-union-like data structures. CIFs are pure at this stage.",
      "testStrategy": "Define several product and sum types. Instantiate them using their CIFs. Verify that the type checker correctly types these instantiations. Access fields of product types and pattern match (rudimentary, if available, or inspect structure) on sum types. Ensure instantiations are evaluated to correct runtime values.",
      "priority": "medium",
      "dependencies": [
        4
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Extend Parser for `deftype` Syntax (Product and Sum Types)",
          "description": "Modify the parser to recognize and parse the `(deftype Name ...)` syntax for both product types `(deftype Name ((field1 type1) (field2 type2) ...))` and sum types `(deftype Name (Variant1 typeA ...) (Variant2 typeB typeC ...) ...)`. The parser should generate distinct Abstract Syntax Tree (AST) nodes for these definitions.",
          "dependencies": [],
          "details": "Implement parsing rules for:\n1. Product types: `(deftype <TypeName> (<fieldName> <fieldType>)+)`. Example: `(deftype Point ((x Nat) (y Nat)))`. The AST node should capture the type name, and an ordered list of (field name, field type name) pairs.\n2. Sum types: `(deftype <TypeName> (<VariantName> <fieldType>*)*)`. Example: `(deftype Shape (Circle Nat) (Rectangle Nat Nat))`. The AST node should capture the type name, and a list of (variant name, list of argument type names) pairs.\nEnsure robust error handling for malformed definitions.",
          "status": "done",
          "testStrategy": "Unit test the parser with various valid `deftype` expressions for both product and sum types. Test edge cases like empty field lists (if disallowed), empty variant lists, types with no arguments for variants. Verify correct AST node structure and content. Test with invalid syntax to ensure proper error reporting."
        },
        {
          "id": 2,
          "title": "Type Checker: Register User-Defined Product and Sum Types",
          "description": "Enhance the type checker to process `deftype` AST nodes from the parser. It must register these new product and sum types in the type environment, storing their structure (field names and resolved types for products; variant names and their resolved argument types for sums).",
          "dependencies": [
            1
          ],
          "details": "When a `deftype` AST node is encountered during type checking:\n1. For product types: Resolve all field types against the current type environment. Store the new type name along with its definition (e.g., an ordered list of (field name, resolved field type)).\n2. For sum types: Resolve all argument types for each variant against the current type environment. Store the new type name along with its definition (e.g., a map of variant names to a list of resolved argument types).\n3. Check for type name collisions within the current scope. Disallow redefinition of existing types or primitive types.\n4. The registered types should be available for subsequent type checking.",
          "status": "done",
          "testStrategy": "Unit test the type checker by processing various `deftype` AST nodes. Verify that types are correctly registered in the type environment with their accurate structure. Test scenarios with valid type references, undefined type references in field/variant definitions, and type name conflicts."
        },
        {
          "id": 3,
          "title": "Type Checker: Recognize and Type Check Canonical Instantiation Function (CIF) Calls",
          "description": "Update the type checker to recognize expressions like `(TypeName arg1 ...)` or `(VariantName arg1 ...)` as Canonical Instantiation Function (CIF) calls. It should type-check these calls against the registered product or sum type definitions, determining the type of the resulting expression.",
          "dependencies": [
            2
          ],
          "details": "1. For product types: If an application form `(F arg1 ... argN)` is encountered and `F` matches a registered product type name (e.g., `Point`), treat this as a CIF call.\n   - Verify the number of arguments matches the number of fields in the `Point` type definition.\n   - Type-check each argument `argI` against the corresponding field type `fieldTypeI`.\n   - The type of the entire expression `(Point arg1 ... argN)` is `Point`.\n2. For sum types: If an application form `(V arg1 ... argM)` is encountered and `V` matches a registered variant name (e.g., `Circle` of type `Shape`), treat this as a CIF call.\n   - Verify `V` is a known variant of some sum type `S`.\n   - Verify the number of arguments matches the definition of variant `V`.\n   - Type-check each argument `argI` against the corresponding argument type for variant `V`.\n   - The type of the entire expression `(Circle arg1 ... argM)` is the parent sum type `S` (e.g., `Shape`).\nCIFs are implicit; no explicit function definition is parsed for them.",
          "status": "done",
          "testStrategy": "Unit test the type checker with various CIF calls. Include tests for: \n- Correct product type instantiations (e.g., `(Point 1 2)`).\n- Correct sum type variant instantiations (e.g., `(Circle 5)`).\n- Incorrect calls: wrong number of arguments, arguments of incorrect types for both product and sum CIFs.\n- Calls to undefined type names or variant names."
        },
        {
          "id": 4,
          "title": "Evaluator: Implement Product Type Instantiation",
          "description": "Modify the evaluator to handle CIF calls for product types. When a type-checked expression like `(Point 1 2)` is evaluated, it should create and return an internal runtime representation of a product type instance (e.g., a record or struct-like object).",
          "dependencies": [
            3
          ],
          "details": "1. When the evaluator encounters a CIF call for a product type (identified by the type checker, e.g., an AST node tagged as 'ProductCIFCall' with type name and arguments):\n   - Evaluate each argument expression to get its runtime value.\n   - Construct an internal data structure for the product instance. This structure should store the evaluated argument values, associated with their field names (e.g., a map like `{\"x\": <value_of_arg1>, \"y\": <value_of_arg2>}`) or in a fixed order if field names are not stored at runtime for pure products.\n   - The runtime instance should also be tagged with its type name (e.g., `Point`).\n   - Example: `(Point 1 2)` evaluates to a runtime value representing `{ type: 'Point', fields: { x: 1, y: 2 } }` or similar.",
          "status": "done",
          "testStrategy": "Unit test the evaluator for product type instantiation. \n- Evaluate simple product CIF calls like `(Point 1 2)` and verify the structure and content of the resulting runtime object.\n- Test with different data types for fields (e.g., numbers, booleans, other custom types if supported).\n- Ensure the runtime object is correctly tagged with its type."
        },
        {
          "id": 5,
          "title": "Evaluator: Implement Sum Type Instantiation",
          "description": "Modify the evaluator to handle CIF calls for sum type variants. When a type-checked expression like `(Circle 5)` (for `deftype Shape (Circle Nat) ...`) is evaluated, it should create and return an internal runtime representation of a sum type instance (e.g., a tagged union).",
          "dependencies": [
            3
          ],
          "details": "1. When the evaluator encounters a CIF call for a sum type variant (identified by the type checker, e.g., an AST node tagged as 'SumCIFCall' with sum type name, variant name, and arguments):\n   - Evaluate each argument expression to get its runtime value.\n   - Construct an internal data structure for the sum type instance. This structure must include:\n     a. The specific variant tag/name (e.g., `\"Circle\"`).\n     b. The evaluated argument values for that variant (e.g., `[<value_of_arg1>]`).\n     c. The overall sum type name (e.g., `\"Shape\"`).\n   - Example: `(Circle 5)` for `(deftype Shape (Circle Nat) ...)` evaluates to a runtime value like `{ type: 'Shape', variant: 'Circle', values: [5] }`.\n   - Example: `(Rectangle 10 20)` for `(deftype Shape ... (Rectangle Nat Nat))` evaluates to `{ type: 'Shape', variant: 'Rectangle', values: [10, 20] }`.",
          "status": "done",
          "testStrategy": "Unit test the evaluator for sum type instantiation.\n- Evaluate various sum type variant CIF calls (e.g., `(Circle 5)`, `(Rectangle 10 20)`).\n- Verify the structure and content of the resulting tagged runtime object (correct sum type, variant tag, and values).\n- Test variants with no arguments and multiple arguments.\n- Ensure the runtime object is correctly tagged."
        }
      ]
    },
    {
      "id": 6,
      "title": "Basic REPL Implementation",
      "description": "Create a basic Read-Eval-Print Loop (REPL) for interactive development, integrating the parser, type checker, and evaluator. This provides an initial user interface for the language.",
      "details": "The REPL should: Read a line of user input. Parse the input S-expression. Type check the parsed AST. If type checking succeeds, evaluate the AST. Print the result of evaluation or any error messages (parse error, type error, runtime error). Maintain a persistent environment across REPL inputs for definitions.",
      "testStrategy": "Interactive testing: Define types using `deftype`. Define functions. Instantiate types. Evaluate expressions involving these definitions. Check error handling and reporting within the REPL for all stages (read, type check, eval). Verify environment persistence.",
      "priority": "medium",
      "dependencies": [
        5
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement REPL Core Loop and User Input Reading",
          "description": "Set up the fundamental REPL structure that continuously prompts the user for input, reads a line of text, and handles basic exit commands (e.g., 'exit', 'quit'). This forms the basic interaction shell.",
          "dependencies": [],
          "details": "Implement an infinite loop that: 1. Prints a prompt (e.g., '> '). 2. Reads a line of text from standard input. 3. Checks if the input is an exit command (e.g., 'exit', ':q'). If so, terminate the REPL. Otherwise, proceed to the next step (parsing, to be added in a subsequent subtask). Use appropriate I/O functions for the target language/environment.",
          "status": "done",
          "testStrategy": "Manually run the REPL. Verify that it displays a prompt. Enter text and see it acknowledged (even if not processed yet). Enter exit commands and verify the REPL terminates."
        },
        {
          "id": 2,
          "title": "Integrate S-expression Parser and Handle Parse Errors",
          "description": "Connect the existing S-expression parser to the REPL. For each user input (that is not an exit command), attempt to parse it. If parsing fails, display a clear, user-friendly parse error message. If successful, the AST should be available for the next stage.",
          "dependencies": [
            1
          ],
          "details": "After reading input in the REPL loop (from subtask 1), pass the input string to the `parse()` function from the parser module. Implement try-catch or error-checking around the parse call. If a parse error occurs, print a message like 'Parse Error: [error details]' to standard error and loop back for new input. If successful, store the generated AST.",
          "status": "done",
          "testStrategy": "Enter valid S-expressions; verify no error is printed and the REPL awaits next input (or moves to a placeholder for next stage). Enter malformed S-expressions (e.g., `(foo`, `(bar . )`, `())`) and verify specific parse error messages are displayed."
        },
        {
          "id": 3,
          "title": "Integrate Type Checker and Handle Type Errors",
          "description": "Integrate the type checker module into the REPL. After successful parsing, pass the AST to the type checker. If type checking fails, display a clear type error message. If successful, the (potentially annotated) AST proceeds to evaluation. For this subtask, the type checker will operate with a fresh/empty environment for each input.",
          "dependencies": [
            2
          ],
          "details": "After a successful parse (from subtask 2), call the `typeCheck(ast, initialEnvironment)` function from the type checker module. `initialEnvironment` will be a new, empty environment for each call in this subtask. Implement try-catch or error-checking for type errors. If a type error occurs, print 'Type Error: [error details]' and loop back. If successful, store the (typed) AST.",
          "status": "done",
          "testStrategy": "Enter syntactically correct but type-incorrect expressions (e.g., `(+ 1 #t)` if booleans aren't summable with numbers). Verify specific type error messages. Enter type-correct expressions and verify no error is printed."
        },
        {
          "id": 4,
          "title": "Integrate Evaluator, Handle Runtime Errors, and Print Results",
          "description": "Integrate the evaluator module. After successful type checking, pass the AST to the evaluator. Print the result of the evaluation. If a runtime error occurs, display a clear runtime error message. For this subtask, the evaluator will operate with a fresh/empty environment for each input (matching the type checker).",
          "dependencies": [
            3
          ],
          "details": "After successful type checking (from subtask 3), call the `evaluate(ast, initialEnvironment)` function from the evaluator module. `initialEnvironment` will be a new, empty environment. Implement try-catch or error-checking for runtime errors. If evaluation is successful, print the resulting value to standard output. If a runtime error occurs (e.g., division by zero, unbound variable before persistence), print 'Runtime Error: [error details]'. Always loop back for new input.",
          "status": "done",
          "testStrategy": "Enter expressions that evaluate successfully (e.g., `(+ 1 2)`) and verify the correct result is printed. Enter expressions causing runtime errors (e.g., `(/ 1 0)`) and verify specific runtime error messages."
        },
        {
          "id": 5,
          "title": "Implement Persistent Environment Across REPL Inputs",
          "description": "Modify the REPL to initialize and maintain a single, persistent environment that is used across all user inputs. This allows definitions (e.g., variables, functions) made in one REPL interaction to be available in subsequent interactions.",
          "dependencies": [
            4
          ],
          "details": "1. Initialize a global/shared environment object once when the REPL starts. 2. Modify the calls to `typeCheck` (subtask 3) and `evaluate` (subtask 4) to pass this persistent environment instance instead of a fresh one. 3. Ensure that language constructs that create definitions (e.g., `define`, `let` if it modifies the top-level) update this shared environment. The type checker and evaluator might need internal adjustments to correctly handle and update the passed-in environment.",
          "status": "done",
          "testStrategy": "1. Define a variable: `(define x 10)`. Verify no error and prompt returns. 2. Use the variable: `(+ x 5)`. Verify result is `15`. 3. Define a function: `(define (add_one y) (+ y 1))`. 4. Call the function: `(add_one 20)`. Verify result is `21`. Test redefinition if supported."
        }
      ]
    },
    {
      "id": 7,
      "title": "Algebraic Effect System Core: Declaration and Basic Handling",
      "description": "Implement the core infrastructure for algebraic effects, including effect declaration (`defeffect`) and a basic mechanism for performing effects and handling them with `try/handle` (or `try/catch` for specific effects).",
      "details": "Parse `(defeffect EffectName (operation (params) : ReturnType) ...)` to define effects and their operations. Implement a `perform (EffectName.operation args)` primitive that suspends computation. Implement `(try body-expr (:handle (EffectName op) (k arg) handler-body) ...)` where `k` is the continuation. The handler body can resume the computation using `(resume k value)`. This requires a continuation-passing style transformation or similar mechanism in the evaluator.",
      "testStrategy": "Define a simple custom effect (e.g., `State` with `get`/`put` operations). Write programs that perform these effects. Implement handlers that manage the effect (e.g., provide state). Verify that effects suspend computation and handlers can resume them, demonstrating non-local control flow.",
      "priority": "medium",
      "dependencies": [
        2
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement `defeffect` Parser and Effect Registry",
          "description": "Parse `(defeffect EffectName (operation (params) : ReturnType) ...)` syntax. Store effect definitions, including their operations, parameters, and return types, in a central registry accessible by the runtime.",
          "dependencies": [],
          "details": "Modify the language parser to recognize the `defeffect` keyword and its structure (EffectName, list of operations, each with parameters and an optional ReturnType). Create data structures to represent `EffectDefinition` and `OperationSignature`. Implement a global or module-scoped registry (e.g., a hash map) to store these definitions, keyed by `EffectName`. Each `EffectName` would map to an object/struct containing its defined operations and their signatures. Ensure validation of effect and operation names (e.g., uniqueness, valid identifiers).",
          "status": "done",
          "testStrategy": "Define several effects with varying numbers of operations, different parameter lists, and with/without return types. Verify that they are parsed correctly and stored in the registry with the expected structure. Test error handling for malformed `defeffect` expressions (e.g., duplicate effect names, invalid operation syntax)."
        },
        {
          "id": 2,
          "title": "Implement `perform` Primitive and Initial Suspension Signal",
          "description": "Implement the `(perform EffectName.operation args)` primitive. When `perform` is called, it should identify the effect and operation, package the arguments, and signal a suspension of the current computation by propagating an effect instance.",
          "dependencies": [
            1
          ],
          "details": "Add `perform` as a built-in function or special form. It should look up `EffectName.operation` in the registry (from subtask 1) to validate the operation and arity of `args`. Create a unique, identifiable object (e.g., an \"EffectInstance\" or a special throwable object) that encapsulates the specific effect operation being performed and its arguments. The evaluator must be modified to recognize this signal and halt normal execution flow, propagating this signal upwards. This signal will later be caught by a `try/handle` block.",
          "status": "done",
          "testStrategy": "Test `perform` with valid effect/operation names and correct arguments. Verify that performing an effect interrupts the normal flow and propagates an EffectInstance object. Test error conditions: unknown effect/operation, incorrect number of arguments. If no handler is present, this might result in an unhandled effect error."
        },
        {
          "id": 3,
          "title": "Implement `try/handle` Syntax Parsing and Handler Scope Setup",
          "description": "Parse the `(try body-expr (:handle (EffectName op) (k arg) handler-body) ...)` syntax. During evaluation of a `try` expression, establish a dynamic scope that registers the provided handlers for specific effects and operations.",
          "dependencies": [
            1
          ],
          "details": "Extend the parser to support the `try` special form and its `:handle` clauses. Each `:handle` clause specifies an `EffectName`, an `operation` name (`op`), a continuation parameter (`k`), an argument parameter (`arg`), and a `handler-body`. When a `try` expression is evaluated, push a new frame onto a runtime \"handler stack\". This frame should store a mapping from `(EffectName, operationName)` pairs to their corresponding handler functions (closures created from `handler-body` capturing `k` and `arg` parameters and the lexical environment). The `body-expr` is then evaluated within this scope. Upon normal completion or an effect being handled and resumed out of the `try` block, this handler frame should be popped.",
          "status": "done",
          "testStrategy": "Parse various `try/handle` expressions with single and multiple `:handle` clauses. Verify that the handler scope is correctly established on the handler stack during `body-expr` evaluation and torn down afterwards. Test evaluation of `body-expr` within a `try` block that does not perform any effects, ensuring it executes normally."
        },
        {
          "id": 4,
          "title": "Implement Effect Handling Logic and Continuation Capturing",
          "description": "Integrate `perform` with `try/handle`. When an effect is signaled (from subtask 2) within a `try` block, search the handler stack for a matching handler. If found, capture the current continuation and invoke the handler with the continuation and effect arguments.",
          "dependencies": [
            2,
            3
          ],
          "details": "Modify the evaluator's response to the \"EffectInstance\" signal. When an effect is signaled, the evaluator should search the current handler stack (from subtask 3) for a handler matching the `EffectName` and `operationName` from the EffectInstance. If a handler is found: 1. Capture the current state of computation as a \"continuation\" object/function. This continuation, when invoked later with a value, should resume execution as if the `perform` call returned that value. 2. Invoke the matched handler function, passing it the captured continuation (`k`) and the arguments from the `perform` call (bound to `arg`). If no handler is found, the effect signal should continue propagating upwards.",
          "status": "done",
          "testStrategy": "Create test cases where `perform` is called inside a `try/handle` block with a matching handler. Verify that the correct handler is invoked. Verify that the continuation object and effect arguments are correctly passed to the handler. Initially, the handler might just print arguments or return a fixed value without using `resume`. Test unhandled effects propagating out of a `try` block."
        },
        {
          "id": 5,
          "title": "Implement `resume` Primitive for Continuation Invocation",
          "description": "Implement the `(resume k value)` primitive. This primitive takes a continuation (captured in subtask 4) and a value, and resumes the suspended computation, making the original `perform` call appear to return `value`.",
          "dependencies": [
            4
          ],
          "details": "Add `resume` as a built-in function or primitive. It expects a continuation object (as created in subtask 4) and a result value. Invoking `(resume k value)` should: 1. Restore the evaluation context (e.g., stack, relevant parts of the environment) associated with the continuation. 2. Make the original `perform` call (that was suspended) evaluate to `value`. 3. Ensure that the handler stack is correctly managed; the handler that called `resume` is typically no longer active for the resumed computation unless it re-establishes handlers. The control flow returns to the point after the `perform` call.",
          "status": "done",
          "testStrategy": "Test handlers that use `(resume k some-value)`. Verify that the computation resumes correctly from the point of `perform` and that the `perform` expression effectively returns `some-value`. Test scenarios with multiple `perform` calls for the same effect handled by the same handler instance (if the handler design allows re-entry or multiple resumptions). Test resuming with different types of values. Ensure that after resumption, the execution context is correct."
        }
      ]
    },
    {
      "id": 8,
      "title": "`ConstructionFailure` Effect and Basic CIF Runtime Constraints",
      "description": "Introduce the predefined `ConstructionFailure` effect as a proper algebraic effect within our 3-tier system. Modify Constructor Invocation Functions (CIFs) for types defined with `(:where ...)` clauses to `perform` this effect if runtime constraint checks fail. This allows construction failures to be managed by context-aware algebraic effect handlers rather than traditional exception handling.",
      "status": "pending",
      "dependencies": [
        5,
        7
      ],
      "priority": "medium",
      "details": "Predefine the `ConstructionFailure` effect (e.g., `(defeffect ConstructionFailure (fail (message String)) : Nothing)`). This will be a Tier 2/3 effect. Extend `deftype` to parse `(:where predicate-expr)` clauses. When a CIF for such a type is called, it will evaluate the `predicate-expr` after constructing the underlying value. If the predicate is false, the CIF will `perform (ConstructionFailure.fail \"Constraint violated\")`. Users can then manage this effect using the standard algebraic effect handler mechanism (e.g., `with-handler`). This allows for flexible, context-dependent failure management, such as providing a default value, logging the error, or aborting the computation.",
      "testStrategy": "Define a type with a `(:where ...)` constraint (e.g., `(deftype PositiveNat Nat (:where (> self 0)))`). Test instantiation with valid values (should succeed) and invalid values (should perform `ConstructionFailure`). Verify that a suitable effect handler (e.g., one defined with `defhandler`) can intercept the `ConstructionFailure` effect and execute custom logic, such as returning a default value or re-raising a different effect.",
      "subtasks": [
        {
          "id": 1,
          "title": "Define Predefined `ConstructionFailure` Effect",
          "description": "Introduce the `ConstructionFailure` effect into the system's core library or prelude. This effect signals failures during type construction when runtime constraints are violated.",
          "dependencies": [],
          "details": "Implement `(defeffect ConstructionFailure (fail (message String)) : Nothing)` as specified. Ensure it's available globally. This should be classified as a Tier 2 (compile-time checkable) and Tier 3 (runtime) effect. The `fail` operation should accept a `String` message. The effect type should indicate no return value (e.g., `: Nothing`), signifying that it does not resume by default.",
          "status": "pending",
          "testStrategy": "Verify `ConstructionFailure` is a recognized effect type and is correctly integrated into the Tier 2/3 effect system. Test that `(perform (ConstructionFailure.fail \"test message\"))` can be invoked (it will be unhandled initially). Check that the `fail` operation correctly packages the message as its payload."
        },
        {
          "id": 2,
          "title": "Extend `deftype` to Parse and Store `:where` Clauses",
          "description": "Modify the `deftype` macro or special form to recognize, parse, and store `(:where predicate-expr)` clauses found within type definitions. The predicate expression will be used for runtime validation.",
          "dependencies": [
            1
          ],
          "details": "Update the `deftype` parser. When a `(:where predicate-expr)` clause is encountered: 1. Parse `predicate-expr`. 2. Store this predicate (e.g., as a lambda, an abstract syntax tree, or a compiled function) in the type's metadata. 3. Define and document a convention for how the value being constructed will be referenced within `predicate-expr` (e.g., a special variable like `self` or `this`).",
          "status": "pending",
          "testStrategy": "Define various types using `deftype` with and without `:where` clauses. Inspect the internal representation (e.g., type metadata object) to confirm correct parsing and storage of the predicate. Test with syntactically valid and invalid predicates to ensure robust parsing."
        },
        {
          "id": 3,
          "title": "Adapt CIF Generation to Incorporate Constraint Predicates",
          "description": "Update the Constructor Invocation Function (CIF) generation logic. For types defined with a `:where` clause, the generated CIF must be structured to call the stored predicate expression after the base value is constructed.",
          "dependencies": [
            2
          ],
          "details": "Modify the code generation part of `deftype` or the CIF creation mechanism. When a CIF is generated for a type with a stored predicate: 1. The CIF should first construct the underlying value as usual. 2. After construction, the generated CIF code should include a call to the stored predicate, passing the newly constructed value to it according to the convention established in Subtask 2. The actual performing of the `ConstructionFailure` effect based on the predicate's result is handled in the next subtask.",
          "status": "pending",
          "testStrategy": "For types with `:where` clauses, inspect the generated CIF code (if feasible) or use a debugger to verify that the structure for predicate evaluation (i.e., the call to the predicate function) is correctly inserted into the CIF. This subtask focuses on setting up the call, not the full execution and effect performance yet."
        },
        {
          "id": 4,
          "title": "Implement Runtime Predicate Check and `ConstructionFailure` Invocation in CIFs",
          "description": "Enhance CIFs for types with `:where` clauses to execute the stored predicate at runtime. If the predicate evaluates to false, the CIF must perform the `ConstructionFailure.fail` effect.",
          "dependencies": [
            1,
            3
          ],
          "details": "In the CIF execution flow for types with constraints: 1. After the base value is constructed and the predicate is called (as set up in Subtask 3), check its return value. 2. If the predicate returns `false` (or any falsey value according to the language's semantics), perform `(ConstructionFailure.fail \"Constraint violated\")`. The message can be made more specific, e.g., by including the type name or a user-provided message from the `:where` clause if supported.",
          "status": "pending",
          "testStrategy": "Instantiate types with `:where` clauses: 1. For predicates that should pass, verify successful construction and correct value. 2. For predicates that should fail, verify that `(ConstructionFailure.fail ...)` is performed. This might initially result in an unhandled effect error if Subtask 5 is not yet complete, which is acceptable at this stage. Confirm the message in the performed effect."
        },
        {
          "id": 5,
          "title": "Enable Handling of `ConstructionFailure` via Algebraic Effect Handlers",
          "description": "Ensure the existing algebraic effect handling mechanism can be used to manage the `ConstructionFailure` effect. This allows user code to define handlers that intercept construction failures and execute custom logic.",
          "dependencies": [
            4
          ],
          "details": "Leverage the language's existing effect handler syntax (e.g., `with-handler` and `defhandler`). When a `ConstructionFailure` is performed within the dynamic scope of a handler: 1. Control is transferred to the appropriate clause in the handler. 2. The handler receives the effect payload (the message) and the continuation. 3. The handler can then choose to: a) Abort the computation and return a fallback value. b) Resume the computation with a default value if the effect signature allowed it (though `ConstructionFailure` shouldn't). c) Perform another effect. This subtask ensures the general handler mechanism works correctly for this specific, newly introduced effect.",
          "status": "pending",
          "testStrategy": "1. Define a handler that catches `ConstructionFailure` and returns a default value (e.g., `0` or `nil`). 2. Wrap a failing constructor call with this handler, e.g., `(with-handler MyFailureHandler (PositiveNat -1))`. Verify the expression evaluates to the default value. 3. Verify that the handler is *not* invoked when construction succeeds, e.g., `(with-handler MyFailureHandler (PositiveNat 1))` should return a valid `PositiveNat` instance. 4. Test that the handler receives the correct error message from the effect's payload. 5. Test nested handlers to ensure correct dynamic scoping."
        }
      ]
    },
    {
      "id": 9,
      "title": "CIF Purity Analysis and Effect Inference (Initial)",
      "description": "Implement initial logic for CIF purity analysis. The compiler/type checker should infer if a CIF is pure or potentially effectful (e.g., due to `ConstructionFailure` from a runtime constraint).",
      "details": "During `deftype` processing, analyze its definition. If a `(:where ...)` clause exists and its predicate cannot be statically proven true (assume all are runtime checks for now), the CIF is marked as potentially performing `ConstructionFailure`. This information should be associated with the type/CIF and accessible by the type system. Pure CIFs have no `(:where)` or their constraints are trivially true.",
      "testStrategy": "Define types with and without `(:where)` clauses. Query the system (e.g., via a debug interface or by how the type checker treats calls) to verify that CIFs are correctly identified as pure or effectful (performing `ConstructionFailure`).",
      "priority": "medium",
      "dependencies": [
        8
      ],
      "status": "pending",
      "subtasks": [
        {
          "id": 1,
          "title": "Define Data Structure for CIF Purity/Effect Status",
          "description": "Design and implement the data structure to represent whether a CIF (Constructed Immutable Form) is pure or potentially effectful (e.g., due to `ConstructionFailure`). This structure will be associated with type definitions.",
          "dependencies": [],
          "details": "Introduce an enum or a set of flags (e.g., `PurityStatus { PURE, POTENTIALLY_EFFECTFUL_CONSTRUCTION_FAILURE }`). This status should be attachable to the internal representation of a CIF, likely as a field in the `TypeDefinition` struct or a property in the symbol table entry for the type. Ensure it defaults to a sensible value (e.g., PURE or UNKNOWN) before analysis.",
          "status": "pending",
          "testStrategy": "Unit tests for the data structure itself, if it's more complex than a simple enum. Verify it can represent the required states. No functional tests involving CIF analysis yet."
        },
        {
          "id": 2,
          "title": "Implement `deftype` and `(:where)` Clause Detection in AST",
          "description": "Modify the compiler's Abstract Syntax Tree (AST) traversal mechanism (e.g., during `deftype` processing or a dedicated analysis pass) to identify `deftype` declarations and specifically locate any `(:where ...)` clauses within their definitions.",
          "dependencies": [],
          "details": "Extend the existing AST visitor or parser logic. When a `deftype` node is encountered, traverse its body to find any `(:where ...)` S-expression. The primary output of this step for a given `deftype` is the presence and content (or absence) of this clause. This subtask focuses only on detection, not analysis of the clause's content.",
          "status": "pending",
          "testStrategy": "Unit tests with various `deftype` AST snippets: some with `(:where)` clauses, some without, some with `(:where)` clauses in different positions or nested structures (if applicable to the language grammar) to ensure correct and robust detection. Verify that the detector correctly flags the presence/absence of `(:where)` and can extract the clause itself."
        },
        {
          "id": 3,
          "title": "Initial `(:where)` Clause Analysis for Effect Inference",
          "description": "Implement the initial, simplified logic to analyze `(:where ...)` clauses. For this initial version, any `deftype` containing one or more `(:where ...)` clauses will be considered potentially effectful, implying a potential `ConstructionFailure`. CIFs without `(:where)` clauses are considered pure.",
          "dependencies": [
            2
          ],
          "details": "Based on the detection from subtask 2: if one or more `(:where ...)` clauses are present in a `deftype` definition, the CIF is provisionally determined to have `POTENTIALLY_EFFECTFUL_CONSTRUCTION_FAILURE` status. If no `(:where)` clause is found, it's provisionally determined to be `PURE`. This step explicitly defers complex static analysis of the predicate within the `(:where)` clause, adhering to the 'assume all are runtime checks for now' constraint.",
          "status": "pending",
          "testStrategy": "Test with `deftype` examples. Input `deftype` ASTs (or relevant intermediate representations) to this analysis stage. If a `(:where)` clause was detected (by logic from subtask 2), the analysis output for the CIF should be 'effectful'. If absent, it should be 'pure'. This can be tested by checking an intermediate analysis result or log output."
        },
        {
          "id": 4,
          "title": "Store and Associate Inferred Purity/Effect Status with CIF Representation",
          "description": "Integrate the purity/effect status (determined in subtask 3) into the CIF's persistent representation using the data structure defined in subtask 1. This information must be reliably associated with the type definition for later use.",
          "dependencies": [
            1,
            3
          ],
          "details": "After analyzing a `deftype` (as per subtask 3), update the corresponding `TypeDefinition` object, symbol table entry, or other canonical representation of the CIF with the inferred `PurityStatus` (from subtask 1). Ensure this information is correctly stored and accessible throughout subsequent compilation phases where type information is used.",
          "status": "pending",
          "testStrategy": "After processing `deftype` definitions through the analysis pipeline (subtasks 2 and 3), inspect the internal representation of the types (e.g., via a debugger, dedicated test accessors, or by serializing type information). Verify that the correct `PurityStatus` has been stored for CIFs with and without `(:where)` clauses."
        },
        {
          "id": 5,
          "title": "Expose CIF Purity/Effect Status via Type System API",
          "description": "Provide a clear and well-defined API or mechanism for the type system and other compiler components (like the type checker or optimizer) to query the stored purity/effect status of any given CIF.",
          "dependencies": [
            4
          ],
          "details": "Add a method or accessor function to the type system's interface or to the type representation itself. For example, `TypeSystem.getCifPurity(typeId: TypeIdentifier) -> PurityStatus` or `TypeDefinition.getPurityStatus() -> PurityStatus`. This API will be the primary way other parts of the compiler access this inferred information.",
          "status": "pending",
          "testStrategy": "Unit tests for the new API. Create mock type definitions or use a test instance of the type system where CIFs have pre-set purity statuses (as if stored by subtask 4). Use the new API to retrieve these statuses and verify correctness. Test with types that have been analyzed and those that might not have (e.g., built-in types, if applicable, to ensure graceful handling)."
        }
      ]
    },
    {
      "id": 10,
      "title": "Dependent Types Implementation (Π-types and Σ-types)",
      "description": "Implement dependent function types (Π-types) and dependent pair/product types (Σ-types) in the type system and type checker.",
      "details": "Extend type representations: `PiType(var_name, var_type, body_type)`, `SigmaType(var_name, var_type, body_type)`. Update the type checker: For Π-types `(-> (x : A) (B x))`, when checking the function body `B x`, `x` is in scope with type `A`. For Σ-types `(Sigma (x : A) (B x))`, an instance is a pair `(a, b)` where `a : A` and `b : (B a)`. This requires the type checker to evaluate expressions at the type level (or use a distinct syntax for type-level computation if needed).",
      "testStrategy": "Define and type check functions using Π-types (e.g., a function returning a length-indexed vector `Vec A n`). Define and type check data structures using Σ-types (e.g., a pair where the type of the second element depends on the first `(Sigma (n : Nat) (Vec Bool n))`). Test with simple examples like `(deftype Vec ((A : Type) (n : Nat)) ...)` where `n` is used in constraints or structure.",
      "priority": "medium",
      "dependencies": [
        4
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Define AST Nodes and Internal Representation for Π-types and Σ-types",
          "description": "Extend the Abstract Syntax Tree (AST) and internal type representation to include `PiType(var_name, var_type, body_type)` and `SigmaType(var_name, var_type, body_type)`. This forms the foundational data structures for dependent types.",
          "dependencies": [],
          "details": "Define `PiType` structure: `var_name` (String/Identifier), `var_type` (Type Expression), `body_type` (Type Expression which may refer to `var_name`). Define `SigmaType` structure: `var_name` (String/Identifier), `var_type` (Type Expression), `body_type` (Type Expression which may refer to `var_name`). Ensure these new type structures integrate with existing type representations (e.g., as variants in an enum or subclasses). Consider how `var_name` will be bound within `body_type` (e.g., de Bruijn indices or explicit name binding).",
          "status": "done",
          "testStrategy": "Unit tests to verify the creation, structure, and properties (like free/bound variables) of `PiType` and `SigmaType` instances. Test serialization/deserialization if applicable."
        },
        {
          "id": 2,
          "title": "Implement Parser Extensions for Π-type and Σ-type Syntax",
          "description": "Update the language parser to recognize and correctly parse the syntax for Π-types (e.g., `(Pi (x : A) (B x))` or `(x : A) -> B x`) and Σ-types (e.g., `(Sigma (x : A) (B x))` or `(x : A) * B x`).",
          "dependencies": [
            1
          ],
          "details": "Define or confirm the concrete syntax for Π-types and Σ-types. Modify the parser grammar (e.g., LALR, PEG, or recursive descent) to incorporate these new syntactic forms. Ensure the parser constructs the correct `PiType` and `SigmaType` AST nodes defined in Subtask 1, capturing `var_name`, `var_type`, and `body_type` appropriately.",
          "status": "done",
          "testStrategy": "Parser tests with various valid syntax examples for Π-types and Σ-types, including nested dependent types. Test invalid syntax to ensure proper error reporting. Verify correct AST node generation."
        },
        {
          "id": 3,
          "title": "Implement Core Type-Level Substitution and Normalization Engine",
          "description": "Develop the foundational engine for substituting values (or value expressions) into type expressions and normalizing these expressions. This is essential for resolving dependencies in Π-types and Σ-types during type checking.",
          "dependencies": [
            1
          ],
          "details": "Implement `substitute(type_expr, var_name, value_expr)`: Replaces free occurrences of `var_name` in `type_expr` with `value_expr`. Must correctly handle variable capture (e.g., via alpha-conversion or de Bruijn indices). Implement `normalize(type_expr)`: Reduces a type expression to its normal form. This may involve evaluating parts of expressions that are known at compile-time (e.g., constants, simple arithmetic if allowed in types, or reducing beta-redexes if functions are allowed in types). Ensure this engine can operate on all type structures, including the new `PiType` and `SigmaType` (e.g., substitution under binders).",
          "status": "done",
          "testStrategy": "Unit tests for `substitute` with various scenarios: simple substitution, nested types, substitution under binders, and variable capture avoidance. Unit tests for `normalize` with expressions that should reduce to a canonical form and those already in normal form. Test with type expressions involving `PiType` and `SigmaType`."
        },
        {
          "id": 4,
          "title": "Implement Type Checking for Π-types (Dependent Functions)",
          "description": "Extend the type checker to handle formation, introduction (lambda abstraction), and elimination (application) rules for Π-types, utilizing the substitution and normalization engine.",
          "dependencies": [
            1,
            2,
            3
          ],
          "details": "Formation: For `(Pi (x : A) Bx)`, check that `A` is a valid type. Then, in a context extended with `x : A`, check that `Bx` is a valid type. Introduction (Lambda): For `lambda (x : A) . body`, type check `body` in a context extended with `x : A`. If `body : Bx`, the lambda has type `(Pi (x : A) Bx)`. Elimination (Application): For `f arg`, if `f : (Pi (x : A) Bx)` and `arg : A'`, check type equivalence of `A` and `A'`. The result type is `Bx` with `arg` substituted for `x`, followed by normalization: `normalize(substitute(Bx, x, arg))`. Update the typing environment/context management to handle the dependent variable `x` correctly.",
          "status": "done",
          "testStrategy": "Type checker tests for: valid dependent function definitions and type inference; valid dependent function applications and correct result type computation (using substitution); type errors for ill-formed Π-types, incorrect lambda bodies, and mismatched function arguments. Test scoping of the dependent variable."
        },
        {
          "id": 5,
          "title": "Implement Type Checking for Σ-types (Dependent Pairs)",
          "description": "Extend the type checker for formation, introduction (pair construction), and elimination (projections) of Σ-types, utilizing the substitution and normalization engine.",
          "dependencies": [
            1,
            2,
            3
          ],
          "details": "Formation: For `(Sigma (x : A) Bx)`, check that `A` is a valid type. Then, in a context extended with `x : A`, check that `Bx` is a valid type. Introduction (Pair): For a pair `(a, b)`, type check `a` to get type `A`. Then, type check `b`. Its type must be equivalent to `Bx` with `a` substituted for `x`, followed by normalization: `normalize(substitute(Bx, x, a))`. The pair `(a,b)` then has type `(Sigma (x : A) Bx)`. Elimination (Projections): If `p : (Sigma (x : A) Bx)`, then `proj1(p) : A`. And `proj2(p) : normalize(substitute(Bx, x, proj1(p)))`. Implement syntax and type checking for pair construction and projections.",
          "status": "done",
          "testStrategy": "Type checker tests for: valid dependent pair constructions and type inference; valid projections from dependent pairs and correct type computation for projections; type errors for ill-formed Σ-types, malformed pairs (e.g., second element's type doesn't match based on the first element's value). Test type equivalence involving substituted types."
        }
      ]
    },
    {
      "id": 11,
      "title": "Identity Types (`Id A x y`) and Path Equality (`refl`)",
      "description": "Implement Identity types `(Id A x y)` representing the proposition that `x` and `y` (of type `A`) are equal. Include the reflexivity constructor `refl`.",
      "details": "Introduce `Id` as a type constructor: `(Id A x y)` is a type. `A` is a type, `x` and `y` are terms of type `A`. Implement its constructor `refl : (-> (a : A) (Id A a a))`. The type checker must understand that `(Id A x y)` is a type and that `(refl z)` has type `(Id A z z)`. This is the first step towards path-based reasoning.",
      "testStrategy": "Define identity types for various base types `A`. Construct proofs of reflexivity, e.g., `(refl 5)` should have type `(Id Nat 5 5)`. Type check expressions involving `Id` types and `refl`. Test that `(Id Nat 1 2)` is a valid type, even if potentially uninhabited without further axioms.",
      "priority": "medium",
      "dependencies": [
        10
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Define AST Node and Parser Rule for `Id` Type Constructor",
          "description": "Introduce the `Id` type constructor `(Id A x y)` into the system's syntax and Abstract Syntax Tree (AST). This allows the system to recognize and represent identity types.",
          "dependencies": [],
          "details": "Modify the lexer and parser to recognize the `Id` keyword and its three arguments: `A` (the type), `x` (the left-hand term), and `y` (the right-hand term).\nDefine a new AST node type (e.g., `IdTypeNode`) to represent `(Id A x y)`. This node should store references or sub-nodes for `A`, `x`, and `y`.\nEnsure the parser correctly constructs this AST node from input expressions like `(Id Nat zero zero)`.",
          "status": "done",
          "testStrategy": "Write unit tests for the parser to verify that expressions of the form `(Id A x y)` are correctly parsed into the new `IdTypeNode` AST representation. Include tests for correct argument parsing and error handling for malformed `Id` expressions."
        },
        {
          "id": 2,
          "title": "Implement Type Checking Rule for `Id A x y`",
          "description": "Implement the type checking logic to validate that `(Id A x y)` is a well-formed type. This involves checking its components `A`, `x`, and `y`, and determining the universe of `(Id A x y)`.",
          "dependencies": [
            1
          ],
          "details": "In the type checker module, add a new rule or extend an existing one to handle `IdTypeNode`.\n1. Type check the `A` component. It must resolve to a type (e.g., `Type` or `Type_i` in a system with universes).\n2. Type check the `x` component. Let its inferred type be `A_x`.\n3. Type check the `y` component. Let its inferred type be `A_y`.\n4. Verify that `A_x` and `A_y` are judgmentally equal to `A` (the type specified in the `Id` expression).\n5. If all checks pass, the expression `(Id A x y)` itself is a type. It typically resides in the same universe as `A`, or a base universe like `Prop` if such a distinction exists (e.g., `Type` or `Prop`).",
          "status": "done",
          "testStrategy": "Write unit tests for the type checker focusing on `Id` types.\n- Test valid cases: `(Id Nat zero zero)` should be recognized as a type (e.g., `Type`).\n- Test invalid cases: `(Id Nat (lambda (x:Nat) x) zero)` where the second argument is not of type `Nat` but `Nat -> Nat`.\n- Test invalid cases: `(Id zero zero zero)` where the first argument `zero` is not a type."
        },
        {
          "id": 3,
          "title": "Define AST Node and Parser Rule for `refl` Constructor",
          "description": "Introduce the `refl` constructor `(refl x)` into the system's syntax and AST. This allows the system to recognize and represent proofs of reflexivity.",
          "dependencies": [
            1
          ],
          "details": "Modify the lexer and parser to recognize the `refl` keyword and its single argument `x`.\nDefine a new AST node type (e.g., `ReflNode`) to represent `(refl x)`. This node should store a reference or sub-node for the term `x`.\nEnsure the parser correctly constructs this AST node from input expressions like `(refl zero)`.",
          "status": "done",
          "testStrategy": "Write unit tests for the parser to verify that expressions of the form `(refl x)` are correctly parsed into the new `ReflNode` AST representation. Test with various term structures for `x`."
        },
        {
          "id": 4,
          "title": "Implement Type Checking Rule for `refl x`",
          "description": "Implement the type checking logic for the `refl` constructor. The term `(refl t)` should have the type `(Id A t t)`, where `A` is the type of `t`.",
          "dependencies": [
            2,
            3
          ],
          "details": "In the type checker module, add a new rule or extend an existing one to handle `ReflNode`.\n1. Type check the term `t` (from `(refl t)`). Let its inferred type be `A_inferred`.\n2. The type of the expression `(refl t)` is `(Id A_inferred t t)`.\n3. This involves constructing an `IdTypeNode` (or its internal representation) with `A = A_inferred`, left term = `t` (deep copy or reference), and right term = `t` (deep copy or reference).\nEnsure the type checker correctly forms this `Id` type as the result.",
          "status": "done",
          "testStrategy": "Write unit tests for the type checker focusing on `refl` terms.\n- Test valid cases: `(refl zero)` should type check to `(Id Nat zero zero)` (assuming `zero : Nat`).\n- Test valid cases: `(refl true)` should type check to `(Id Bool true true)` (assuming `true : Bool`).\n- Verify that the components of the resulting `Id` type (`A`, `t`, `t`) are correctly set."
        },
        {
          "id": 5,
          "title": "Integrate `Id` and `refl` and Add End-to-End Tests",
          "description": "Ensure `Id` types and `refl` terms are fully integrated into the type system. Write comprehensive tests demonstrating their interaction and usage in definitions and proofs.",
          "dependencies": [
            4
          ],
          "details": "Verify that `refl` terms can be assigned to variables or used in contexts expecting an `Id` type with matching parameters.\nExample: `(define p : (Id Nat 5 5) (refl 5))` should type check.\nTest error reporting for type mismatches, e.g., trying to assign `(refl 5)` to `(Id Nat 5 6)` or `(Id Bool 5 5)`.\nConsider how `Id` types and `refl` interact with other language features like function definitions, let-bindings, and (if applicable) pattern matching or dependent elimination rules for `Id` (though elimination is not part of this task).\nCreate a set of small programs or definitions that use `Id` and `refl` to ensure they work correctly within the broader system.",
          "status": "done",
          "testStrategy": "Develop end-to-end test files that include definitions and expressions using `Id` and `refl`.\n- Example 1: `(define reflexivity-of-zero : (Id Nat zero zero) (refl zero))`\n- Example 2: `(define generic-refl : (-> (A : Type) (x : A) (Id A x x)) (lambda (A_arg : Type) (lambda (x_arg : A_arg) (refl x_arg))))`\n- Test type inference where applicable.\n- Test error messages for incorrect usage in a larger context."
        }
      ]
    },
    {
      "id": 12,
      "title": "Effect Polymorphism for CIFs with Dependent Constraints",
      "description": "Enhance CIFs to support effect polymorphism based on dependent constraints, allowing them to be pure if a proof is available or effectful otherwise, as specified by `:constraint-proof` and `:performs-when-unproven`.",
      "details": "Extend `deftype` syntax: `(:constraint-proof (p : ProofType))` and `(:performs-when-unproven EffectToPerform)`. When a CIF is called: 1. Check if a proof for `ProofType` (often an `Id` type or a boolean proposition) is statically available (e.g., from type refinements of inputs, or given via `(:given proof-term)` at call site). 2. If proof is available, CIF is pure. 3. If proof is not available, CIF performs `EffectToPerform` (or `ConstructionFailure` if not specified). This requires the type system to handle proof terms and potentially rudimentary proof checking/inference. Example: `(deftype NonEmptyVec ((A : Type) (n : Nat)) (Array A) (:constraint-proof (p : (not (Id Nat n Nat.zero)))) (:performs-when-unproven ConstructionFailure))`.",
      "testStrategy": "Use the `NonEmptyVec` example from PRD. Test pure instantiation when `n` is statically non-zero (e.g., `(NonEmptyVec Int 1)`). Test effectful instantiation when `n` is a variable, requiring `try/catch`. Test providing an explicit proof via `(:given ...)`. Test with refined types like `Nat-Positive` that implicitly provide the proof, making the CIF pure.",
      "priority": "medium",
      "dependencies": [
        9,
        10,
        11
      ],
      "status": "pending",
      "subtasks": [
        {
          "id": 1,
          "title": "Extend `deftype` Syntax and AST for Constraint Proofs and Effects",
          "description": "Modify the language parser and Abstract Syntax Tree (AST) to support the new `:constraint-proof` and `:performs-when-unproven` clauses within `deftype` definitions for Custom Inductive Families (CIFs).",
          "dependencies": [],
          "details": "Update the parser (e.g., LALR grammar, recursive descent parser) for `deftype` to recognize `(:constraint-proof (p : ProofType))` and `(:performs-when-unproven EffectToPerform)`. Extend the AST nodes for CIF definitions to store the proof variable name (e.g., `p`), the `ProofType` (as an AST representation of a type), and the `EffectToPerform` (as an identifier or a special marker like `ConstructionFailure`). Ensure robust error handling for malformed syntax.",
          "status": "pending",
          "testStrategy": "Unit tests for the parser with various valid and invalid `deftype` definitions using the new clauses. Verify correct AST structure and error reporting."
        },
        {
          "id": 2,
          "title": "Type System Representation for `ProofType` and Proof Terms",
          "description": "Enhance the type system to represent, type-check, and validate `ProofType` expressions (e.g., `(Id Nat n Nat.zero)`, boolean propositions) specified in CIFs, and to handle associated proof terms.",
          "dependencies": [
            1
          ],
          "details": "Define internal representations for `ProofType` within the type checker, potentially recognizing specific patterns like `Id` types or general propositional types. Implement type checking for `ProofType` expressions themselves to ensure they are well-formed. Establish how proof terms are represented (e.g., as specific AST nodes or by leveraging existing term representations). If `Id` types are central (e.g., `(Id T a b)`), ensure they can be robustly handled as propositions.",
          "status": "pending",
          "testStrategy": "Unit tests for type-checking various `ProofType` expressions (e.g., valid, invalid, involving `Id` types). Tests for representing and potentially type-checking basic proof terms against simple `ProofType`s."
        },
        {
          "id": 3,
          "title": "Implement Static Proof Derivation from Type Refinements",
          "description": "Develop logic within the type checker to statically infer the availability of a proof for a CIF's `ProofType` based on type refinements of its input arguments at the call site.",
          "dependencies": [
            2
          ],
          "details": "When a CIF is called, retrieve its declared `ProofType` (from AST, understood by type system via Subtask 2). Substitute CIF type parameters in `ProofType` with actual types/values from the call. Analyze the types of the provided arguments, looking for refinements (e.g., `x : Nat where x > 0`). Implement a mechanism (e.g., a small SMT query interface, a set of specialized inference rules) to determine if the available refinements logically entail the `ProofType`. For example, if `ProofType` is `(not (Id Nat n Nat.zero))` and an argument `n_val` for `n` has a refined type implying `n_val != 0`, the proof is considered available.",
          "status": "pending",
          "testStrategy": "Test with CIF calls where proofs can be derived from argument refinements (e.g., `n > 0` implies `n != 0`). Test cases where proofs cannot be derived. Verify correct interaction with the type refinement system."
        },
        {
          "id": 4,
          "title": "Implement Handling of Explicit `(:given proof-term)` at Call Sites",
          "description": "Extend CIF call-site syntax and type-checking to support explicitly provided proof terms via `(:given proof-term)`, and validate these terms against the CIF's `ProofType`.",
          "dependencies": [
            2
          ],
          "details": "Modify the parser for function/CIF calls to accept an optional `(:given proof-term)` clause. Store the provided `proof-term` (as an AST expression) in the call-site AST node. During type checking of the CIF call, if `(:given proof-term)` is present: type-check the `proof-term` itself. Verify that the type of the `proof-term` is compatible with or proves the CIF's `ProofType` (after substituting CIF parameters, using `ProofType` understanding from Subtask 2). This constitutes the 'rudimentary proof checking' for explicit proofs. If valid, the proof is considered available.",
          "status": "pending",
          "testStrategy": "Test CIF calls with valid and invalid `(:given proof-term)` clauses. Test type checking of various proof terms against different `ProofType`s. Ensure correct parsing of the new call-site syntax."
        },
        {
          "id": 5,
          "title": "Integrate Proof Availability into Effect Typing for CIF Calls",
          "description": "Modify the CIF call resolution and effect typing mechanism to use the determined proof availability (from implicit derivation or explicit provision) to assign either a 'pure' effect or the specified `EffectToPerform` (or default `ConstructionFailure`).",
          "dependencies": [
            3,
            4
          ],
          "details": "At each CIF call site, invoke the proof availability checks: first, the static derivation from refinements (Subtask 3), then the check for an explicit `(:given proof-term)` (Subtask 4). If a proof is deemed available through either mechanism: the CIF call is assigned a 'pure' effect in the effect system. If no proof is available: the CIF call is assigned the effect specified by `:performs-when-unproven` in its `deftype`. If `:performs-when-unproven` is not specified, assign a default `ConstructionFailure` effect (this effect must be defined and handled by the effect system, possibly as a compile-time error if unhandled or a specific runtime exception). Ensure the overall type and effect inference system correctly propagates these conditional effects.",
          "status": "pending",
          "testStrategy": "End-to-end tests for CIFs with various constraint proofs. Test calls where proof is available (implicitly/explicitly), verifying pure effect. Test calls where proof is unavailable, verifying the specified effect (or `ConstructionFailure`). Verify interaction with the broader effect system and error reporting for unproven constraints leading to `ConstructionFailure`."
        }
      ]
    },
    {
      "id": 13,
      "title": "Universe Hierarchy Implementation (Type, Type 1, ...)",
      "description": "Implement a basic universe hierarchy (e.g., `Type` or `Type 0`, `Type 1`, ...) to consistently handle types as first-class citizens and avoid paradoxes like Girard's paradox.",
      "details": "Introduce universe types: `Type_i` (or `Type i`). `Type_i` is itself of type `Type_{i+1}`. All user-defined types, Π-types, Σ-types, Id-types will reside in some universe `Type_i`. The type checker must enforce universe consistency rules (e.g., `(-> A B)` is in `Type_k` if `A : Type_i`, `B : Type_j` and `k = max(i,j)` for non-dependent functions, more complex for dependent). Start with a simple hierarchy like `Type` (for ordinary types) and `Kind` (for `Type` itself), or `Type 0`, `Type 1`.",
      "testStrategy": "Define types that take other types as parameters (e.g., `(List Type)`). Verify that the type checker correctly assigns universe levels and reports errors for universe inconsistencies (e.g., a type trying to contain itself in a way that violates hierarchy).",
      "priority": "medium",
      "dependencies": [
        10
      ],
      "status": "done",
      "subtasks": [
        {
          "id": 1,
          "title": "Define `Type_i` AST Node and Implement `Type_i : Type_{i+1}` Rule",
          "description": "Introduce an Abstract Syntax Tree (AST) node for universe types, denoted as `Type_i` (e.g., `Ast.Universe(level: int)`). Implement the fundamental typing rule where `Type_i` is itself of type `Type_{i+1}`. This involves representing universe levels and their hierarchical relationship.",
          "dependencies": [],
          "details": "Create a new AST variant, `UniverseNode(level: int)`, to represent `Type_i`. In the type system, this node itself represents a type. The core logic to be implemented is that `typeof(UniverseNode(i))` is `UniverseNode(i+1)`. This might require special handling in the type inference or type checking mechanism for these universe type constructors. Assume levels are non-negative integers. Consider how `Type_{i+1}` is represented, especially if `i` could reach a maximum representable level (though an unbounded conceptual model is fine for initial implementation).",
          "status": "done",
          "testStrategy": "Unit tests: 1. Construct `Type 0` (e.g., `UniverseNode(0)`). Verify its inferred type is `Type 1` (e.g., `UniverseNode(1)`). 2. Construct `Type 1`, verify its type is `Type 2`. 3. Test the internal representation and equality of `UniverseNode` instances."
        },
        {
          "id": 2,
          "title": "Integrate `Type_i` into Core Type System and Basic Type Checking",
          "description": "Modify the language's core type representation to fully accommodate `Type_i` as a valid type. Update the type checker to recognize, infer types for, and check `Type_i` nodes, specifically enforcing the `Type_i : Type_{i+1}` rule during general type checking operations.",
          "dependencies": [
            1
          ],
          "details": "Ensure that `Type_i` (represented by `UniverseNode`) can appear in any context where a type is expected (e.g., type annotations, function signatures). The type checker's `infer_type(expression)` function should correctly return `UniverseNode(level+1)` when `expression` is `UniverseNode(level)`. The `check_type(expression, expected_type)` function must validate this relationship. This typically involves adding new cases to pattern matches over type structures within the type checker.",
          "status": "done",
          "testStrategy": "Unit tests: 1. Type check an expression `Type 0` and assert its inferred type is `Type 1`. 2. Type check `Type 5` and assert its inferred type is `Type 6`. 3. Test type equality comparisons involving `Type_i` (e.g., `Type 0 == Type 0` is true, `Type 0 == Type 1` is false). 4. Test type checking an ill-typed universe, e.g. `Type 0 : Type 0` should fail."
        },
        {
          "id": 3,
          "title": "Assign Default Universe Levels to User-Defined and Primitive Types",
          "description": "Establish a default universe level (typically `Type 0`) for all newly defined data types (e.g., `struct Point`, `enum Color`) and any built-in primitive types (e.g., `Int`, `Bool`, `String`). Update the type definition processing and type checker to assign and verify these base universe levels.",
          "dependencies": [
            2
          ],
          "details": "When a user defines a new type (e.g., `data MyType = ...`), it should be assigned to `Type 0` by default, meaning `MyType : Type 0`. The type checker must be aware of this when `MyType` is used as a type. For example, in `let x : MyType = ...`, the type checker verifies that `MyType` is indeed a type (i.e., it resides in some `Type_i`). This subtask primarily concerns types that are not themselves parameterized by other types that might affect their universe level. If primitive types exist, they should also be assigned to `Type 0` (e.g. `Int : Type 0`).",
          "status": "done",
          "testStrategy": "Unit tests: 1. Define a simple data type `Foo` and check that `typeof(Foo)` is `Type 0`. 2. If primitive types like `Integer` exist, check that `typeof(Integer)` is `Type 0`. 3. Test that using `Foo` as a type in a variable declaration (e.g., `let x : Foo = ...`) is valid and type checks correctly. 4. Test that a type definition itself is correctly recorded as being in `Type 0`."
        },
        {
          "id": 4,
          "title": "Implement Universe Level Calculation for Non-Dependent Function Types (Π-types)",
          "description": "Update the type checker to calculate and enforce the universe level for non-dependent function types (Π-types). The rule is: if `A -> B` is a function type, where `A : Type_i` and `B : Type_j`, then the type `(A -> B)` itself resides in `Type_{max(i,j)}`.",
          "dependencies": [
            3
          ],
          "details": "Modify the AST node for function types or the type checking logic for them. When type checking a function type constructor `T1 -> T2`: 1. Infer the types of `T1` and `T2`. These must be universe types, say `Type_i` and `Type_j` respectively (meaning `T1 : Type_i` and `T2 : Type_j`). 2. The type of the function type `(T1 -> T2)` is then `Type_{max(i,j)}`. This rule must be enforced. This applies when forming function types, e.g., `(Int -> Bool) : Type 0` because `Int : Type 0` and `Bool : Type 0`, so `max(0,0)=0`.",
          "status": "done",
          "testStrategy": "Unit tests: 1. Given `A : Type 0`, `B : Type 0`, check `(A -> B) : Type 0`. 2. Given `A : Type 0`, `B : Type 1` (where `Type 1` itself is a type, e.g. `Type : Type 1`), check `(A -> B) : Type 1`. 3. Given `A : Type 1`, `B : Type 0`, check `(A -> B) : Type 1`. 4. Test nested function types, e.g., `(A -> (B -> C))`. 5. Test type checking failure if a component type (e.g., `A` or `B`) is not a valid type (i.e., not in any `Type_k`)."
        },
        {
          "id": 5,
          "title": "Extend Universe Rules to Dependent Π-types, Σ-types, and Id-types",
          "description": "Extend universe level calculation and checking to dependent function types (Π-types where codomain type depends on a term of the domain type). Also, define and implement rules for Σ-types (dependent pairs) and Id-types (identity/equality types) if they are part of the language, ensuring they reside in appropriate universes.",
          "dependencies": [
            4
          ],
          "details": "For dependent function types `(x:A) -> B(x)`: if `A : Type_i` and for any term `a:A`, the type `B(a) : Type_j`, then the type `((x:A) -> B(x))` resides in `Type_{max(i,j)}`. This requires the type checker to handle type dependencies. For Σ-types `(x:A) * B(x)`: if `A : Type_i` and `B(a) : Type_j` for `a:A`, then `((x:A) * B(x)) : Type_{max(i,j)}`. For Id-types `Id A x y`: if `A : Type_i` (and `x,y:A`), then `(Id A x y) : Type_i`. These rules ensure all major type formers are consistently placed within the universe hierarchy. The focus should be on implementing the rule for dependent Π-types first, then others as applicable.",
          "status": "done",
          "testStrategy": "Unit tests: 1. For dependent Π-types: Define `A : Type 0`, and a type family `P : A -> Type 0`. Check `((x:A) -> P x) : Type 0`. 2. Define `A : Type 1`, `P : A -> Type 0`. Check `((x:A) -> P x) : Type 1`. 3. If Σ-types are implemented: `A : Type 0`, `B : A -> Type 0`. Check `((x:A) * B x) : Type 0`. 4. If Id-types are implemented: `A : Type 0`, `x:A`, `y:A`. Check `(Id A x y) : Type 0`. 5. Test cases that should fail due to universe inconsistencies in these dependent type formers."
        }
      ]
    },
    {
      "id": 14,
      "title": "Basic Module System (Import/Export, Namespacing)",
      "description": "Implement a basic module system for namespace management, allowing definitions to be organized into modules and selectively imported/exported.",
      "details": "Syntax for defining modules: `(module ModuleName (export symbol1 symbol2) body...)`. Syntax for importing: `(import ModuleName)` or `(import ModuleName (only symbol1) (prefix p-))`. The evaluator and type checker need to respect module boundaries and resolve symbols accordingly. Each module should have its own environment, linked to imported modules.",
      "testStrategy": "Create multiple module files. Define types and functions in one module, export some. Import them into another module and use them. Test for name collisions and how they are handled (e.g., qualified names or errors). Test different import syntaxes (full import, selective import, prefixed import).",
      "priority": "medium",
      "dependencies": [
        6
      ],
      "status": "pending",
      "subtasks": [
        {
          "id": 1,
          "title": "Extend Parser for Module and Import Syntax",
          "description": "Modify the language parser to correctly recognize and parse `(module ModuleName (export ...) body...)` and `(import ModuleName ...)` expressions, generating corresponding Abstract Syntax Tree (AST) nodes.",
          "dependencies": [],
          "details": "Update the lexical analyzer (if necessary) and parser rules. Define new AST node types for `ModuleDefinition` (capturing module name, export list, and body expressions) and `ImportStatement` (capturing the module to import, an optional `only` list of symbols, and an optional `prefix` string). Ensure the parser can handle variations in export lists (e.g., empty, single, multiple symbols) and import options.",
          "status": "pending",
          "testStrategy": "Create unit tests for the parser with various valid module definitions and import statements, including different forms of export lists and import options (`only`, `prefix`). Test parsing of malformed module/import syntax to ensure proper error reporting and recovery if applicable."
        },
        {
          "id": 2,
          "title": "Implement Module Representation and Registry",
          "description": "Define data structures for representing modules, their environments, and exported symbols. Implement a global registry to manage and access defined modules.",
          "dependencies": [
            1
          ],
          "details": "Create a `Module` class or struct. This structure should contain: its name (string), a dedicated `Environment` instance (which can chain to a global environment or other imported module environments), a list or map of its exported symbols (mapping exported names to their actual values/definitions within the module), and the parsed AST of its body. Implement a `ModuleRegistry` (e.g., a singleton class or a global hash map) to store `Module` instances indexed by their names. This registry will be used to resolve module names during import and to prevent or manage redefinition of modules.",
          "status": "pending",
          "testStrategy": "Unit tests for `Module` creation, adding definitions to a module's internal environment, marking symbols as exported (storing necessary information to resolve them later), and retrieving modules by name from the `ModuleRegistry`. Test behavior for attempting to define duplicate module names."
        },
        {
          "id": 3,
          "title": "Process Module Definitions and Handle Exports",
          "description": "Implement the logic to process parsed `ModuleDefinition` AST nodes. This involves creating a new module instance, evaluating its body within its specific environment, and populating its export list based on the `(export ...)` clause.",
          "dependencies": [
            2
          ],
          "details": "When the evaluator encounters a `ModuleDefinition` AST node: \n1. Create a new `Module` instance using the parsed name and body.\n2. Register this new module in the `ModuleRegistry`.\n3. Create a new, isolated `Environment` for this module. This environment should be used for evaluating the module's body.\n4. Evaluate the expressions in the module's `body` within this new module-specific environment.\n5. After evaluation, for each symbol listed in the `(export ...)` clause, verify it's defined in the module's environment. If so, add it to the module's list/map of accessible exports (e.g., storing a mapping from the exported name to its evaluated value or definition within the module's environment).",
          "status": "pending",
          "testStrategy": "Test defining modules with various simple and complex bodies. Verify that only symbols specified in the `(export ...)` clause are marked as exported by the module object. Test error handling for exporting symbols that are not defined within the module's body. Ensure symbols defined within a module are encapsulated and not accessible globally unless explicitly exported and then imported."
        },
        {
          "id": 4,
          "title": "Implement Import Statement Processing",
          "description": "Implement the logic to process parsed `ImportStatement` AST nodes, making exported symbols from one module available in the current (importing) module's environment, respecting `(only ...)` and `(prefix ...)` clauses.",
          "dependencies": [
            3
          ],
          "details": "When the evaluator encounters an `ImportStatement` AST node within the context of a current (importing) module or top-level environment:\n1. Resolve the target module name specified in the import statement by looking it up in the `ModuleRegistry`. Handle errors if the module is not found.\n2. Retrieve the target module's list of exported symbols.\n3. For each exported symbol from the target module:\n    a. If an `(only symbol1 ...)` clause is present in the import statement, only consider symbols that are explicitly listed in this `only` clause.\n    b. Determine the name to be used for the symbol in the importing environment: if a `(prefix p- ...)` clause is present, prepend the specified prefix to the original symbol name. Otherwise, use the original symbol name.\n    c. Add a binding for this (potentially filtered and prefixed) name into the importing module's environment. This binding should effectively link to the original definition in the imported module's environment (e.g., by copying the value, creating an alias, or a thunk that resolves to the original).",
          "status": "pending",
          "testStrategy": "Test various import scenarios: importing all symbols from a module, importing a subset of symbols using `(only ...)` clause, importing symbols with a `(prefix ...)` clause, and combinations of `only` and `prefix`. Test error conditions such as importing from a non-existent module, attempting to import a non-exported symbol (if `only` specifies it), or name collisions if not handled by prefixing."
        },
        {
          "id": 5,
          "title": "Integrate Module System into Evaluator and Type Checker",
          "description": "Update the symbol resolution logic in the language's evaluator and type checker to be module-aware. This means respecting the current module's environment, its imports, and ensuring proper encapsulation.",
          "dependencies": [
            4
          ],
          "details": "Modify the core symbol lookup mechanisms:\n*   **Evaluator**: When resolving a symbol, the evaluator must first search the local environment of the current module. If the symbol is not found locally, it should then search through the symbols imported into the current module (respecting any prefixes or `only` restrictions applied during import). The evaluator needs to maintain a concept of the \"current module context\" during execution.\n*   **Type Checker**: Similarly, the type checker's symbol resolution for type lookups and variable type inference must follow the same module-aware path: local module environment first, then imported symbols. Type checking of a module's body should occur within its own isolated scope, considering its imports.\n*   Define how top-level definitions (code not explicitly within a `(module ...)` form) are handled. They might be placed in a default global module, or all code might be required to reside within modules.\n*   Ensure that the evaluation of a module body (during `(module ...)` processing) and import statements correctly sets and restores the current module context.",
          "status": "pending",
          "testStrategy": "Develop end-to-end tests. These tests should involve defining multiple modules, exporting and importing symbols between them using various options (`only`, `prefix`). Evaluate expressions and perform type checking on code that utilizes these cross-module symbols. Verify correct symbol resolution, proper type inference across module boundaries, and strict enforcement of encapsulation (e.g., inability to access non-exported symbols from another module directly)."
        }
      ]
    },
    {
      "id": 15,
      "title": "Hygienic Macro System (Initial Implementation)",
      "description": "Implement an initial version of a hygienic macro system, allowing users to define syntactic abstractions using `define-syntax` and syntax rules, following Scheme principles.",
      "details": "Implement `(define-syntax keyword (syntax-rules (literals...) ((pattern) template) ...))`. The macro expander should run after parsing but before type checking/evaluation. Focus on achieving hygiene to prevent accidental variable capture. This involves careful handling of symbols and their lexical contexts during macro expansion.",
      "testStrategy": "Define simple macros like `when`, `unless`, `let*` (if `let` is basic). Test macro expansion to ensure correct output AST. Crucially, test for hygiene: define macros that introduce bindings and use them in contexts where those binding names might clash with existing variables, verifying that the macro's bindings do not capture or shadow unintended variables.",
      "priority": "medium",
      "dependencies": [
        1
      ],
      "status": "pending",
      "subtasks": [
        {
          "id": 1,
          "title": "Extend Parser for `define-syntax` and `syntax-rules`",
          "description": "Modify the language's parser to recognize and correctly parse `define-syntax` forms. This includes parsing the `syntax-rules` structure, capturing the macro keyword, the list of literal identifiers, and the set of pattern-template rules.",
          "dependencies": [],
          "details": "Update the grammar to include `define-syntax` as a new top-level form or special form. The parser should produce an Abstract Syntax Tree (AST) node specifically representing a macro definition. This AST node must clearly delineate: 1. The keyword (symbol) being defined as a macro. 2. The list of literal symbols specified in `(literals...)`. 3. An ordered list of rules, where each rule is a pair of (pattern, template). Ensure the parser can handle nested structures within patterns and templates (e.g., nested lists, multiple pattern variables).",
          "status": "pending",
          "testStrategy": "Unit test the parser with various valid `define-syntax` expressions, including those with empty/non-empty literal lists, single/multiple rules, and complex nested patterns/templates. Also test with malformed `define-syntax` expressions to ensure proper error reporting."
        },
        {
          "id": 2,
          "title": "Implement Macro Definition Storage and Retrieval",
          "description": "Develop a system for storing parsed macro definitions and retrieving them when a potential macro invocation is encountered. This system will act as a compile-time macro environment.",
          "dependencies": [
            1
          ],
          "details": "Design a data structure (e.g., a hash map or a dedicated environment structure) to store macro definitions. This structure will map macro keywords (symbols) to their parsed `syntax-rules` objects (as produced by subtask 1). Implement functions to: 1. Add a new macro definition to this storage when a `define-syntax` form is processed. 2. Look up a macro definition by its keyword. This lookup will be used by the macro expander. The storage should be managed appropriately within the compilation phases.",
          "status": "pending",
          "testStrategy": "Unit test the storage mechanism by adding various macro definitions and then attempting to retrieve them. Test cases should include retrieving existing macros, attempting to retrieve non-existent macros (should return a clear 'not found' indication), and potentially re-defining macros (if allowed by the language semantics)."
        },
        {
          "id": 3,
          "title": "Implement `syntax-rules` Pattern Matching and Template Instantiation",
          "description": "Implement the core logic for `syntax-rules` expansion. This involves matching an input syntax form against the patterns of a macro's rules and, upon a successful match, instantiating the corresponding template.",
          "dependencies": [
            2
          ],
          "details": "Implement a pattern matcher that supports: \n- Identifiers as pattern variables (capturing parts of the input syntax).\n- Literal identifiers (as specified in the `literals...` list of `syntax-rules`), which must match exactly.\n- The underscore `_` as a wildcard pattern that matches anything without binding it.\n- The ellipsis `...` for matching zero or more occurrences of a preceding sub-pattern.\n- Nested list/vector patterns.\nImplement template instantiation logic that:\n- Substitutes pattern variables with the syntax they captured.\n- Handles ellipsis `...` in templates to correctly structure output based on sequence captures.\n- Reconstructs the output syntax (AST) based on the template. Initially, this can be non-hygienic, focusing on structural transformation.",
          "status": "pending",
          "testStrategy": "Unit test the pattern matcher and template instantiator with a variety of macro rules and input forms. Test cases should cover: simple matches, literal matching, wildcard usage, ellipsis matching (zero, one, multiple elements), nested patterns, and correct template instantiation with variable substitution and ellipsis expansion. Test error conditions like no matching rule."
        },
        {
          "id": 4,
          "title": "Implement Hygiene Mechanism for Macro Expansion",
          "description": "Introduce hygiene into the macro expansion process to prevent accidental variable capture. This ensures that identifiers maintain their correct lexical scope across macro expansion boundaries.",
          "dependencies": [
            3
          ],
          "details": "Choose and implement a hygiene algorithm (e.g., automatic renaming based on lexical context, or syntax objects carrying lexical information). \nKey aspects:\n1. When a macro expands, identifiers introduced by the macro's template (not originating from pattern variables) must be treated as if they were defined in the macro definition's lexical environment. This typically involves 'coloring' or 'tagging' symbols with their lexical context or renaming them to be unique.\n2. Identifiers captured by pattern variables from the macro call site must retain their original call-site lexical meaning.\n3. Literal identifiers in patterns should be compared based on their symbolic identity within their respective lexical contexts.\nThis subtask modifies the template instantiation part of subtask 3 to incorporate hygiene.",
          "status": "pending",
          "testStrategy": "Test with classic hygiene-testing macros. Examples:\n- A macro defining a local variable `x` and using it, ensuring it doesn't capture an `x` from the call site.\n- A macro using a free variable `y` (expected to be bound in the macro definition's scope), ensuring it doesn't accidentally pick up a `y` from the call site.\n- Macros that pass syntax containing free variables to other macros."
        },
        {
          "id": 5,
          "title": "Integrate Macro Expander into Compilation Pipeline",
          "description": "Integrate the hygienic macro expander into the overall compilation/evaluation pipeline. The expander should operate on the AST after parsing and before subsequent phases like type checking or evaluation.",
          "dependencies": [
            1,
            4
          ],
          "details": "Modify the compiler/interpreter's main workflow to include a macro expansion phase. This phase takes the AST produced by the parser (subtask 1) as input.\nImplement a traversal mechanism (e.g., a tree walk) over the AST. When a form that could be a macro call is encountered:\n1. Look up the identifier in the macro definition storage (from subtask 2).\n2. If it's a macro, invoke the hygienic expansion logic (from subtask 4).\n3. Replace the original macro call AST node with the expanded AST node.\n4. Recursively expand the resulting syntax, as macro expansions can produce new macro calls.\nThe expansion process continues until no more macro calls are present in the AST. The fully expanded AST is then passed to the next compilation stage (e.g., semantic analysis, type checking, or code generation/evaluation). Ensure `define-syntax` itself is handled correctly by this phase (i.e., it defines a macro rather than being expanded further).",
          "status": "pending",
          "testStrategy": "End-to-end tests using small programs that define and use one or more hygienic macros. Verify that the program's behavior after macro expansion is correct and that hygiene is maintained. Check interactions between multiple macros. Ensure the expander correctly processes top-level `define-syntax` forms and then uses those definitions for subsequent expansions."
        }
      ]
    },
    {
      "id": 16,
      "title": "Pattern Matching for Product and Sum Types",
      "description": "Implement a pattern matching system for destructuring product types (field access) and matching sum type variants, including syntax parsing, match expression evaluation, and type checker integration for exhaustiveness and type safety.",
      "details": "Develop a comprehensive pattern matching facility. This involves:\n1.  **Syntax Definition and Parsing**:\n    *   Define the S-expression syntax for `match` expressions, e.g., `(match <scrutinee-expr> (<pattern1> <body1>) ... (<patternN> <bodyN>))_`.\n    *   Define pattern syntax for: literals (e.g., `10`, `#t`, `\"hello\"`), variables (e.g., `x`), wildcard (`_`), product type destructuring (e.g., `(Point x y)`), and sum type variant matching (e.g., `(Some val)`, `(Left err)`).\n    *   Extend the existing S-expression parser (from Task 1) to produce AST nodes for `MatchExpression` and various `Pattern` types (e.g., `LiteralPattern`, `VariablePattern`, `WildcardPattern`, `ConstructorPattern`).\n2.  **Match Expression Evaluation**:\n    *   Implement the evaluation logic for `match` expressions.\n    *   The scrutinee expression is evaluated first.\n    *   Patterns are tried in the order they appear.\n    *   For the first matching pattern: \n        *   Bind any variables introduced by the pattern to the corresponding parts of the scrutinee's value.\n        *   Evaluate the associated body expression in an environment extended with these new bindings.\n    *   If no pattern matches, a runtime error should be raised (unless compile-time exhaustiveness checks prevent this scenario).\n3.  **Type Checker Integration**:\n    *   Extend the type checker (Task 4) to analyze `match` expressions.\n    *   **Type of Scrutinee**: The type of the scrutinee expression must be determined.\n    *   **Pattern Typing**: Each pattern must be type-compatible with the scrutinee's type. For constructor patterns, the constructor must belong to the scrutinee's type (if it's a sum type) or be the type itself (for product types).\n    *   **Variable Binding Types**: Infer types for variables bound within patterns. E.g., if matching `(Point x y)` against a `Point` type where `x` and `y` are `Nat`, then `x` and `y` are typed as `Nat` in the body.\n    *   **Body Typing**: Each body expression is type-checked in its extended environment. All bodies in a single `match` expression must have a common, compatible type, which becomes the type of the `match` expression itself.\n    *   **Exhaustiveness Checking**: The type checker must verify that the set of patterns for a given scrutinee type is exhaustive. \n        *   For sum types (defined via `deftype` from Task 5), all variants must be covered, or a wildcard pattern must be present.\n        *   For `Bool`, patterns for `#t` and `#f` (or a wildcard) are needed.\n        *   Report a compile-time error if a `match` expression is found to be non-exhaustive.\n    *   **Unreachability**: Optionally, warn about or disallow unreachable patterns (e.g., a pattern following a wildcard).\n4.  **Interaction with `deftype` (Task 5)**:\n    *   The pattern matching system must use the definitions of product and sum types created by `deftype`. This includes knowing the fields of product types and the variants of sum types to perform destructuring and exhaustiveness checks correctly.",
      "testStrategy": "1.  **Parser Tests**:\n    *   Verify correct parsing of `match` expressions with various patterns: literals, variables, wildcards, product constructors, sum variant constructors, nested patterns.\n    *   Test syntax errors for malformed `match` expressions or patterns.\n2.  **Evaluation Tests**:\n    *   Test successful matching and value destructuring for product types.\n    *   Test successful matching for different sum type variants.\n    *   Verify correct variable bindings from patterns are available in the body.\n    *   Confirm that the correct body is evaluated based on the first matching pattern.\n    *   Test wildcard pattern behavior.\n    *   Test runtime error for non-exhaustive matches if not caught by the type checker (e.g., if checking is disabled or for dynamic scenarios).\n3.  **Type Checking Tests**:\n    *   **Pattern Compatibility**: Test that patterns incompatible with the scrutinee's type are rejected (e.g., matching a `Nat` with a `Point` pattern).\n    *   **Variable Type Inference**: Verify types of variables bound in patterns are correctly inferred and used for type checking bodies.\n    *   **Body Type Consistency**: Ensure all bodies in a `match` expression conform to a common type. Test cases where body types differ and should result in an error.\n    *   **Exhaustiveness Checking**: \n        *   Sum types: Test with full coverage of variants, partial coverage (error), and coverage with a wildcard.\n        *   `Bool`: Test with `#t`, `#f` patterns; `#t` only (error); `#t`, `_` (ok).\n        *   Product types: Test destructuring patterns.\n    *   **Type Safety**: Ensure that using a bound variable with an incorrect type within a clause body results in a type error.\n4.  **Integration Tests with `deftype`**:\n    *   Define several product and sum types using `deftype`.\n    *   Write complex `match` expressions using these types, involving nested patterns and multiple clauses.\n    *   Verify correct evaluation, full type checking (including exhaustiveness), and error reporting.",
      "status": "done",
      "dependencies": [
        4,
        5
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Define AST Nodes and Extend Parser for Match Expressions and Patterns",
          "description": "Define the Abstract Syntax Tree (AST) nodes for `MatchExpression` and various `Pattern` types (Literal, Variable, Wildcard, Constructor). Extend the existing S-expression parser (from Task 1) to parse the `(match ...)` syntax and pattern syntax into these AST nodes.",
          "dependencies": [],
          "details": "Define `MatchExpression` AST node: `(scrutinee: Expr, cases: List[(Pattern, Expr)])`. Define `Pattern` AST hierarchy: `LiteralPattern(value: LiteralValue)`, `VariablePattern(name: String)`, `WildcardPattern()`, `ConstructorPattern(constructorName: String, subPatterns: List[Pattern])`. The parser should handle S-expression syntax like `(match <scrutinee-expr> (<pattern1> <body1>) ... (<patternN> <bodyN>))` and patterns such as `10`, `#t`, `\"hello\"`, `x`, `_`, `(Point x y)`, `(Some val)`. Ensure the parser correctly integrates with existing AST structures and error reporting.",
          "status": "done",
          "testStrategy": "Unit test the parser with various valid and invalid `match` expressions and pattern syntaxes. Verify correct AST node generation and appropriate error messages for syntax errors."
        },
        {
          "id": 2,
          "title": "Implement Core Match Expression Evaluation Logic",
          "description": "Implement the runtime evaluation mechanism for `MatchExpression` AST nodes. This includes evaluating the scrutinee, iterating through patterns in order, performing matching for literals, variables, and wildcards, binding variables to an extended environment, and executing the corresponding body. If no pattern matches, a runtime error should be raised.",
          "dependencies": [
            1
          ],
          "details": "Implement `eval_match(match_expr, env)`: 1. Evaluate `match_expr.scrutinee` in `env` to get `scrutinee_value`. 2. Iterate through `match_expr.cases`. For each `(pattern, body)`: a. Implement `match_pattern(pattern, scrutinee_value)` which returns `Option[Map[String, Value]]` representing new bindings. Initially, support `LiteralPattern` (compare value), `VariablePattern` (binds scrutinee_value to variable name), `WildcardPattern` (always matches, no bindings). b. If match succeeds, create `extended_env` from `env` plus new bindings. Evaluate `body` in `extended_env` and return result. 3. If loop finishes with no match, raise a runtime error (e.g., \"Non-exhaustive match error\"). `ConstructorPattern` matching logic will be fully developed in a later subtask (ID 5), but basic name matching could be stubbed if necessary.",
          "status": "done",
          "testStrategy": "Test evaluation with `match` expressions involving literals, variables, and wildcards. Verify correct body execution, variable binding within the body's scope, and proper return values. Test non-matching scenarios to ensure runtime errors are raised."
        },
        {
          "id": 3,
          "title": "Integrate Match Expressions into Type Checker: Scrutinee, Basic Pattern, and Body Typing",
          "description": "Extend the type checker (Task 4) to analyze `MatchExpression` AST nodes. This involves: determining the scrutinee's type; type checking basic patterns (Literal, Variable, Wildcard) against the scrutinee's type; inferring types for variables bound in these simple patterns; and ensuring all bodies in a single `match` expression have a common, compatible type, which becomes the type of the `match` expression.",
          "dependencies": [
            1
          ],
          "details": "Implement `typecheck_match(match_expr, type_env)`: 1. Typecheck `match_expr.scrutinee` to get `scrutinee_type`. 2. For each `(pattern, body)`: a. Implement `typecheck_pattern(pattern, scrutinee_type, type_env)` for basic patterns: `LiteralPattern` (literal's type must be compatible with `scrutinee_type`), `VariablePattern` (variable is typed as `scrutinee_type`; add to `extended_type_env`), `WildcardPattern` (compatible with any type, no new bindings). b. Typecheck `body` in the `extended_type_env` (derived from `type_env` plus pattern bindings) to get `body_type`. 3. Collect all `body_type`s. Compute their least common supertype (LUB). This LUB is the type of the `match` expression. If no LUB exists (incompatible body types), report a type error. `ConstructorPattern` type checking will be fully developed in a later subtask (ID 5).",
          "status": "done",
          "testStrategy": "Unit test type checking for `match` expressions with simple patterns. Verify correct type inference for the overall expression and for variables bound by patterns. Test type mismatches (e.g., literal pattern vs. scrutinee type, incompatible body types) to ensure errors are reported."
        },
        {
          "id": 4,
          "title": "Implement Exhaustiveness and Unreachability Checks in Type Checker",
          "description": "Enhance the type checker to perform exhaustiveness checks for `match` expressions, reporting a compile-time error if a match is not exhaustive. This primarily applies to sum types (defined via `deftype` from Task 5) and booleans. Optionally, implement unreachability checks for patterns (e.g., a pattern following a wildcard).",
          "dependencies": [
            3
          ],
          "details": "Extend `typecheck_match` or add a separate pass: 1. **Exhaustiveness Checking**: `check_exhaustiveness(patterns, scrutinee_type, type_definitions_from_Task5)`: a. If `scrutinee_type` is `Bool`, check if patterns cover `#t` and `#f`, or if a wildcard `_` is present. b. If `scrutinee_type` is a sum type, retrieve its variants from `type_definitions_from_Task5`. Check if all variants are covered by `ConstructorPattern`s or if a wildcard `_` is present. c. If not exhaustive, report a compile-time error. 2. **Unreachability Checking (Optional)**: `check_unreachability(patterns)`: Analyze patterns in sequence. If a pattern `P_i` is found to be unreachable because preceding patterns `P_1 ... P_{i-1}` cover all cases `P_i` could match, issue a warning or compile-time error. For example, any pattern after `_` or `x` (variable pattern of the same type) is unreachable.",
          "status": "done",
          "testStrategy": "Test exhaustiveness checking with various sum types (from `deftype`) and boolean scrutinees. Verify that non-exhaustive matches are caught at compile time. Test cases with and without wildcard patterns. If implementing unreachability, test scenarios with redundant or clearly unreachable patterns."
        },
        {
          "id": 5,
          "title": "Implement Constructor Pattern Destructuring and Full Type System Integration",
          "description": "Fully implement pattern matching for product type destructuring (e.g., `(Point x y)`) and sum type variant matching (e.g., `(Some val)`). This involves refining both evaluation (`match_pattern`) and type checking (`typecheck_pattern`) to correctly handle `ConstructorPattern`s, using type definitions from `deftype` (Task 5) for field/variant names, arity, and types of sub-patterns/payloads.",
          "dependencies": [
            2,
            4
          ],
          "details": "1. **Refine Evaluation (`match_pattern` for `ConstructorPattern`)**: a. For product types: Check constructor name matches type name, arity matches field count. Recursively match sub-patterns against field values. b. For sum types: Check constructor name matches variant tag, arity matches variant payload. Recursively match sub-patterns against payload values. Aggregate bindings from sub-matches. 2. **Refine Type Checking (`typecheck_pattern` for `ConstructorPattern`)**: a. Use `type_definitions_from_Task5` to get info about product type fields or sum type variants. b. For product types: Verify constructor name is the type name, arity matches. For each sub-pattern and corresponding field type, recursively call `typecheck_pattern` and add inferred bindings to `extended_type_env`. c. For sum types: Verify constructor name is a valid variant of `scrutinee_type`, arity matches. For each sub-pattern and corresponding variant parameter type, recursively call `typecheck_pattern` and add inferred bindings. This ensures variables bound within constructor patterns (e.g., `x`, `y` in `(Point x y)`) receive their correct types for use in the body.",
          "status": "done",
          "testStrategy": "Test with various product and sum types defined via `deftype`. Verify correct destructuring of values and variable binding during evaluation. Verify correct type inference for variables bound within constructor patterns. Test error conditions like arity mismatches, incorrect constructor names, and type errors within sub-patterns."
        }
      ]
    },
    {
      "id": 17,
      "title": "Implement Core Standard Library (Nat, Bool, Option, List)",
      "description": "Implement the core standard library types: `Nat`, `Bool`, `List`, and `NonEmptyList`. This task focuses on establishing essential, safe, and robust building blocks for practical programming in PathFinder LISP, aligned with a HoTT/dependent types philosophy. Key aspects include defining types with `deftype`, using the effect system for partial functions (explicitly eliminating the need for `Option` types), and leveraging the proof-carrying `NonEmptyList` type for safe head/tail access.",
      "status": "done",
      "dependencies": [
        4,
        5
      ],
      "priority": "high",
      "details": "This task involves defining the core data types for the PathFinder LISP standard library, with an emphasis on totality and safety.\n\n**General Requirements:**\n- All specified types (Nat, Bool, List T, NonEmptyList T) must be defined using the `deftype` mechanism (from Task 5).\n- Canonical Instantiation Functions (CIFs) for each type and its variants (e.g., `NECons` for `NonEmptyList`, `Cons` for `List`) should be available as per the `deftype` specification.\n- Operations and functions for these types should be implemented as PathFinder LISP functions and must be type-checked by the system's type checker (from Task 4).\n- Partial functions like `subtract` must use the language's effect system for error handling instead of returning an option type.\n- The `deftype` mechanism must support parameterized types (e.g., `List T`) and recursive type definitions (e.g., `List T`, Peano `Nat`).\n\n**Type Definitions and Operations:**\n\n1.  **Nat (Natural Numbers):**\n    *   Definition: `(deftype Nat (Zero) (Succ Nat))` (Peano representation).\n    *   CIFs: `Zero`, `Succ`.\n    *   Operations:\n        *   `isZero?: Nat -> Bool`\n        *   `add: Nat Nat -> Nat`\n        *   `subtract: Nat Nat -> Nat` (This is a partial function. If subtraction results in a negative number, it should trigger a 'DomainError' effect rather than returning a value.)\n        *   `equals?: Nat Nat -> Bool`\n        *   `lessThan?: Nat Nat -> Bool`\n\n2.  **Bool (Booleans):**\n    *   Definition: `(deftype Bool (PFalse) (PTrue))`.\n    *   CIFs: `PFalse`, `PTrue`.\n    *   Operations:\n        *   `and: Bool Bool -> Bool`\n        *   `or: Bool Bool -> Bool`\n        *   `not: Bool -> Bool`\n\n3.  **List T (Lists):**\n    *   Definition: `(deftype (List T) (Nil) (Cons T (List T)))` (Parameterized, recursive sum type).\n    *   CIFs: `Nil`, `Cons`.\n    *   Operations:\n        *   `isEmpty?: (List T) -> Bool`\n        *   `append: (List T) (List T) -> (List T)`\n        *   `length: (List T) -> Nat`\n        *   `mapList: (List T) (T -> U) -> (List U)`\n        *   `filterList: (List T) (T -> Bool) -> (List T)`\n        *   `foldLeft: (List T) U ((U T) -> U) -> U`\n        *   `reverse: (List T) -> (List T)`\n\n4.  **NonEmptyList T (Proof-Carrying Lists):**\n    *   Definition: `(deftype (NonEmptyList T) (NECons T (List T)))` (A non-empty head followed by a standard list).\n    *   CIFs: `NECons`.\n    *   Operations (These are total functions on `NonEmptyList`):\n        *   `head: (NonEmptyList T) -> T`\n        *   `tail: (NonEmptyList T) -> (List T)`\n\n**Implementation Considerations:**\n-   The definitions should be placed in a standard library module that can be automatically loaded or easily imported.\n-   Ensure the effect handling for `subtract` is correctly implemented and can be caught by an appropriate handler.\n-   Programs should be encouraged to pattern match on `List T` to distinguish between the `Nil` case and the `(Cons h t)` case, which can then be used to construct a `(NonEmptyList T)` for safe use with `head` and `tail`.",
      "testStrategy": "Testing will involve unit tests for each type and its operations, focusing on CIFs, functional correctness, type checking, and edge cases.\n\n**1. Nat Tests:**\n    - Verify `(Zero)` and `(Succ ...)` create `Nat` values.\n    - Test `isZero?` on `Zero` and non-zero numbers.\n    - Test `add` with various combinations.\n    - Test `subtract`: verify correct results for N >= M. For N < M, verify that the appropriate 'DomainError' effect is triggered.\n    - Test `equals?` and `lessThan?` with various pairs.\n    - Type checking: `(add Zero PTrue)` should be a type error.\n\n**2. Bool Tests:**\n    - Verify `(PFalse)` and `(PTrue)` create `Bool` values.\n    - Test `and`, `or`, `not` with all input combinations.\n    - Type checking: `(and PTrue Zero)` should be a type error.\n\n**3. List T Tests:**\n    - Verify `(Nil)` and `(Cons val list)` create `List` values (e.g., `(List Nat)`).\n    - Test `isEmpty?` on `(Nil)` and non-empty lists.\n    - Test `append` with empty lists and non-empty lists.\n    - Test `length` for various list sizes.\n    - Test `mapList`, `filterList`, `foldLeft`, `reverse` with various inputs: empty lists, single-element lists, multiple-element lists.\n    - Type checking: `(Cons 1 (Cons PTrue (Nil)))` should be a type error for a homogeneous list `(List Nat)`. Ensure higher-order functions' arguments are correctly type-checked.\n\n**4. NonEmptyList T Tests:**\n    - Verify `(NECons h t)` creates a `NonEmptyList T` value.\n    - Test `head` on various non-empty lists to ensure it returns the first element.\n    - Test `tail` on various non-empty lists to ensure it returns the rest of the list.\n    - Type checking: `(head (Nil))` should be a type error, as `head` requires a `(NonEmptyList T)`.\n\n**5. Integration Tests:**\n    - Write small programs that pattern match on a `(List T)`, and upon finding a `(Cons h t)`, construct a `(NonEmptyList T)` to safely call `head` and `tail`.\n    - Write programs that use `subtract` within an effect handler to catch and manage domain errors.\n    - Verify that all defined functions and operations are correctly type-checked by the type system (Task 4).",
      "subtasks": [
        {
          "id": 1,
          "title": "Define `Bool` Type and Implement Core Boolean Operations",
          "description": "Defines the `Bool` type using `deftype` with `PFalse` and `PTrue` variants. Implements its Canonical Instantiation Functions (CIFs) and the fundamental boolean operations: `and`, `or`, `not`. This subtask establishes the foundational boolean logic for the standard library.",
          "dependencies": [],
          "details": "1. Define `Bool` using `(deftype Bool (PFalse) (PTrue))`.\n2. Ensure `deftype` (from Task 5) generates `PFalse` and `PTrue` as CIFs.\n3. Implement PathFinder LISP functions for:\n   - `and: Bool Bool -> Bool`\n   - `or: Bool Bool -> Bool`\n   - `not: Bool -> Bool`\n4. Ensure all functions are type-checked by the system's type checker (from Task 4).\n5. Place these definitions in the standard library module for automatic loading or easy import.",
          "status": "done",
          "testStrategy": "Unit test `PFalse` and `PTrue` CIFs. Test `and`, `or`, `not` operations with all possible boolean input combinations (e.g., `(and PTrue PFalse)`, `(or PFalse PFalse)`, `(not PTrue)`) to verify correctness."
        },
        {
          "id": 2,
          "title": "Define `Nat` Type and Implement Basic Query and Comparison Operations",
          "description": "Defines the `Nat` (Natural Numbers) type using Peano representation `(deftype Nat (Zero) (Succ Nat))` via `deftype`. Implements its CIFs (`Zero`, `Succ`) and basic operations that query state or compare `Nat` values, returning `Bool`: `isZero?`, `equals?`, `lessThan?`. This subtask relies on `deftype` supporting recursive type definitions.",
          "dependencies": [
            1
          ],
          "details": "1. Define `Nat` using `(deftype Nat (Zero) (Succ Nat))`. Confirm `deftype` (Task 5) supports recursive definitions as this is a recursive type.\n2. Ensure `Zero` (CIF for the `Zero` variant) and `Succ` (CIF for the `Succ` variant, taking a `Nat`) are available as per `deftype` specification.\n3. Implement PathFinder LISP functions for:\n   - `isZero?: Nat -> Bool`\n   - `equals?: Nat Nat -> Bool` (e.g., implement recursively by comparing structures: `(equals? Zero Zero)` is `PTrue`, `(equals? (Succ m) (Succ n))` is `(equals? m n)`, other cases `PFalse`)\n   - `lessThan?: Nat Nat -> Bool` (e.g., implement recursively: `(lessThan? Zero (Succ n))` is `PTrue`, `(lessThan? (Succ m) (Succ n))` is `(lessThan? m n)`, other cases `PFalse`)\n4. These functions will use the `Bool` type and its CIFs (`PTrue`, `PFalse`) from subtask 1 for their return values.\n5. Ensure all functions are type-checked. Place these definitions in the standard library module.",
          "status": "done",
          "testStrategy": "Unit test `Zero` and `Succ` CIFs (e.g., `(Zero)` creates a Nat, `(Succ (Zero))` creates a Nat). Test `isZero?` on `Zero` and non-Zero `Nat`s (e.g., `(Succ Zero)`). Test `equals?` with identical and different `Nat`s. Test `lessThan?` with various pairs of `Nat`s (e.g., `(lessThan? Zero (Succ Zero))`, `(lessThan? (Succ Zero) Zero)`)."
        },
        {
          "id": 5,
          "title": "Define Parameterized `List T` Type and Implement Safe Core Operations",
          "description": "Defines the parameterized, recursive `List T` type using `deftype`: `(deftype (List T) (Nil) (Cons T (List T)))`. Implements its CIFs (`Nil`, `Cons`) and a comprehensive set of list operations that are total for all lists. This subtask relies on `deftype` supporting both parameterized and recursive types.",
          "dependencies": [
            1,
            2
          ],
          "details": "1. Define `List T` using `(deftype (List T) (Nil) (Cons T (List T)))`. Confirm `deftype` (Task 5) supports parameterized and recursive types.\n2. Ensure `Nil` (CIF for `Nil` variant, type `(List T)` for any `T`) and `Cons` (CIF for `Cons` variant, type `T (List T) -> (List T)`) are available.\n3. Implement PathFinder LISP functions for:\n   - `isEmpty?: (List T) -> Bool` (uses `Bool` from subtask 1)\n   - `append: (List T) (List T) -> (List T)`\n   - `length: (List T) -> Nat` (uses `Nat` from subtask 2)\n   - `mapList: (List T) (T -> U) -> (List U)`\n   - `filterList: (List T) (T -> Bool) -> (List T)` (predicate function uses `Bool` from subtask 1)\n   - `foldLeft: (List T) U ((U T) -> U) -> U`\n   - `reverse: (List T) -> (List T)` (can be implemented efficiently using `foldLeft`)\n4. Ensure all functions are type-checked, including generic types `T` and `U`. Place in standard library module.",
          "status": "done",
          "testStrategy": "Unit test `Nil` and `Cons` CIFs. Test `isEmpty?` on `Nil` and non-empty lists. Test `append` with various list combinations. Test `length` on empty and non-empty lists. Test `mapList`, `filterList`, `foldLeft`, and `reverse` with various inputs and functions to ensure correctness."
        },
        {
          "id": 3,
          "title": "Define `NonEmptyList T` and Implement Safe `head`/`tail` Operations",
          "description": "Defines the `NonEmptyList T` type to statically guarantee non-emptiness. Implements total functions `head` and `tail` that operate on this type, providing safe, proof-carrying access to list elements.",
          "dependencies": [
            5
          ],
          "details": "1. Define `NonEmptyList T` using `(deftype (NonEmptyList T) (NECons T (List T)))`.\n2. Ensure `NECons` is available as a CIF with the type `T (List T) -> (NonEmptyList T)`.\n3. Implement the following total PathFinder LISP functions:\n   - `head: (NonEmptyList T) -> T`\n   - `tail: (NonEmptyList T) -> (List T)`\n4. These functions are guaranteed to succeed because the type `NonEmptyList T` provides proof that there is at least one element.\n5. Place these definitions in the standard library module.",
          "status": "done",
          "testStrategy": "Unit test the `NECons` CIF to ensure it creates `NonEmptyList` values. For a given `(NECons h t)`, verify that `(head (NECons h t))` returns `h` and `(tail (NECons h t))` returns `t`. Test with various types for `T`."
        },
        {
          "id": 4,
          "title": "Implement `Nat` Arithmetic: `add` and Effectful `subtract`",
          "description": "Implements the arithmetic operations `add: Nat Nat -> Nat` and `subtract: Nat Nat -> Nat` for the `Nat` type. The `subtract` operation is partial and will use the language's effect system to signal a domain error when subtraction is not possible within `Nat`.",
          "dependencies": [
            2
          ],
          "details": "1. Implement PathFinder LISP functions for:\n   - `add: Nat Nat -> Nat` (Implement recursively: `(add Zero n) = n`, `(add (Succ m) n) = (Succ (add m n))`)\n   - `subtract: Nat Nat -> Nat` (Implement recursively. For `(subtract (Succ m) (Succ n))`, recurse. For `(subtract Zero (Succ n))`, trigger a 'DomainError' effect.)\n2. These functions operate on the `Nat` type defined in subtask 2.\n3. Ensure all functions are type-checked. Place in standard library module.",
          "status": "done",
          "testStrategy": "Unit test `add` with various `Nat` inputs. Test `subtract` for successful cases (e.g., 5-3, 3-0, 3-3) to ensure the correct `Nat` is returned. Test failure cases (e.g., 3-5, 0-3) to ensure that the 'DomainError' effect is triggered and can be handled."
        }
      ]
    },
    {
      "id": 18,
      "title": "Implement Constraint System for Type Definitions and CIFs",
      "description": "Extend the type system to support dependent type constraints on type definitions using a `:where` clause. This will be verified at compile-time using the HoTT type system. The implementation will focus on generating proof obligations from constraints, requiring proof-of-satisfaction during instantiation, and creating proof-carrying values. This system will integrate with the Tier 1 (compile-time verification) and Tier 2 (constraint-aware effects) architecture, replacing traditional runtime checks.",
      "status": "pending",
      "dependencies": [
        5,
        4
      ],
      "priority": "medium",
      "details": "**1. Parser Extension (extending Task 5 `deftype`):**\n   - Modify the parser to recognize an optional `:where` clause in `deftype` expressions.\n   - Syntax: `(deftype TypeName ((field1 Type1) (field2 Type2) ...) :where <propositional-type>)`\n   - The `<propositional-type>` is a type-level expression that depends on the fields of the struct (e.g., `(> field1 0)` is interpreted as a proposition to be proven).\n\n**2. AST Representation:**\n   - Define how the parsed propositional type is stored within the AST representation of the type definition.\n\n**3. Type Checker & Proof Obligations (Tier 1):**\n   - The type checker must interpret the `:where` clause as a proof obligation, creating a dependent type. For a type `T` with fields `f1, f2` and constraint `P`, the full type is effectively `(T f1 f2 where (P f1 f2))`.\n   - At instantiation sites, e.g., `(T val1 val2)`, the type checker must verify that a proof for the proposition `(P val1 val2)` can be synthesized or is explicitly provided.\n   - Failure to construct or verify a proof must result in a compile-time type error.\n\n**4. Proof-Carrying Values & Instantiation:**\n   - Instances of constrained types are \"proof-carrying values.\" The runtime representation of the value must bundle the data with the evidence (the proof object) that its constraints are satisfied.\n   - The concept of Canonical Instantiation Functions (CIFs) is updated: instead of performing a runtime boolean check, the instantiation process now requires a proof object as an input (which may be synthesized by the compiler) and produces a proof-carrying value.\n\n**5. Tier 2 Integration (Constraint-Aware Effects):**\n   - Integrate with the Tier 2 effect system. Functions that produce values of a constrained type must have an effect signature that reflects the proof obligation.\n   - For example, a function `(-> Nat PositiveNat)` must have an effect that it discharges the proof for `(IsPositive result)`.\n   - Conversely, functions consuming proof-carrying values can use the carried proof to satisfy their own preconditions.\n\n**6. Error Reporting:**\n   - Implement clear and informative compile-time error messages for:\n     - Syntax errors in `:where` clauses.\n     - Proof failures during instantiation, indicating the specific proposition that could not be proven and the values involved.",
      "testStrategy": "**1. Parser Tests:**\n   - Test `deftype` with valid `:where` clauses using various propositional types (e.g., `(IsPositive field1)`, `(< x y)`).\n   - Test `deftype` with syntactically invalid `:where` clauses.\n\n**2. Type Checker & Proof Verification Tests (Tier 1):**\n   - Define `(deftype PositiveNat (value Nat) :where (IsPositive value))`.\n     - Test `(PositiveNat 10)`: Should succeed at compile time as a proof can be synthesized.\n     - Test `(PositiveNat 0)`: Should fail at compile time with a proof error.\n   - Define `(deftype OrderedPair (x Nat) (y Nat) :where (< x y))`.\n     - Test `(OrderedPair 1 2)`: Should succeed.\n     - Test `(OrderedPair 2 1)`: Should fail at compile time with a proof error.\n\n**3. Proof-Carrying Value Tests:**\n   - Verify that an instance of `PositiveNat` contains both the numeric value and a proof object for `IsPositive`.\n   - Write a function `(fn [p PositiveNat] ...)` and verify that within its body, the compiler knows that `(> (p.value) 0)` is true without a runtime check.\n\n**4. Tier 2 Effect System Tests:**\n   - Test that a function declared as `(-> Nat PositiveNat)` is type-checked correctly and its effect signature reflects the proof obligation.\n   - Test that a function that internally calls `(PositiveNat -1)` fails to type-check because it cannot discharge its effect.\n\n**5. Error Reporting Tests:**\n   - For each proof failure mode, verify that the error message clearly indicates the proposition that failed, the values used, and why the proof could not be constructed.",
      "subtasks": [
        {
          "id": 1,
          "title": "Extend Parser and AST for Dependent Type Constraints",
          "description": "Modify the `deftype` parser to recognize a `:where` clause containing a propositional type and update the AST to represent this dependent constraint.",
          "dependencies": [],
          "details": "1. Update the parser grammar for `deftype` to support the syntax: `(deftype TypeName ((field1 Type1) ...) :where <propositional-type>)`.\n2. The `<propositional-type>` should be parsed into a type-level AST node.\n3. Define how this constraint is stored within the AST of the type definition, linking it to the fields it depends on.",
          "status": "pending",
          "testStrategy": "Unit tests for the parser: \n- Successfully parse `deftype` with valid `:where` clauses containing type-level propositions.\n- Reject syntactically incorrect `:where` clauses.\n- Verify the generated AST correctly represents the dependent constraint."
        },
        {
          "id": 2,
          "title": "Generate Proof Obligations in Type Checker",
          "description": "Integrate logic into the type checker to interpret a `:where` clause as a proof obligation, effectively creating a dependent type.",
          "dependencies": [
            1
          ],
          "details": "1. The type checker, when processing a `deftype`, must identify the `:where` clause's proposition.\n2. It must establish the dependency of the proposition on the type's fields, creating a dependent type definition.\n3. This definition will be used to generate proof obligations at instantiation sites.",
          "status": "pending",
          "testStrategy": "Unit tests for the type checker:\n- Verify that a `deftype` with a valid constraint results in a dependent type representation internally.\n- Test that propositions correctly capture dependencies on the type's fields.\n- Test error reporting for malformed propositions (e.g., using undefined fields)."
        },
        {
          "id": 3,
          "title": "Implement Compile-Time Proof Verification (Tier 1)",
          "description": "Implement the core logic in the type checker to verify proofs for constraints at instantiation sites. This is the primary compile-time validation step.",
          "dependencies": [
            2
          ],
          "details": "1. When type-checking a call to a type constructor (e.g., `(MyType ...)`), retrieve the corresponding proof obligation.\n2. Attempt to automatically synthesize a proof for the obligation using the provided literal values and the HoTT system's theorem prover/proof synthesizer.\n3. If a proof cannot be synthesized, check if one was provided explicitly.\n4. A failure to find or verify a proof must result in a compile-time error.",
          "status": "pending",
          "testStrategy": "Unit tests for the proof verification logic:\n- Instantiate a constrained type where the proof is simple and can be synthesized (e.g., `(PositiveNat 10)`).\n- Attempt instantiation where the proof should fail (e.g., `(PositiveNat 0)`).\n- Test with multi-argument propositions (e.g., `(OrderedPair 2 1)`)."
        },
        {
          "id": 4,
          "title": "Implement Proof-Carrying Values and Update Instantiation",
          "description": "Modify the runtime representation of constrained types to be proof-carrying and update the instantiation logic (e.g., CIFs) to construct these values.",
          "dependencies": [
            3
          ],
          "details": "1. Define the runtime memory layout for a proof-carrying value, which bundles the data fields with a proof object.\n2. Modify the code generation for type instantiation. The instantiation function will now take the field values and a proof object as arguments.\n3. The compiler will be responsible for passing the synthesized or user-provided proof to this function at the call site.\n4. This replaces the old model of runtime boolean checks entirely.",
          "status": "pending",
          "testStrategy": "Integration tests:\n- Instantiate a constrained type and inspect the resulting runtime object to confirm it contains both data and a proof.\n- Write a function that accepts a proof-carrying value and verify that the compiler can use the carried proof to satisfy other static checks."
        },
        {
          "id": 5,
          "title": "Integrate with Tier 2 Effects and Implement Error Reporting",
          "description": "Connect the constraint system to the Tier 2 effect system and implement clear, user-friendly error messages for all stages of proof failure.",
          "dependencies": [
            4
          ],
          "details": "1. **Tier 2 Effects:** Ensure that functions producing constrained types declare this as part of their effect signature. The type checker must verify that the function body successfully discharges this proof obligation.\n2. **Error Reporting:** Design and implement clear compile-time error messages for proof failures. Messages should specify the proposition that failed and the concrete values that caused the failure.",
          "status": "pending",
          "testStrategy": "End-to-end tests:\n- Define a function `(-> Nat PositiveNat)` and show it type-checks if it handles the proof correctly, and fails otherwise.\n- Trigger every expected proof failure scenario and verify the error message is informative and points to the correct source location and values."
        }
      ]
    },
    {
      "id": 19,
      "title": "Enhanced Error Reporting and Diagnostics System",
      "description": "Implement a comprehensive, HoTT-aware error reporting and diagnostics system tailored for a 3-tier architecture. The system will replace traditional stack traces with context-aware diagnostics for proof failures (Tier 1), effect resolution issues (Tier 2), and runtime effect handler problems (Tier 3). It will generate messages that explain proof obligation failures, effect context violations, dependent type mismatches, and type universe errors, guiding users toward correct dependent type usage.",
      "status": "pending",
      "dependencies": [
        3,
        4
      ],
      "priority": "medium",
      "details": "1. **Tier-Aware Error Data Structures**: Define data structures that capture the context of our 3-tier architecture. This includes specific structures for:\n    *   **Tier 1 Proof Failures**: Capturing the proof goal, hypotheses, and the point of failure in the proof term.\n    *   **Tier 2 Effect Violations**: Representing effect resolution failures, including expected vs. actual effect contexts and the source of the violation.\n    *   **Tier 3 Runtime Handler Errors**: Storing information about failures within runtime effect handlers.\n    *   **Dependent Type Errors**: Specifically for universe inconsistencies and dependent type mismatches, capturing the path and context of the type dependency.\n2. **Contextual Diagnostic Generation**: Develop a module to translate error structures into context-aware diagnostics, replacing traditional stack traces. The output should clearly present:\n    *   **Proof Obligation Traces**: For Tier 1, show the sequence of proof obligations that led to the failure.\n    *   **Effect Context Diffs**: For Tier 2, visualize the discrepancy between required and provided effect contexts.\n    *   **Dependent Type Mismatch Explanations**: Clearly articulate why a dependent type application is incorrect, guiding the user on how to fix it.\n3. **Integration with 3-Tier System**:\n    *   Integrate with the **Tier 1 proof engine** to capture and report proof failures.\n    *   Integrate with the **Tier 2 effect checker/resolver** to report effect violations.\n    *   Integrate with the **Tier 3 runtime system** to handle and report errors from effect handlers.\n4. **User Guidance for Dependent Types**: Ensure all relevant error messages, especially for type mismatches, are designed to educate the user on the principles of dependent types, providing actionable suggestions for correcting their code.",
      "testStrategy": "1. **Unit Tests for Error Structures**: Verify that the new tier-aware data structures correctly capture context for proof failures, effect violations, and dependent type errors.\n2. **Tier 1 Proof Failure Tests**: Create test cases with incorrect proofs. Verify that the system generates clear proof obligation traces and accurately identifies the point of failure.\n3. **Tier 2 Effect Violation Tests**: Write code that violates effect constraints. Test that the system correctly reports the effect context mismatch and points to the source of the violation.\n4. **Tier 3 Runtime Handler Tests**: Simulate failures within runtime effect handlers and verify that the error reporting system captures and presents the errors correctly.\n5. **Dependent Type Error Tests**: Write code with common dependent type errors (e.g., universe inconsistencies, incorrect path applications). Verify that the error messages provide clear explanations and helpful guidance.\n6. **Diagnostic Usability Review**: Conduct reviews of the generated diagnostics (proof traces, effect diffs) for clarity, accuracy, and actionability with developers familiar with HoTT and effect systems.",
      "subtasks": [
        {
          "id": 1,
          "title": "Define Tier-Aware Error Data Structures for Proofs, Effects, and Types",
          "description": "Establish foundational data structures tailored for our 3-tier architecture. These structures must capture detailed context for Tier 1 proof failures, Tier 2 effect violations, Tier 3 runtime errors, and complex dependent type mismatches.",
          "dependencies": [],
          "details": "1. Define specific classes/structs for `ProofFailureError`, `EffectContextViolationError`, `RuntimeHandlerError`, and `DependentTypeError`.\n2. For `ProofFailureError`, include fields for the proof goal, hypotheses, and the failing sub-term.\n3. For `EffectContextViolationError`, include fields for expected vs. actual effect signatures and the operation causing the violation.\n4. For `DependentTypeError`, include fields for universe levels, path details, and the context of the type dependency.\n5. Update the central error collector to handle these new, specialized error structures.",
          "status": "pending",
          "testStrategy": "Unit tests: Verify that the tier-aware data structures can correctly store and retrieve all required contextual information for simulated proof, effect, and dependent type errors."
        },
        {
          "id": 2,
          "title": "Develop Contextual Diagnostic Generation Engine",
          "description": "Create a module to translate the structured, tier-aware error data (from subtask 1) into human-readable, contextual diagnostics that replace traditional stack traces. This includes generating proof failure traces and effect context diffs.",
          "dependencies": [
            1
          ],
          "details": "1. Implement a primary function that accepts a tier-aware error object (from subtask 1).\n2. For `ProofFailureError`, generate a trace of the proof obligations leading to the failure.\n3. For `EffectContextViolationError`, generate a clear \"diff\" showing the discrepancy between the required and provided effect contexts.\n4. For `DependentTypeError`, generate messages that explain the universe mismatch or path inconsistency, guiding the user toward a correct formulation.\n5. Ensure the output format is clear and helps developers debug issues across the three tiers.",
          "status": "pending",
          "testStrategy": "Unit tests: Provide various tier-aware error objects and verify the output diagnostics. Test that proof traces are logical, effect diffs are accurate, and dependent type explanations are helpful."
        },
        {
          "id": 3,
          "title": "Integrate Tier 1 Proof Failure Reporting with Proof Engine",
          "description": "Integrate the new error reporting system with the Tier 1 proof engine to capture and report proof failures, including failed proof obligations and ill-formed proof terms.",
          "dependencies": [
            1,
            2
          ],
          "details": "1. Identify all points in the proof engine where proof obligations are generated and checked.\n2. When a proof fails, instantiate the `ProofFailureError` data structure (from subtask 1) with the goal, context, and failing term.\n3. Report the error object to the central collector.\n4. Verify that the diagnostic engine (subtask 2) produces a clear proof trace that helps the user understand why their proof is incorrect.",
          "status": "pending",
          "testStrategy": "Integration tests: Create test cases with incorrect proofs (e.g., mismatched types, unprovable goals). Run the proof engine and verify that the correct `ProofFailureError` is generated and the resulting diagnostic trace is accurate and informative."
        },
        {
          "id": 4,
          "title": "Integrate Tier 2 and Tier 3 Effect Error Reporting",
          "description": "Integrate the error reporting system with the Tier 2 effect checker and Tier 3 runtime system to provide detailed diagnostics for effect-related errors.",
          "dependencies": [
            1,
            2
          ],
          "details": "1. In the Tier 2 effect checker, when an effect violation is detected, create and report an `EffectContextViolationError` object.\n2. Ensure the error context includes the expected and actual effects.\n3. In the Tier 3 runtime, wrap effect handler execution to catch exceptions or failures.\n4. When a handler fails, create and report a `RuntimeHandlerError` object with relevant runtime state.\n5. Verify the diagnostic engine (subtask 2) produces clear messages for both compile-time effect violations and runtime handler failures.",
          "status": "pending",
          "testStrategy": "Integration tests: For Tier 2, write code that violates effect signatures. For Tier 3, create mock effect handlers that fail at runtime. Verify that the system reports these errors with the correct context and helpful diagnostics."
        },
        {
          "id": 5,
          "title": "Refine Diagnostics for Dependent Types and Add User Guidance",
          "description": "Focus on making diagnostics for dependent type errors exceptionally clear and educational. Refine messages to guide users in correctly using dependent types, path equalities, and universe levels.",
          "dependencies": [
            2,
            3,
            4
          ],
          "details": "1. Review and refine all messages related to `DependentTypeError`.\n2. For common errors like universe inconsistencies, provide explicit suggestions (e.g., \"Try lifting the type to a higher universe level\").\n3. For dependent type mismatches, attempt to pinpoint the specific part of the type that is incorrect and explain the dependency.\n4. Ensure error messages related to type families and path equalities are precise and link back to the relevant definitions.\n5. Collect feedback from developers on the clarity of these specific error messages.",
          "status": "pending",
          "testStrategy": "Usability testing: Have developers write code designed to trigger complex dependent type errors. Evaluate whether the diagnostics help them understand and fix the problem. Compare message variations to find the most effective phrasing."
        }
      ]
    },
    {
      "id": 20,
      "title": "Implement Basic Proof Search and Constraint Inference System",
      "description": "Develop a system for basic proof search and constraint inference to enable automatic constraint satisfaction. This system will include simple proof generation, type-level computation for constraint checking, and integration with effect polymorphism decisions as specified in the PRD's effect polymorphic CIF system.",
      "details": "**1. Proof Representation and Basic Search Algorithm:**\n   - Define data structures for representing proof steps, proof trees, and logical formulae relevant to constraints.\n   - Implement a foundational proof search algorithm (e.g., a simple tableau prover, or a resolution-based method tailored to the constraint language from Task 18).\n   - The search should be capable of taking a constraint goal and attempting to derive its validity based on axioms and existing type information.\n\n**2. Constraint Inference Engine:**\n   - Design and implement a set of inference rules applicable to the language's constraint expressions (e.g., transitivity, symmetry for equality, rules for type properties, custom rules from PRD).\n   - Create an engine that can apply these rules to a given set of constraints to deduce new, implied constraints. This engine will support the proof search mechanism.\n\n**3. Type-Level Computation for Constraint Checking:**\n   - Extend the constraint validation logic (from Task 18) to utilize the proof search and inference engine.\n   - During type checking or CIF instantiation, when a constraint needs verification, the system will first attempt direct evaluation. If this is insufficient, it will invoke the proof search mechanism.\n   - Enable the evaluation or symbolic reasoning about type-level functions or predicates within constraints.\n\n**4. Simple Proof Generation:**\n   - Upon successful satisfaction of a constraint via proof search, the system should be able to generate a simplified trace or certificate of the proof.\n   - This output can be used for debugging, providing explanations to the developer, or potentially for more advanced compiler analyses in the future.\n\n**5. Integration with Effect Polymorphism (as per PRD):**\n   - Thoroughly review the PRD specifications for the \"effect polymorphic CIF system.\"\n   - Ensure the proof search and constraint inference mechanisms are equipped to handle constraints related to computational effects (e.g., purity, specific effect signatures, effect subsumption).\n   - The system must aid in deciding or verifying effect-related properties for polymorphic types and functions, aligning with the PRD's requirements for CIFs. For instance, inferring that a function `f : (A -> B) -> C` is pure if its argument function `(A -> B)` is proven pure via constraints.",
      "testStrategy": "**1. Unit Tests:**\n   - **Proof Search:** Create test cases with constraints that are trivially true, require multi-step derivations, and are unsatisfiable. Verify correct outcomes and termination.\n   - **Constraint Inference:** Test individual inference rules with known inputs and expected outputs. Verify the engine's ability to derive a complete set of implied constraints.\n   - **Type-Level Computation:** Define types with constraints involving type-level functions/predicates (e.g., list length, arithmetic properties) and verify correct validation by the proof system.\n   - **Proof Generation:** For constraints proven true, inspect the generated proof trace for correctness and clarity.\n\n**2. Integration Tests:**\n   - **Interaction with Task 18 (Constraint System):**\n     - Define `deftype` expressions with `:where` clauses that necessitate the proof search/inference capabilities (e.g., involving quantifiers or complex logical combinations if supported).\n     - Test that types are correctly accepted/rejected based on the provability of their constraints during compile-time checks.\n     - Test CIF instantiation where runtime constraint checks leverage the inference engine.\n   - **Effect Polymorphism Scenarios (aligned with PRD):**\n     - Implement test cases for polymorphic functions and types with effect-related constraints (e.g., a higher-order function whose effect signature depends on the proven effects of its function arguments).\n     - Verify that the system correctly infers or proves these effect properties, leading to correct type checking and CIF behavior as per the PRD.\n     - Example: Test a scenario where a CIF's effect polymorphism is resolved by proving a constraint like `(effect_of(X) subset_of allowed_effects)`.\n\n**3. Scenario-Based Testing (PRD Alignment):**\n   - Develop comprehensive test scenarios based directly on examples or specifications from the PRD for the effect polymorphic CIF system.\n   - Ensure the end-to-end behavior (parsing, type checking, constraint satisfaction, CIF instantiation) matches the PRD's intent when the new proof search and inference system is active.",
      "status": "pending",
      "dependencies": [
        18
      ],
      "priority": "medium",
      "subtasks": [
        {
          "id": 1,
          "title": "Define Proof Data Structures and Implement Foundational Proof Search",
          "description": "Establish core data structures for representing proof steps, proof trees, and logical formulae for constraints. Implement a foundational proof search algorithm (e.g., tableau or resolution-based) capable of deriving constraint validity from axioms and existing type information.",
          "dependencies": [],
          "details": "Data structures should be compatible with constraints defined in Task 18. The search algorithm will take a constraint goal and attempt to prove its validity. Initial implementation can use a simple depth-first or breadth-first search. Axioms and type information form the knowledge base.",
          "status": "pending",
          "testStrategy": "Unit test data structure integrity and serialization/deserialization. Test the search algorithm with basic constraint goals (provable and unprovable) against a minimal set of predefined axioms."
        },
        {
          "id": 2,
          "title": "Develop Constraint Inference Engine with Rule Application Logic",
          "description": "Design and implement a set of inference rules (e.g., transitivity, symmetry, type property rules, custom rules from PRD). Create an engine that applies these rules to a given set of constraints to deduce new, implied constraints, thereby supporting the proof search mechanism.",
          "dependencies": [
            1
          ],
          "details": "The inference engine will take known constraints and apply rules to expand this set. Rules should be designed for extensibility and configurability. This engine will be invoked by the proof search (from subtask 1) to generate intermediate proof steps or explore new deduction paths.",
          "status": "pending",
          "testStrategy": "Unit test individual inference rules for correctness. Test the engine's ability to derive expected implied constraints from a given set using various rule combinations. Verify correct interaction with the proof search mechanism from subtask 1."
        },
        {
          "id": 3,
          "title": "Integrate Proof System into Type-Level Constraint Checking",
          "description": "Extend the existing constraint validation logic (from Task 18) to utilize the proof search and inference engine. When direct evaluation of a constraint is insufficient, the system will invoke the proof mechanism. Enable symbolic reasoning about type-level functions or predicates within constraints.",
          "dependencies": [
            1,
            2
          ],
          "details": "Modify the type checking or Constraint Intermediate Form (CIF) instantiation logic. If a constraint check fails direct evaluation, formulate it as a goal for the proof search system. The system must handle type-level functions/predicates, potentially by treating them as uninterpreted functions or by applying specific axioms/rules defined for them.",
          "status": "pending",
          "testStrategy": "Test scenarios where constraints are solved by direct evaluation versus those requiring the proof search and inference engine. Verify correct handling and reasoning for type-level functions/predicates within constraints, ensuring the proof system is invoked appropriately."
        },
        {
          "id": 4,
          "title": "Implement Simple Proof Trace Generation for Successful Proofs",
          "description": "Upon successful satisfaction of a constraint via the proof search mechanism, the system should generate a simplified trace or certificate of the proof. This output will serve debugging, developer explanation, or future compiler analyses.",
          "dependencies": [
            1,
            2,
            3
          ],
          "details": "Augment the proof search algorithm (from subtask 1) and inference engine (subtask 2) to record the sequence of applied rules, axioms, and derived facts leading to the proof. Develop a formatter to present this trace in a human-readable or structured (e.g., JSON) format. Focus on clarity and essential information for debugging and understanding the proof.",
          "status": "pending",
          "testStrategy": "For various constraints successfully proven by the integrated system (subtask 3), verify that the generated proof trace accurately and clearly reflects the deduction steps. Check the output format, completeness, and readability of the trace."
        },
        {
          "id": 5,
          "title": "Adapt Proof System for Effect Polymorphism Constraints (PRD)",
          "description": "Review PRD specifications for the 'effect polymorphic CIF system.' Adapt the proof search and constraint inference mechanisms to handle constraints related to computational effects (e.g., purity, specific effect signatures, effect subsumption). The system must aid in deciding or verifying effect-related properties for polymorphic types and functions.",
          "dependencies": [
            1,
            2,
            3
          ],
          "details": "Identify specific effect-related constraint types from the PRD (e.g., `isPure(X)`, `hasEffect(E, X)`). Define corresponding axioms or inference rules (e.g., for purity propagation, effect composition, effect subsumption). Integrate these into the inference engine (subtask 2) and ensure the proof search (subtask 1) can utilize them within the context of constraint checking (subtask 3). Example: inferring purity of `f : (A -> B) -> C` if its argument function `(A -> B)` is proven pure via constraints.",
          "status": "pending",
          "testStrategy": "Develop test cases based on PRD examples for effect polymorphism. Verify the system's ability to correctly infer or validate effect-related properties, such as purity of higher-order functions or effect subsumption between types, using the implemented proof and inference capabilities."
        }
      ]
    },
    {
      "id": 21,
      "title": "Set Up Racket/Rhombus Development Environment and Project Structure",
      "description": "Establish the development environment using Racket #lang (or Rhombus with shrubbery/forest macros), including implementation language choice, initial project structure, build system, testing framework, and development tools. This task is foundational for all subsequent implementation work.",
      "details": "1. **Language Choice & Setup**: Evaluate and decide between standard Racket (e.g., `#lang racket/base`) and Rhombus. If Rhombus, identify and integrate necessary base layers like `shrubbery` and `forest`. Document the choice and install the chosen Racket version or Rhombus distribution.\n2. **Project Structure**: Create a standard directory layout: `src/` for core source code, `tests/` for unit/integration tests, `examples/` for sample programs, `docs/` for documentation, and `scripts/` for utility scripts. Initialize a main entry point file if applicable (e.g., `src/main.rkt`).\n3. **Version Control**: Initialize a Git repository (`git init`). Create a comprehensive `.gitignore` file tailored for Racket/Rhombus projects (e.g., ignoring `compiled/` directories, editor-specific files, OS-specific files).\n4. **Build System**: Configure Racket's `raco make` for building the project or set up the equivalent build process for Rhombus. Create initial build configuration files (e.g., `info.rkt` for Racket package metadata if the project will be structured as a package).\n5. **Testing Framework**: Integrate the `rackunit` testing framework. Create a main test runner file (e.g., `tests/main-tests.rkt`) to discover and run all tests. Include a simple placeholder test.\n6. **Dependency Management**: Document the process for managing external Racket packages using `raco pkg`. List any known core external libraries required from the outset.\n7. **Development Tools**: Recommend and document setup for IDEs/editors (e.g., DrRacket, VS Code with Racket LSP, Emacs with racket-mode). Investigate and optionally set up linters (e.g., `raco lint`) and code formatters.\n8. **Documentation Setup**: Set up Scribble for project documentation. Create a basic `docs/main.scrbl` file and configure `raco setup` or `raco scribble` for building documentation.",
      "testStrategy": "1. **Environment Verification**: Confirm successful installation and activation of the chosen Racket version or Rhombus environment on a clean system or in a container.\n2. **Project Initialization & Git**: Clone the repository after the initial commit. Verify the directory structure matches the definition. Confirm the `.gitignore` file is present and correctly excludes common Racket artifacts (e.g., create dummy compiled files, check `git status`).\n3. **Build Process**: Create a minimal 'hello world' module in `src/`. Successfully build the project using the configured build command (e.g., `raco make src/main.rkt`). Verify compiled outputs are generated and handled correctly by version control.\n4. **Testing Framework**: Create a simple test case in `tests/` (e.g., using `rackunit` `check-equal?`). Run the test suite (e.g., `raco test tests/main-tests.rkt`) and confirm tests are discovered and pass.\n5. **REPL & Tooling**: Launch the Racket/Rhombus REPL in the project directory. Successfully `require` a module from `src/`. If linters/formatters are set up, run them on a sample file and verify they function as expected.\n6. **Dependency Management Check**: If a sample external dependency is identified, attempt to install it via `raco pkg install` and `require` it in a test module to ensure the process works.\n7. **Documentation Generation**: Add minimal content to `docs/main.scrbl`. Run the documentation build command (e.g., `raco scribble +m docs/main.scrbl`) and verify that HTML or other specified output is generated correctly.",
      "status": "done",
      "dependencies": [],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Language Selection, Installation, and Version Control Initialization",
          "description": "Decide between standard Racket and Rhombus, install the chosen language environment, initialize a Git repository, and create a tailored .gitignore file.",
          "dependencies": [],
          "details": "1. **Language Evaluation & Choice**: Evaluate standard Racket (e.g., `#lang racket/base`) versus Rhombus (potentially with `shrubbery` and `forest` macros). Document the decision and its rationale.\n2. **Installation**: Install the chosen Racket version or Rhombus distribution. Verify the installation by running the REPL (e.g., `racket` or `rhombus`).\n3. **Version Control Setup**: Initialize a Git repository in the project's root directory using `git init`.\n4. **.gitignore File**: Create a comprehensive `.gitignore` file. Include patterns for Racket/Rhombus compiled files (e.g., `compiled/`, `*.zo`), editor-specific files (e.g., `.vscode/`, `*.elc`), OS-specific files (e.g., `.DS_Store`, `Thumbs.db`), and any local configuration files.",
          "status": "done",
          "testStrategy": "Verify that the chosen Racket/Rhombus REPL starts correctly. Confirm that `git status` shows a clean working directory after an initial commit that includes the `.gitignore` file."
        },
        {
          "id": 2,
          "title": "Establish Core Project Directory Structure and Basic Build Configuration",
          "description": "Create the standard directory layout for source code, tests, examples, documentation, and scripts. Set up the initial build system configuration using Racket's tools.",
          "dependencies": [
            1
          ],
          "details": "1. **Directory Structure**: Create the following directories in the project root: `src/` (for core source code), `tests/` (for unit and integration tests), `examples/` (for sample programs using the library/application), `docs/` (for project documentation), and `scripts/` (for utility and build scripts).\n2. **Main Entry Point**: Create an initial main entry point file if applicable (e.g., `src/main.rkt` containing a basic module definition like `(#lang racket/base (provide main)) (define (main) (displayln \"Hello, Project!\"))`).\n3. **Build System Setup**: Configure Racket's `raco make` for building the project. This involves creating an `info.rkt` file in the project root if structuring the project as a Racket package. The `info.rkt` should define essential metadata like project name, version, and initial (empty or core) dependencies.\n4. **Initial Build Test**: Ensure that `raco make` (or the Rhombus equivalent) can process the `info.rkt` and compile files in `src/`.",
          "status": "done",
          "testStrategy": "Verify that all specified directories exist. Execute `raco make` (or equivalent build command); it should complete without errors, potentially compiling `src/main.rkt`."
        },
        {
          "id": 3,
          "title": "Integrate Testing Framework and Create Initial Test Suite",
          "description": "Integrate the `rackunit` testing framework. Create a main test runner file and include a simple placeholder test to ensure the testing setup is functional.",
          "dependencies": [
            2
          ],
          "details": "1. **Framework Integration**: Ensure `rackunit` is available (it's typically bundled with Racket). If developing a package, list `rackunit` as a test dependency in `info.rkt`.\n2. **Test Runner**: Create a main test runner file, e.g., `tests/main-tests.rkt`. This file should `(require rackunit)` and be structured to discover and run all test files within the `tests/` directory (e.g., by explicitly requiring other test files or using a helper to find them).\n3. **Placeholder Test**: Add a simple placeholder test case in `tests/main-tests.rkt` or a separate `tests/example-test.rkt` file (e.g., `(require rackunit) (test-case \"Placeholder Test\" (check-true #t \"This is a basic truth test.\"))`).\n4. **Test Execution Script/Command**: Configure the build system or create a script (e.g., in `scripts/run-tests.sh` or a Racket script `scripts/run-tests.rkt`) to execute all tests (e.g., by running `racket tests/main-tests.rkt`).",
          "status": "done",
          "testStrategy": "Execute the test runner script/command. The output should indicate that the test suite ran and the placeholder test passed."
        },
        {
          "id": 4,
          "title": "Set Up Dependency Management and Initial Documentation Infrastructure",
          "description": "Document the process for managing external Racket packages using `raco pkg`. Set up the basic infrastructure for project documentation using Scribble, including an initial document and build configuration.",
          "dependencies": [
            2
          ],
          "details": "1. **Dependency Management Documentation**: In a `README.md` or `CONTRIBUTING.md` file, document how to manage external Racket packages using `raco pkg` commands (e.g., `raco pkg install <package>`, `raco pkg update <package>`).\n2. **Initial Dependencies**: List any known core external libraries required from the outset. If the project is a package, add these to the `deps` list in `info.rkt`.\n3. **Scribble Setup**: Set up Scribble for project documentation. Create a basic `docs/main.scrbl` file with a title (e.g., `@title[My Project Documentation]`) and a minimal section.\n4. **Documentation Build**: Configure `raco setup` (if the project is a package and `info.rkt` specifies Scribble docs) or use `raco scribble` commands (e.g., `raco scribble --htmls ++xref-in Scribble-xref.rktd docs/main.scrbl`) to build the documentation. Consider adding a script to `scripts/build-docs.sh` for this process.",
          "status": "done",
          "testStrategy": "Attempt to install a known, simple Racket package using `raco pkg install <some-package>` to verify the documented process. Build the initial Scribble documentation and check that the HTML output is generated in the expected location (e.g., `docs/html/index.html`)."
        },
        {
          "id": 5,
          "title": "Configure Development Tools and Finalize Project Scripts",
          "description": "Recommend and document setup for IDEs/editors, linters (e.g., `raco lint`), and code formatters. Review and finalize utility scripts for common development tasks.",
          "dependencies": [
            4
          ],
          "details": "1. **IDE/Editor Setup**: Document recommended IDEs/editors (e.g., DrRacket, VS Code with Racket/LSP extension, Emacs with racket-mode). Provide basic setup instructions or links to relevant extensions/plugins in `README.md` or a development guide.\n2. **Linter Setup**: Investigate and set up `raco lint` for static analysis. Document its usage (e.g., `raco lint src/**/*.rkt tests/**/*.rkt`). Consider integrating it into a pre-commit hook or a CI pipeline script.\n3. **Code Formatter (Optional)**: Investigate and optionally set up a code formatter compatible with Racket/Rhombus. Document its usage if adopted.\n4. **Finalize Utility Scripts**: Review, refine, and document all scripts in the `scripts/` directory (e.g., for building the project, running tests, generating documentation, linting code). Ensure they are executable and robust.",
          "status": "done",
          "testStrategy": "Verify that the recommended IDE/editor extensions can be installed and provide basic functionality (e.g., syntax highlighting for `.rkt` files). Run `raco lint` on the existing codebase and ensure it executes. Execute all scripts in the `scripts/` directory to confirm they work as intended and produce the expected outcomes."
        }
      ]
    },
    {
      "id": 22,
      "title": "MCP Server for Structural S-Expression Editing",
      "description": "Develop an MCP (Multi-Connection Protocol) server that provides tools for structural S-expression editing. This server will enable parsing Racket/Lisp files into S-expression trees, performing structural modifications, and serializing them back with proper formatting.",
      "details": "The server should expose the following functionalities, likely as MCP methods:\n1.  `read_sexp(filePath: string) -> SExpressionTree`: Parses a Racket/Lisp file at `filePath` into an internal S-expression tree representation. This should leverage the existing parser from Task 1.\n2.  `modify_sexp(tree: SExpressionTree, path: SPath, newSubtree: SExpression) -> SExpressionTree`: Modifies the S-expression tree at a given `path` (e.g., a list of indices specifying the route to the sub-expression) by replacing it with `newSubtree`.\n3.  `insert_sexp(tree: SExpressionTree, path: SPath, index: int, newSubtree: SExpression) -> SExpressionTree`: Inserts `newSubtree` into a list at `path` at the given `index`.\n4.  `delete_sexp(tree: SExpressionTree, path: SPath) -> SExpressionTree`: Deletes the sub-expression at the given `path`.\n5.  `wrap_sexp(tree: SExpressionTree, path: SPath, wrapperSymbol: string) -> SExpressionTree`: Wraps the sub-expression at `path` with a new list structure, e.g., `(wrapperSymbol originalSubExpression)`.\n6.  `format_sexp(tree: SExpressionTree) -> string`: Pretty-prints the S-expression tree into a well-formatted string, suitable for writing back to a file. This should ensure consistent indentation and readability.\n7.  `validate_sexp(tree: SExpressionTree) -> bool/errors`: Checks the structural validity of the S-expression tree (e.g., balanced parentheses, valid atom types). This is primarily about syntactic structure, not semantic correctness or type checking.\n\nThe server should be designed to integrate with IDEs or other development tools that require programmatic manipulation of Lisp code. The internal S-expression tree representation should be compatible with or based on the AST defined in Task 2. This server aims to provide a robust foundation for advanced S-expression editing capabilities, helping to resolve issues like bracket matching for consumers like the type checker.",
      "testStrategy": "1.  **Unit Tests for `read_sexp`**:\n    *   Test with valid Racket/Lisp files containing various S-expression structures (nested lists, atoms, strings, numbers, comments).\n    *   Test with empty files and files with syntax errors; ensure appropriate error handling.\n2.  **Unit Tests for Modification Functions (`modify_sexp`, `insert_sexp`, `delete_sexp`, `wrap_sexp`)**:\n    *   For each function, create various S-expression trees and test modifications at different valid and invalid paths.\n    *   Verify that the returned tree reflects the changes correctly.\n    *   Test edge cases: modifying root, inserting into empty lists, deleting from lists, wrapping atoms and lists.\n3.  **Unit Tests for `format_sexp`**:\n    *   Test with various complex S-expression trees.\n    *   Verify that the output string is correctly formatted (indentation, spacing, line breaks).\n    *   Ensure that formatting is idempotent (formatting an already formatted string produces the same result or a structurally equivalent one).\n4.  **Unit Tests for `validate_sexp`**:\n    *   Test with well-formed S-expression trees.\n    *   Test with malformed trees (e.g., issues not caught by initial parsing but relevant to structural integrity rules defined for this function).\n5.  **Integration Tests**:\n    *   Test a sequence of operations: read a file, perform several modifications, format the result, and validate it.\n    *   Compare the formatted output with an expected output file.\n    *   Test the MCP server interface: send requests for each function and verify the responses.",
      "status": "done",
      "dependencies": [
        1,
        2,
        21
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "MCP Server Foundation and `read_sexp` Implementation",
          "description": "Initialize the MCP server framework. Implement the `read_sexp` functionality to parse Racket/Lisp files into an internal S-expression tree, leveraging the parser from Task 1 and the AST from Task 2. This subtask also involves defining or confirming the `SExpressionTree` and `SPath` data structures.",
          "dependencies": [],
          "details": "1. Select and configure an MCP library/framework suitable for the project's language (e.g., Python, Java, Node.js).\n2. Implement the basic server structure: connection handling, request dispatching.\n3. Define the internal `SExpressionTree` representation, ensuring compatibility with the AST from Task 2. This includes nodes for atoms (symbols, numbers, strings, etc.) and lists/conses.\n4. Define the `SPath` representation (e.g., a list of integer indices or specific keys) for uniquely identifying sub-expressions within an `SExpressionTree`.\n5. Implement the `read_sexp(filePath: string) -> SExpressionTree` MCP method:\n    a. Input: `filePath` (string).\n    b. Action: Use the existing parser (from Task 1) to read the file content and generate an AST.\n    c. Convert/adapt this AST to the server's internal `SExpressionTree` representation.\n    d. Output: The resulting `SExpressionTree` object.",
          "status": "done",
          "testStrategy": "1. Unit test `read_sexp` with various valid Racket/Lisp files (simple, nested, empty, comments) and invalid files (syntax errors, non-existent files).\n2. Verify the structure of the generated `SExpressionTree` against expected outputs.\n3. Test basic MCP server connectivity and successful invocation of the `read_sexp` method via an MCP client."
        },
        {
          "id": 2,
          "title": "Implement `format_sexp` and `validate_sexp` Utilities",
          "description": "Develop the `format_sexp` function for pretty-printing S-expression trees into human-readable, consistently formatted strings, and the `validate_sexp` function for checking the structural integrity of S-expression trees.",
          "dependencies": [
            1
          ],
          "details": "1. Implement `format_sexp(tree: SExpressionTree) -> string`:\n    a. Input: `SExpressionTree`.\n    b. Action: Traverse the tree and generate a string representation.\n    c. Ensure consistent indentation, line breaks for readability, and proper handling of different S-expression elements (atoms, lists, dotted pairs if applicable).\n    d. Output: Formatted string.\n2. Implement `validate_sexp(tree: SExpressionTree) -> bool/errors`:\n    a. Input: `SExpressionTree`.\n    b. Action: Traverse the tree to check for structural validity (e.g., all list elements are valid S-expressions, atoms have valid types according to the S-expression grammar). This is primarily syntactic, not semantic.\n    c. Output: Boolean `true` if valid, or an object/list containing error descriptions if invalid.",
          "status": "done",
          "testStrategy": "1. Unit test `format_sexp` with diverse `SExpressionTree` structures (empty, simple, deeply nested, various atom types) and verify the output string matches expected formatting rules.\n2. Unit test `validate_sexp` with known valid `SExpressionTree` instances and instances with deliberate structural errors (e.g., improper list termination if not caught by parser, invalid atom types if your definition is strict)."
        },
        {
          "id": 3,
          "title": "Implement Core Destructive Modifications: `modify_sexp` and `delete_sexp`",
          "description": "Implement the `modify_sexp` operation to replace a sub-expression at a given `SPath` and `delete_sexp` to remove a sub-expression at a given `SPath`. These operations modify the tree structure.",
          "dependencies": [
            1
          ],
          "details": "1. Implement helper function(s) for navigating an `SExpressionTree` using an `SPath` to locate and access the parent and target sub-expression. Handle invalid or out-of-bounds paths gracefully (e.g., by raising an error or returning a specific status).\n2. Implement `modify_sexp(tree: SExpressionTree, path: SPath, newSubtree: SExpression) -> SExpressionTree`:\n    a. Inputs: Original `SExpressionTree`, `SPath` to the target node, `newSubtree` (an `SExpression`).\n    b. Action: Locate the sub-expression at `path`. Replace it with `newSubtree`. Consider if operations should be in-place or return a new tree (returning a new tree is generally safer).\n    c. Output: The modified `SExpressionTree`.\n3. Implement `delete_sexp(tree: SExpressionTree, path: SPath) -> SExpressionTree`:\n    a. Inputs: Original `SExpressionTree`, `SPath` to the target node.\n    b. Action: Locate the sub-expression at `path`. Remove it from its parent list. If the path points to an element that cannot be deleted (e.g., root, or an atom that's not part of a list), handle appropriately.\n    c. Output: The modified `SExpressionTree`.",
          "status": "done",
          "testStrategy": "1. Unit test `modify_sexp`: provide various `SExpressionTree`s, `SPath`s (root, leaf, mid-level, invalid), and `newSubtree`s. Verify the returned tree structure.\n2. Unit test `delete_sexp`: provide various `SExpressionTree`s and `SPath`s. Test deleting from start, middle, end of lists, and deleting the only element. Verify returned tree structure and error handling for invalid paths."
        },
        {
          "id": 4,
          "title": "Implement Additive Modification Operations: `insert_sexp` and `wrap_sexp`",
          "description": "Implement the `insert_sexp` operation to add a new sub-expression into a list at a specific `SPath` and index, and `wrap_sexp` to wrap an existing sub-expression at an `SPath` with a new list structure.",
          "dependencies": [
            1,
            3
          ],
          "details": "1. Leverage or extend path navigation logic from subtask 3.\n2. Implement `insert_sexp(tree: SExpressionTree, path: SPath, index: int, newSubtree: SExpression) -> SExpressionTree`:\n    a. Inputs: Original `SExpressionTree`, `SPath` to the parent list, `index` for insertion, `newSubtree` (an `SExpression`).\n    b. Action: Navigate to the list identified by `path`. Insert `newSubtree` at the specified `index`. Handle out-of-bounds indices (e.g., clamp to list bounds, or error). The `path` should point to a list.\n    c. Output: The modified `SExpressionTree`.\n3. Implement `wrap_sexp(tree: SExpressionTree, path: SPath, wrapperSymbol: string) -> SExpressionTree`:\n    a. Inputs: Original `SExpressionTree`, `SPath` to the target sub-expression, `wrapperSymbol` (string).\n    b. Action: Locate the sub-expression at `path`. Create a new list `(wrapperSymbol originalSubExpression)`. Replace the original sub-expression at `path` with this new list.\n    c. Output: The modified `SExpressionTree`.",
          "status": "done",
          "testStrategy": "1. Unit test `insert_sexp`: test inserting into empty lists, at the beginning, middle, and end of existing lists. Test with various `SPath`s, valid/invalid indices, and `newSubtree`s. Verify tree structure.\n2. Unit test `wrap_sexp`: test with various `SPath`s (targeting atoms and lists) and `wrapperSymbol`s. Verify the structure of the newly created wrapper list and its correct placement."
        },
        {
          "id": 5,
          "title": "Expose All Operations as MCP Methods and Finalize Server",
          "description": "Integrate all implemented S-expression manipulation functions (`format_sexp`, `validate_sexp`, `modify_sexp`, `delete_sexp`, `insert_sexp`, `wrap_sexp`) as methods within the MCP server established in Subtask 1. Finalize server implementation including robust error handling and documentation for MCP methods.",
          "dependencies": [
            1,
            2,
            3,
            4
          ],
          "details": "1. For each core function (`format_sexp`, `validate_sexp`, `modify_sexp`, `delete_sexp`, `insert_sexp`, `wrap_sexp`), create a corresponding MCP method handler in the server.\n2. Ensure MCP method handlers correctly parse incoming request parameters (e.g., `SExpressionTree` JSON, `SPath` array, `index` integer, `filePath` string).\n3. Call the respective core logic functions with these parameters.\n4. Serialize return values (e.g., `SExpressionTree` to JSON, string, boolean/error object) into appropriate MCP responses.\n5. Implement comprehensive error handling at the MCP layer: catch exceptions from core logic, handle invalid MCP requests/parameters, and return meaningful error responses over MCP.\n6. Add logging for MCP requests, responses, and significant server events.\n7. Prepare documentation for each exposed MCP method, detailing its purpose, parameters (name, type, description), return value (type, description), and potential errors.",
          "status": "done",
          "testStrategy": "1. Integration tests: Use an MCP client to invoke each of the exposed MCP methods (`read_sexp`, `format_sexp`, `validate_sexp`, `modify_sexp`, `delete_sexp`, `insert_sexp`, `wrap_sexp`).\n2. Test with a variety of valid inputs and expected successful outcomes.\n3. Test with invalid inputs (e.g., malformed SPath, incorrect types, non-existent files for `read_sexp`) to verify robust error reporting via MCP.\n4. Verify that sequences of operations (e.g., read, modify, format) work correctly together through the MCP interface."
        }
      ]
    },
    {
      "id": 23,
      "title": "Type Inference and Elaboration Engine",
      "description": "Implement a type inference and elaboration engine that automatically deduces dependent type parameters, universe levels, and generates proof obligations. This will simplify type annotations for users, making the HoTT-based language more practical.",
      "details": "Implement a bidirectional type checking algorithm (synthesis and checking modes) that can infer missing type information, extending the existing type checker (from Task 4 and Task 10). Focus on inferring types for lambda parameters, function application arguments, and let-bindings.\n\n**Dependent Type Inference**:\n- Infer parameters for Π-types and Σ-types. For example, if `f : (Π (A : Type) (x : A) -> A)`, in an application `(f _ y)`, infer the first argument (the type `A`) from the type of `y`.\n- Handle implicit arguments in dependent type constructors and functions.\n\n**Universe Level Inference** (if applicable to the language design):\n- Implement inference for universe levels to ensure consistency (e.g., `Type i`). This might involve collecting constraints on universe levels and solving them.\n\n**Proof Obligation Generation**:\n- When type checking expressions involving propositions (e.g., `Id A x y` from Task 11), if a proof is required but not explicitly provided, the system should generate a proof obligation.\n- These obligations could be represented as new goals for a separate proof assistant component or require the user to provide the proof term.\n\n**Elaboration**:\n- The inference engine should elaborate partially typed Abstract Syntax Trees (ASTs) into fully typed ASTs. This means filling in all inferred types, implicit arguments, and potentially inserting coercions or other type-level constructs.\n- The elaborated AST will be the input for subsequent compilation or evaluation stages.\n\n**Error Reporting**:\n- Provide clear and informative error messages when inference fails or leads to ambiguity. Messages should guide the user on how to resolve the issue (e.g., by adding explicit type annotations).\n\n**Integration**:\n- Integrate the inference engine into the main type checking pipeline.\n- Ensure it works correctly with features from Task 4 (simple types/functions), Task 10 (dependent types), Task 11 (Identity types), and types defined in Task 17 (Standard Library).",
      "testStrategy": "**Unit Tests for Inference Rules**:\n- Test inference of simple function argument types and return types.\n- Test inference of lambda parameter types.\n- Test inference for let-bindings.\n\n**Dependent Type Inference Tests**:\n- Define functions with dependent types (Π-types, Σ-types) where some parameters can be inferred. Test that the engine correctly infers these parameters in various application scenarios.\n- Example: `(define id (lambda (A : Type) (lambda (x : A) x)))`. Test `(id _ 5)` infers `A` as `Nat` (assuming Nat is part of the system from Task 17 or similar).\n- Test inference with types from the standard library (Task 17), e.g., inferring the type parameter for `List` or `Option` in functions like `map` or `flatMap` if their types allow for inference.\n\n**Universe Level Inference Tests** (if applicable):\n- Create scenarios that require universe level constraints and verify that the inference engine correctly assigns or infers consistent universe levels.\n- Test for universe inconsistency errors.\n\n**Proof Obligation Generation Tests**:\n- Create expressions that should logically require a proof (e.g., using an equality that isn't `refl` without providing a proof term for `Id A x y` from Task 11).\n- Verify that the system correctly identifies and generates the appropriate proof obligation.\n\n**Elaboration Tests**:\n- Inspect the elaborated AST to ensure that all inferred types and implicit arguments are correctly inserted.\n- Verify that the elaborated AST is well-typed according to the full, non-inferential type checker.\n\n**Error Reporting Tests**:\n- Create ambiguous type scenarios and verify that the system reports an error rather than inferring an incorrect type.\n- Create unsolvable inference problems and check for clear error messages that guide the user.\n- Test cases where insufficient information is provided for inference, prompting the user for annotations.\n\n**Integration Tests**:\n- Write small programs that heavily rely on type inference for various constructs (functions, data types from Task 17, dependent types from Task 10, identity types from Task 11).\n- Verify that these programs type check correctly and that the inferred types match expectations.\n- Test interaction with `deftype` and Canonical Instantiation Functions (CIFs) (related to Task 5, via Task 17).",
      "status": "in-progress",
      "dependencies": [
        4,
        10,
        11,
        17
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Extend Type Checker with Bidirectional Inference for Basic Constructs",
          "description": "Modify the existing type checker (from Task 4 & 10) to support bidirectional type checking (synthesis and checking modes). Implement inference for lambda parameters, function application arguments, and types in let-bindings. This forms the foundation for more advanced inference.",
          "dependencies": [],
          "details": "Define two main functions: `infer(context, term)` returning a type, and `check(context, term, type)` verifying the term has the given type. For lambdas `λx. body`, infer parameter type `A` if `x` is unannotated and context allows, or use annotation; then check/infer body. For applications `(f e)`, synthesize type of `f` (e.g., `Π(x:A).B`), check `e` against `A` (or infer `A` if possible), result type is `B[x := e]`. For `let x = e1 in e2`, infer type of `e1` as `A`, then check/infer `e2` in context extended with `x:A`.",
          "status": "done",
          "testStrategy": "Unit tests for inferring types of simple lambdas (annotated and unannotated parameters where inferable), applications (argument type checking and polymorphic function instantiation), and let-bindings (inferring binding's type). Test cases where type annotations are missing and can be inferred, and cases where they are essential and omission leads to an error (to be handled better in Subtask 5)."
        },
        {
          "id": 2,
          "title": "Implement Dependent Type Parameter Inference (Π/Σ-types, Implicit Arguments)",
          "description": "Extend the bidirectional engine to infer missing parameters for dependent Π-types and Σ-types. Implement handling of implicit arguments in dependent type constructors and functions, allowing users to omit them when they can be deduced from context.",
          "dependencies": [
            1
          ],
          "details": "For Π-type parameter inference (e.g., `f : Π (A : Type) (x : A) -> C` in `(f _ y)`), infer `A` from the type of `y` using unification or constraint-based type matching. For Σ-types, ensure dependent components can be inferred. For implicit arguments (marked in function/constructor definitions), attempt inference based on types of explicit arguments or the expected type of the overall expression. Example: for `Id x y` where `Id : Π {A:Type} (a:A) (b:A) -> Type`, infer `A` from type of `x` or `y`.",
          "status": "done",
          "testStrategy": "Test cases for functions and constructors (e.g., `Vec`, `Id` from Task 11) with dependent types where some type arguments are placeholders (`_`) or implicit and should be inferred. Verify inference for parameters in Π-binders and Σ-pair components."
        },
        {
          "id": 3,
          "title": "Implement Universe Level Inference",
          "description": "Develop mechanisms for inferring universe levels (e.g., `Type i`). This involves collecting constraints on universe levels during type checking (e.g., from `Type i : Type j` implying `i < j`, or `Π (A : Type i) -> B : Type j` implying `i <= j`) and solving these constraints to ensure consistency and assign concrete or minimal levels.",
          "dependencies": [
            1
          ],
          "details": "Represent universe levels with variables (e.g., `?u1`). During type checking of type formers (Π, Σ, Type literal, etc.), generate constraints like `?u1 < ?u2` or `?u1 = max(?u2, ?u3)`. Collect all constraints into a system. Implement a solver for these constraints (e.g., based on a directed graph for inequalities, or simple unification for equalities). Report errors for inconsistent universes. Inferred levels become part of the elaborated AST.",
          "status": "in-progress",
          "testStrategy": "Unit tests for expressions that generate universe constraints (e.g., `(Type i) : Type (i+1)`, `Π (A:Type i) (x:A) -> B x` where `B x : Type i`). Test scenarios with solvable constraints, minimally solvable constraints, and unsolvable (inconsistent) constraints, ensuring correct level assignment or error reporting."
        },
        {
          "id": 4,
          "title": "Proof Obligation Generation and AST Elaboration",
          "description": "Implement the generation of proof obligations for propositions (e.g., equality proofs for `Id A x y` from Task 11) when a proof is required but not explicitly provided. Concurrently, elaborate the partially typed Abstract Syntax Tree (AST) into a fully typed AST by filling in all inferred types, implicit arguments, resolved universe levels, and generated proof obligations.",
          "dependencies": [
            2,
            3
          ],
          "details": "Proof Obligation Generation: Identify contexts requiring a proof term (e.g., an argument to a function expecting `Id A x y`). If a placeholder `_` is used, generate a proof obligation object containing the goal proposition and current context. These obligations can be special nodes in the AST. AST Elaboration: Define the structure for the fully elaborated AST. As inference proceeds, construct this new AST, populating it with: 1. Explicit type annotations for all variables and sub-expressions. 2. Instantiated implicit arguments. 3. Solved universe levels for all type expressions. 4. Embedded proof obligations. This elaborated AST is the definitive output of the inference phase.",
          "status": "pending",
          "testStrategy": "Test with expressions that should generate proof obligations (e.g., using `subst` or `rewrite` with an omitted equality proof). Verify the content of generated obligations. Inspect the elaborated AST to confirm that all inferred information (types, implicits, universe levels) is correctly and explicitly represented."
        },
        {
          "id": 5,
          "title": "Integrate Engine, Implement Robust Error Reporting, and Test with Standard Library",
          "description": "Integrate the complete type inference and elaboration engine into the main type checking pipeline. Implement clear, informative, and actionable error messages for inference failures, ambiguities, or unsatisfiable constraints. Conduct thorough testing with existing language features (Tasks 4, 10, 11) and types/functions from the Standard Library (Task 17).",
          "dependencies": [
            4
          ],
          "details": "Integration: Ensure the inference engine is invoked correctly within the compiler/interpreter, and its output (elaborated AST, proof obligations) is consumed by subsequent stages. Error Reporting: Design error messages to be user-friendly. For type mismatches, show expected vs. actual types. For inference failure, pinpoint the problematic expression and suggest adding annotations. For universe errors, explain the inconsistency. For ambiguities, list potential candidates if possible. Testing: Create comprehensive end-to-end tests using examples from the standard library (e.g., `Vector` operations, `Nat` arithmetic, `Fin` properties) that rely on inference. Test interactions with dependent types, identity types, and simple types. Specifically test error reporting for common mistakes.",
          "status": "pending",
          "testStrategy": "End-to-end tests using a suite of HoTT programs exercising all aspects of inference. Include programs that are correct and should type check with inference, and programs that are intentionally incorrect to verify the quality of error messages. Test against all relevant definitions in the Standard Library (Task 17) to ensure compatibility and utility."
        }
      ]
    },
    {
      "id": 24,
      "title": "Implement Practical Syntactic Sugar and Desugaring",
      "description": "Implement syntactic sugar for common programming patterns such as list literals, optional chaining (maybe-monad syntax like `x?.field`), and threading macros. These constructs will desugar into core HoTT-based language expressions, enhancing developer experience and code readability while preserving mathematical rigor.",
      "details": "Implementations should extend the parser (from Task 1) to recognize new syntactic forms and then transform these forms into equivalent core Abstract Syntax Tree (AST) structures (from Task 2) before type checking (Task 4) and evaluation (Task 2).\n\n**1. List Literals:**\n   - Syntax: `[elem1 elem2 ... elemN]` (e.g., `[1 2 3]`, `[]`).\n   - Parser Extension: Lexer to recognize `[` and `]`. Parser to construct an internal representation for list literals.\n   - Desugaring: Transform into a sequence of `List.cons` calls and `List.nil` from the standard library (Task 17). \n     - Example: `[1 2 3]` desugars to `(List.cons 1 (List.cons 2 (List.cons 3 List.nil)))`.\n     - Example: `[]` desugars to `List.nil`.\n\n**2. Maybe-Monad Syntax (Optional Chaining for `Option` types):**\n   - Syntax: `expr?.field` for field access, and `expr?.(function-call arg ...)` for safe method/function calls on an optional value.\n   - Prerequisites: `Option` type and its operations (`Option.map`, `Option.bind`, `Option.pure`, `None`) from Task 17. Product types (structs/records) from Task 5 for field access, and a mechanism like `(get-field instance 'fieldName')`.\n   - Desugaring for field access (`expr?.field`):\n     - Transforms to an expression that checks if `expr` is `Some`. If so, accesses `field` from the wrapped value and returns `(Some fieldValue)`; otherwise, returns `None`.\n     - Example: `myOption?.data` could desugar to `(Option.map myOption (lambda (value) (get-field value 'data')))`. The result type would be `(Option FieldType)`.\n   - Desugaring for function call (`expr?.(f arg)`):\n     - Transforms to an expression that checks if `expr` is `Some`. If so, applies the function to the wrapped value and arguments; otherwise, returns `None`.\n     - Example: `optVal?.(processItem \"arg2\")` could desugar to `(Option.bind optVal (lambda (v) (processItem v \"arg2\")))` if `processItem` returns an `Option`, or `(Option.map optVal (lambda (v) (processItem v \"arg2\")))` if `processItem` returns a plain value to be wrapped in `Some`.\n\n**3. Threading Macro (e.g., Thread-First `->`):**\n   - Syntax: `(-> initial-expr form1 form2 ...)`\n   - Purpose: Reduces nesting for sequential function applications.\n   - Desugaring: The `initial-expr` is passed as the first argument to `form1`. The result of that is passed as the first argument to `form2`, and so on.\n     - If a `form` is a symbol `s`, it becomes `(s threaded-value)`.\n     - If a `form` is a list `(op arg1 ...)` it becomes `(op threaded-value arg1 ...)`.\n   - Example: `(-> \"hello\" (string-append \" world\") string-upcase)` desugars to `(string-upcase (string-append \"hello\" \" world\"))` (assuming `string-append` and `string-upcase` are available, potentially from an extended standard library).\n   - Parser Extension: Recognize `->` as a special form/macro triggering this transformation.\n\n**General Considerations:**\n- All desugared expressions must be valid core language ASTs.\n- The desugaring process should happen after parsing and before type checking.\n- Error reporting for malformed sugar syntax should be clear.",
      "testStrategy": "Each syntactic sugar feature requires thorough testing:\n\n**1. List Literals:**\n   - Parse and desugar `[]`. Verify it becomes `List.nil`. Check type and evaluation.\n   - Parse and desugar `[1 2 3]`. Verify desugaring to `(List.cons 1 (List.cons 2 (List.cons 3 List.nil)))`. Check type `(List Nat)` and evaluate to the correct list structure.\n   - Test with lists of other types (e.g., `Bool`, `String` if available) and empty lists of specific types if supported.\n   - Test nested list literals: `[[1] [2 3]]`.\n   - Test parsing errors for malformed list literals, e.g., `[1 2`. \n\n**2. Maybe-Monad Syntax (`?.`):**\n   - Setup: Define a product type (e.g., `(deftype User ((id Nat) (name String)))`) and an `Option User` variable.\n   - Field Access:\n     - Test `optionUser?.id` when `optionUser` is `(Some (User 1 \"Alice\"))`. Expected: `(Some 1)`.\n     - Test `optionUser?.id` when `optionUser` is `None`. Expected: `None`.\n     - Verify type of the result is `(Option Nat)`.\n   - Function Call:\n     - Define a function `(define (format-user u) (string-append \"ID: \" (nat-to-string (get-field u 'id))))` which returns a `String`.\n     - Test `optionUser?.(format-user)` (if `format-user` is adapted or `Option.map` is used for non-Option returning functions). Expected: `(Some \"ID: 1\")` or `None`.\n     - Test with functions that themselves return `Option` using `Option.bind` desugaring.\n     - Verify type correctness of desugared expressions.\n   - Test parsing errors for malformed `?.` syntax.\n\n**3. Threading Macro (`->`):**\n   - Test simple case: `(-> 10 (add 5) (multiply 2))` (assuming `add` and `multiply` exist and take first arg as input). Expected desugaring: `(multiply (add 10 5) 2)`. Evaluate to `30`.\n   - Test with symbol forms: `(-> \"data\" process-step1 process-step2)` where `process-step1` and `process-step2` are functions. Expected: `(process-step2 (process-step1 \"data\"))`.\n   - Test with more complex forms and multiple arguments in steps: `(-> initial-value (funcA \"param1\") (funcB \"param2\" \"param3\"))`.\n   - Verify type checking of the desugared forms.\n   - Test parsing errors for malformed `->` expressions.\n\n**General Tests:**\n- Ensure that the introduction of syntactic sugar does not break existing parsing or evaluation of core language forms.\n- Verify that error messages from the type checker (Task 4) for type errors within desugared code are clear and map back to the original sugared syntax if possible (stretch goal).",
      "status": "cancelled",
      "dependencies": [
        1,
        2,
        17
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Extend Parser to Recognize New Syntactic Sugar Forms",
          "description": "Modify the lexer and parser to recognize the syntax for list literals (`[...]`), optional chaining (`?.`), and the thread-first macro (`->`). The parser should generate specific, temporary AST nodes for these constructs that will be processed by a subsequent desugaring pass.",
          "dependencies": [],
          "details": "Lexer: Add new tokens for `LBRACKET` (`[`), `RBRACKET` (`]`), and `OPT_CHAIN` (`?.`).\nParser: Implement rules to parse `[expr1 expr2 ...]` into an `AST.ListLiteral` node. Modify expression parsing to handle `expr?.field` and `expr?.(call...)`, creating `AST.OptionalAccess` and `AST.OptionalCall` nodes. Recognize `(-> ...)` as a special form and parse it into an `AST.ThreadMacro` node.",
          "status": "pending",
          "testStrategy": "Write unit tests for the parser that verify correct AST node generation for each new syntactic form, including valid cases, nested forms, and syntax errors for malformed sugar."
        },
        {
          "id": 2,
          "title": "Implement Desugaring of List Literals",
          "description": "Create the initial desugaring transformation pass that walks the AST and replaces `AST.ListLiteral` nodes with their equivalent core language expressions built from `List.cons` and `List.nil`.",
          "dependencies": [],
          "details": "Implement a function `desugar(ast)` that traverses the AST. When an `AST.ListLiteral` node is encountered, transform it. The transformation for `[e1 e2 ... en]` is a right-fold, resulting in `(List.cons e1 (List.cons e2 ... (List.cons en List.nil)))`. An empty list `[]` transforms directly to the `List.nil` identifier. The elements `e1`, `e2`, etc., must also be recursively desugared.",
          "status": "pending",
          "testStrategy": "Test the desugaring pass with various list literals: empty, single-element, multi-element, and nested lists. Verify that the output AST is a valid core language expression and matches the expected `List.cons`/`List.nil` structure."
        },
        {
          "id": 3,
          "title": "Implement Desugaring for Optional Field Access (`expr?.field`)",
          "description": "Extend the desugaring pass to handle `AST.OptionalAccess` nodes. This syntax provides safe access to fields of a value wrapped in an `Option` type by transforming it into an `Option.map` call.",
          "dependencies": [],
          "details": "In the `desugar` function, add a case for `AST.OptionalAccess(expr, 'field')`. The node should be transformed into the AST representation of `(Option.map (desugar expr) (lambda (v) (get-field v 'field')))`. This relies on `Option.map` from the standard library (Task 17) and a core `get-field` primitive (Task 5).",
          "status": "pending",
          "testStrategy": "Write tests that desugar expressions like `myOption?.data` and verify the resulting AST corresponds to the correct `Option.map` structure. Test with nested optional access, e.g., `opt1?.field1?.field2`."
        },
        {
          "id": 4,
          "title": "Implement Desugaring for Optional Function Calls (`expr?.(call)`)",
          "description": "Extend the desugaring pass to handle `AST.OptionalCall` nodes. This syntax provides a way to safely call a function with a value wrapped in an `Option` type, transforming into an `Option.bind` call.",
          "dependencies": [],
          "details": "In the `desugar` function, add a case for `AST.OptionalCall(expr, func, args)`. The node should be transformed into the AST for `(Option.bind (desugar expr) (lambda (v) (func v ...args)))`. The unwrapped value `v` is inserted as the first argument to the function call inside the lambda. This uses `Option.bind` to handle cases where the called function itself returns an `Option`.",
          "status": "pending",
          "testStrategy": "Test desugaring of expressions like `optUser?.(getProfile)`. Verify the output AST uses `Option.bind` and correctly constructs the lambda and inner function call. Test with functions that take multiple arguments."
        },
        {
          "id": 5,
          "title": "Implement Desugaring for the Thread-First Macro (`->`)",
          "description": "Finalize the desugaring pass by implementing the transformation for `AST.ThreadMacro` nodes. This macro simplifies the syntax of chained function calls by threading a value as the first argument to subsequent forms.",
          "dependencies": [],
          "details": "In the `desugar` function, add a case for `AST.ThreadMacro(initialExpr, forms)`. Implement a left-fold over the `forms`. The accumulator starts as `desugar(initialExpr)`. For each `form`, if it's a symbol `s`, the new accumulator is `(s accumulator)`; if it's a list `(op arg1 ...)` the new accumulator is `(op accumulator arg1 ...)`.",
          "status": "pending",
          "testStrategy": "Test the macro with various inputs: simple chains, chains with functions that take multiple arguments, and chains where the initial value is a complex expression. Verify the final nested AST is correct, e.g., `(-> x f g)` becomes `(g (f x))`."
        }
      ]
    },
    {
      "id": 25,
      "title": "Implement Computational Reflection for Decidable Propositions",
      "description": "Develop a mechanism to automatically solve decidable propositions (e.g., equality, ordering) by computation and reflect the computational evidence into formal proof terms. This leverages HoTT's principle of computation as proof for decidable predicates.",
      "details": "This task involves creating a system where the truth of certain propositions can be determined by direct computation, and this computational result can be automatically translated into a formal proof term recognized by the type system.\n\n1.  **Identify Target Decidable Propositions:**\n    *   Initially focus on equality for primitive types from the Standard Library (Task 17), such as `Nat` and `Bool`. Example: `(Id Nat x y)`. \n    *   Consider simple ordering relations on `Nat` (e.g., less than, greater than or equal to) if `Nat` operations support them.\n\n2.  **Implement Computational Decision Procedures:**\n    *   For each target decidable proposition, implement a corresponding computational function (decision procedure). For example:\n        *   `nat_eq_dec : Nat -> Nat -> Bool` (determines if two `Nat`s are equal).\n        *   `bool_eq_dec : Bool -> Bool -> Bool`.\n        *   These functions must reliably compute the truth value of the proposition.\n    *   These decision procedures should operate on evaluated/canonical forms of their arguments.\n\n3.  **Develop the Reflection Tactic/Macro (e.g., `compute_and_reflect`):\n    *   This tactic will take a proposition (a type, e.g., `(Id Nat n m)`) as input.\n    *   **Recognition:** It must identify if the input proposition corresponds to a known decidable predicate for which a computational solver exists.\n    *   **Invocation:** If recognized, it invokes the appropriate decision procedure with the arguments extracted from the proposition (after evaluation/normalization).\n    *   **Proof Construction:** Based on the computational result (typically a boolean):\n        *   If the proposition is computationally true (e.g., `nat_eq_dec x y` returns `true`), the tactic constructs a proof term for that proposition. For `(Id A x x)`, this would be `(refl evaluated_x)` (relies on Task 11).\n        *   If the proposition is computationally false, the tactic should construct a proof of its negation (e.g., a term of type `(Not (Id A x y))`). This might involve a type like `(Dec P)` defined as `(Sigma (b : Bool) (if b then P else (Not P)))`, where the tactic provides the full proof.\n\n4.  **Proof Term Generation Details:**\n    *   **Equality:** For a proposition `(Id T term1 term2)`, evaluate `term1` and `term2` to `val1` and `val2`. If `val1` and `val2` are computationally equal (and `T` has decidable equality), and `val1` is syntactically identical to `val2` after normalization, generate `(refl val1)`. The system must ensure that computational equality implies definitional equality for these cases.\n    *   **Other Predicates:** For a predicate `(P x y)`, if `P_dec x y` returns `true`, generate a term `proof_P_true x y : (P x y)`. If `false`, generate `proof_P_false x y : (Not (P x y))`. The structure of these proof terms will depend on how `P` and `Not P` are defined.\n\n5.  **Integration and Trust:**\n    *   The generated proof terms must be type-checked and accepted by the system (leveraging Task 4 and Task 10).\n    *   The computational decision procedures are effectively part of the trusted computing base for this reflection mechanism. Their correctness is crucial.\n    *   Consider a registry or dispatch mechanism for the `compute_and_reflect` tactic to find the appropriate solver for a given proposition form.\n\n6.  **Error Handling:**\n    *   The tactic should report errors if the proposition is not recognized as decidable or if arguments are malformed.",
      "testStrategy": "1.  **Unit Test Decision Procedures:**\n    *   For `nat_eq_dec`: Test with equal numbers `(nat_eq_dec 5 5)`, unequal numbers `(nat_eq_dec 5 6)`, and expressions `(nat_eq_dec (+ 2 3) 5)`.\n    *   Similarly, test `bool_eq_dec` and any other decision procedures (e.g., for ordering).\n\n2.  **Test Reflection Tactic for Equality (`Id` type):\n    *   Verify that `(compute_and_reflect (Id Nat 3 3))` successfully generates a term of type `(Id Nat 3 3)` (e.g., `(refl 3)`).\n    *   Verify for expressions: `(compute_and_reflect (Id Nat (+ 1 2) 3))`. \n    *   Verify for `Bool`: `(compute_and_reflect (Id Bool #t #t))`. \n    *   Test cases where equality is false: `(compute_and_reflect (Id Nat 3 4))`. The tactic should produce a proof of `(Not (Id Nat 3 4))`.\n\n3.  **Test Reflection Tactic for Other Decidable Propositions (if implemented, e.g., ordering):\n    *   Assume a proposition `(NatLe n m)` (n <= m) and a solver `nat_le_dec`.\n    *   `(compute_and_reflect (NatLe 3 5))` should produce a proof of `(NatLe 3 5)`.\n    *   `(compute_and_reflect (NatLe 5 3))` should produce a proof of `(Not (NatLe 5 3))`.\n\n4.  **Integration with Type Checker:**\n    *   Define terms or functions whose types are proven using the reflection tactic, e.g.:\n      `(define proof_equal_3_3 : (Id Nat 3 3) (compute_and_reflect (Id Nat 3 3)))`\n    *   Ensure these definitions type-check correctly.\n\n5.  **Error Handling Tests:**\n    *   Call `compute_and_reflect` with a proposition for which no decision procedure is defined; expect a clear error.\n    *   Call with malformed propositions or arguments; expect appropriate errors.\n\n6.  **HoTT Compliance Check:**\n    *   Ensure that for `(Id A x y)`, if `x` and `y` compute to the same value `v`, the proof generated is definitionally equal to `(refl v)`.",
      "status": "pending",
      "dependencies": [
        10,
        11,
        17
      ],
      "priority": "medium",
      "subtasks": [
        {
          "id": 1,
          "title": "Define the `Decidable` Type and Conditional Type Construct",
          "description": "Implement the foundational `(Dec P)` type, representing a decidable proposition `P`. This type encapsulates a boolean result and a proof that this boolean correctly reflects the truth of `P`. This requires implementing a type-level `if-then-else` construct.",
          "dependencies": [],
          "details": "Define `(Dec P)` as the sigma type `(Sigma (b : Bool) (if b then P else (Not P)))`. The `(Not P)` type should be defined as `(-> P Empty)`, where `Empty` is the uninhabited type. The core of this task is to enhance the type checker (from Task 10) to handle the `if C then T else F` construct for types. When the condition `C` evaluates to a boolean literal (`true` or `false`), the entire expression must reduce to `T` or `F` respectively during type checking.",
          "status": "pending",
          "testStrategy": "Add unit tests to the type checker to verify that `if true then TypeA else TypeB` correctly reduces to `TypeA`, and `if false then TypeA else TypeB` reduces to `TypeB`. Manually construct a term of type `(Dec P)` for a simple proposition `P` and ensure it type-checks correctly against the new definitions."
        },
        {
          "id": 2,
          "title": "Implement Decision Procedures for `Nat` and `Bool` Equality",
          "description": "Create the computational functions that decide equality for `Nat` and `Bool` types. These functions will not just return a boolean, but a full proof of decidability, i.e., a term of type `(Dec (Id T x y))`, using the structure defined in the previous subtask.",
          "dependencies": [],
          "details": "Implement two primitive functions within the evaluator: 1. `nat_eq_dec : (x : Nat) -> (y : Nat) -> (Dec (Id Nat x y))`. This function compares `x` and `y`. If they are equal, it returns `(pair true (refl x))`. If not, it returns `(pair false proof_of_negation)`, where `proof_of_negation` is a term of type `(-> (Id Nat x y) Empty)`. 2. `bool_eq_dec : (x : Bool) -> (y : Bool) -> (Dec (Id Bool x y))`. This can be implemented by simple case analysis on the inputs. These functions must operate on evaluated/canonical values.",
          "status": "pending",
          "testStrategy": "Write unit tests that directly invoke these new decision procedures with various inputs (e.g., `nat_eq_dec 5 5`, `nat_eq_dec 5 6`). Verify that the boolean component of the returned pair is correct and that the proof component successfully type-checks as either `(Id T x y)` or `(Not (Id T x y))`."
        },
        {
          "id": 3,
          "title": "Create the `compute_and_reflect` Tactic Scaffolding and Dispatch Registry",
          "description": "Implement the basic structure of the user-facing `compute_and_reflect` tactic. This involves parsing the current proof goal and creating a registry to map recognizable proposition forms to their corresponding decision procedures.",
          "dependencies": [],
          "details": "Create a new tactic named `compute_and_reflect`. The tactic must inspect the current goal's type, parsing its head symbol (e.g., `Id`) and argument types (e.g., `Nat`). Implement a registry, such as a hash map, within the tactic's environment. This registry will map a key representing the proposition form (e.g., a tuple `('Id', 'Nat')`) to a reference to its decision procedure function (e.g., `nat_eq_dec`). Populate this registry with the handlers for `Nat` and `Bool` equality. The tactic should fail with a clear error if the goal's form is not found in the registry.",
          "status": "pending",
          "testStrategy": "Set up proof states with various goals like `(Id Nat 3 3)`, `(Id Bool true false)`, and an unsupported one like `(Id String \"a\" \"b\")`. Run the `compute_and_reflect` tactic. Verify that it correctly identifies a handler for the `Nat` and `Bool` goals (without solving them yet) and fails gracefully for the `String` goal, reporting that no decision procedure is available."
        },
        {
          "id": 4,
          "title": "Implement Tactic Logic to Evaluate Arguments and Invoke Decision Procedure",
          "description": "Enhance the `compute_and_reflect` tactic to normalize the arguments of the proposition and then invoke the appropriate decision procedure with these computed values.",
          "dependencies": [],
          "details": "After the tactic identifies the goal (e.g., `(Id Nat (+ 1 1) 2)`) and finds its decision procedure (`nat_eq_dec`), it must use the evaluator (from Task 10) to normalize the arguments of the proposition (e.g., `(+ 1 1)` becomes `2`, and `2` remains `2`). The tactic will then construct and evaluate a call to the decision procedure with the normalized arguments, e.g., `(nat_eq_dec 2 2)`. The result of this evaluation, which is a term of type `(Dec ...)` like `(pair true (refl 2))`, must be captured by the tactic for the final step.",
          "status": "pending",
          "testStrategy": "Use logging or a debugger to trace the tactic's execution. For a goal like `(Id Nat (* 2 3) 6)`, verify that the tactic correctly normalizes `(* 2 3)` to `6`, invokes `nat_eq_dec` with `6` and `6`, and correctly captures the resulting `(Dec ...)` term from the evaluator."
        },
        {
          "id": 5,
          "title": "Generate and Apply Final Proof Term from Computation Result",
          "description": "Finalize the `compute_and_reflect` tactic by using the result from the decision procedure to solve the original proof goal. This completes the reflection of computational evidence into a formal proof.",
          "dependencies": [],
          "details": "The tactic will inspect the `(Dec P)` term (e.g., `(pair b proof_term)`) captured in the previous step. If the boolean `b` is `true`, the tactic extracts the `proof_term` and uses it to solve the original goal, causing the tactic to succeed. If `b` is `false`, the proposition is false, and the tactic must fail with an informative error message stating that the goal is computationally false. The application of the extracted proof term must be checked by the kernel (Task 4), ensuring the entire process remains sound.",
          "status": "pending",
          "testStrategy": "Write end-to-end integration tests. A proof script with `prove (Id Nat (+ 2 3) 5) with compute_and_reflect.` should succeed and close the goal. A script with `prove (Id Nat 4 5) with compute_and_reflect.` should fail with a clear error message. Test with nested computations like `prove (Id Bool (nat_eq_dec 3 3).1 true) with compute_and_reflect.`."
        }
      ]
    },
    {
      "id": 26,
      "title": "Evaluate Rust backend migration for production PathFinder implementation",
      "description": "After completing dependent types, consider migrating from Racket to Rust host for: 1) Native performance 2) Multiple backends (interpreter, Cranelift JIT, LLVM AOT, WASM) 3) Better deployment (single binary) 4) Integration with compiler ecosystem. Goal: PathFinder IL → Rust implementation with same three-tier effect system. Could potentially dogfood by implementing the Rust backend in PathFinder itself.",
      "details": "",
      "testStrategy": "",
      "status": "pending",
      "dependencies": [],
      "priority": "medium",
      "subtasks": [
        {
          "id": 1,
          "title": "Define Core PathFinder IL Data Structures in Rust",
          "description": "Create the foundational Rust structs and enums to accurately represent the PathFinder Intermediate Language (IL). This includes defining types for expressions, statements, function definitions, and the components of the effect system. This is a prerequisite for any processing or execution of PathFinder code in Rust.",
          "dependencies": [],
          "details": "In a new Rust library crate, define modules for the IL's Abstract Syntax Tree (AST). Use Rust's enum and struct features to model the language constructs. For example, `enum Expression { Literal(Value), Var(String), ... }`. Derive `Debug`, `Clone`, and potentially `serde::Serialize` for easier testing and debugging.",
          "status": "pending",
          "testStrategy": "Write unit tests for each data structure to ensure they can be constructed correctly. Implement a simple round-trip serialization/deserialization test (e.g., to JSON) to verify the structure's integrity and completeness against a known-good IL example."
        },
        {
          "id": 2,
          "title": "Implement the Three-Tier Effect System Machinery",
          "description": "Develop the core runtime logic for PathFinder's three-tier effect system. This involves creating the mechanisms for defining effects, handling them, and managing continuations. This module will be a self-contained library component used by all execution backends.",
          "dependencies": [],
          "details": "Create data structures for effect handlers and the effect context stack. Implement the core function for invoking an effect, which should search the context stack for a matching handler. Implement the logic for capturing, saving, and resuming continuations (resumptions). This logic should be generic and not tied to a specific backend (interpreter vs. JIT) at this stage.",
          "status": "pending",
          "testStrategy": "Create a suite of unit tests that exercise the effect system in isolation. Test scenarios should include: invoking an unhandled effect, handling a simple effect, handling nested effects, and resuming a continuation with a value."
        },
        {
          "id": 3,
          "title": "Build a Tree-Walk Interpreter Backend",
          "description": "Implement an interpreter that directly executes the PathFinder IL AST. This serves as a reference implementation to validate the correctness of the IL data structures and the effect system logic in an end-to-end execution flow.",
          "dependencies": [],
          "details": "Create an `Interpreter` struct with an `eval` method that recursively walks the IL AST. Maintain an environment for variable bindings. When an effectful operation is encountered in the AST, the interpreter should call into the effect system machinery developed in the previous subtask. The result of an `eval` call should be a final value or an unhandled effect.",
          "status": "pending",
          "testStrategy": "Port a representative set of test cases from the original Racket implementation. For each test case, construct the corresponding IL AST in Rust and execute it with the interpreter. Assert that the final output or unhandled effect matches the expected result from the Racket version."
        },
        {
          "id": 4,
          "title": "Implement a JIT Backend using Cranelift",
          "description": "Develop a Just-In-Time (JIT) compilation backend using the Cranelift code generation library. This backend will translate PathFinder IL into native machine code at runtime to achieve significant performance improvements over the interpreter.",
          "dependencies": [],
          "details": "Create a `JitCompiler` module that traverses the PathFinder IL AST and emits Cranelift IR. Use `cranelift-jit` to manage memory and compile the IR into executable code. Implement 'trampolines' or foreign function calls from the JIT-ed code back into the Rust runtime to handle the effect system logic (e.g., calling the effect handler search function). Map PathFinder functions to JIT-ed functions and manage their pointers.",
          "status": "pending",
          "testStrategy": "Re-use the test suite from the interpreter subtask. For each test case, the JIT-compiled code should produce the exact same result as the interpreter. Add performance benchmarks comparing the execution time of key algorithms (e.g., recursive functions, tight loops) between the interpreter and the JIT backend."
        },
        {
          "id": 5,
          "title": "Develop a Unified CLI and Single-Binary Build Process",
          "description": "Create a user-facing command-line interface (CLI) to drive the PathFinder execution engine. The CLI should allow users to specify an input file and select the desired backend (interpreter or JIT). The entire project should be configurable to build into a single, distributable binary.",
          "dependencies": [],
          "details": "Create a new binary crate that depends on the library crate containing the IL and backends. Use a crate like `clap` to define and parse command-line arguments, such as `--backend [interpreter|jit]` and the input file path. Implement logic to read a file, parse it into the IL AST representation (initially, this can be a placeholder parser that reads a debug format like JSON), and dispatch to the selected backend. Configure `Cargo.toml` to build a release binary.",
          "status": "pending",
          "testStrategy": "Write end-to-end integration tests using a testing framework like `assert_cmd`. These tests will execute the compiled binary with different command-line flags and input files, capturing stdout/stderr and asserting that the output matches the expected results for both the interpreter and JIT backends."
        }
      ]
    },
    {
      "id": 27,
      "title": "Implement Tier 0 Distributed Proof Cache",
      "description": "Implement a distributed, content-addressable proof cache that acts as a 'Tier 0' in the architecture. This system will transparently resolve proof obligations by searching a network of pre-computed proofs before falling back to local computation, effectively creating a global mathematical commons.",
      "details": "This task establishes a new architectural tier, \"Tier 0\", for distributed, pre-computed proofs, making the network an invisible acceleration layer.\n\n**1. Content-Addressable Proof Obligation Hashing:**\n   - Develop a canonical serialization format for proof obligations generated by the constraint system (Task 18).\n   - The serialization must be stable and independent of variable names (e.g., using de Bruijn indices) to ensure that logically equivalent obligations produce identical hashes.\n   - This hash will serve as the unique key for retrieving proofs from any cache (local or distributed).\n\n**2. Transparent Proof Resolution Pipeline:**\n   - Integrate a new resolution pipeline into the core proof search mechanism (Task 20).\n   - When a proof is required, the system will attempt to resolve it in the following order:\n     1. Query the distributed cache over the network.\n     2. Query the local, on-disk cache.\n     3. Attempt to solve using Tier 1 compile-time mechanisms (e.g., computational reflection from Task 25).\n     4. Defer to Tier 2 runtime checks if applicable.\n     5. Fall back to network coordination for complex proofs if all else fails.\n\n**3. Distributed Cache and Network Protocol:**\n   - Implement a peer-to-peer mechanism for nodes to discover and share proofs.\n   - Define a simple network protocol for querying peers for a proof by its obligation hash.\n   - When a peer generates a new, expensive proof, it should be added to its local cache and made available to the network.\n\n**4. Automatic Verification and Caching:**\n   - Any proof retrieved from any source (local or distributed) must be formally verified against the original proof obligation before being used.\n   - Once a proof is successfully generated locally or verified from a remote source, it should be automatically stored in a local on-disk cache to accelerate future requests.",
      "testStrategy": "**1. Hashing Stability Test:**\n   - Create multiple test cases where proof obligations are structurally identical but use different variable names or syntactic forms.\n   - Verify that the canonical hashing mechanism produces the exact same hash for all equivalent obligations.\n\n**2. Resolution Pipeline Test:**\n   - Define a computationally expensive but decidable proposition (e.g., using functions from Task 25).\n   - First compilation: Verify that the proof is generated using local computation (e.g., reflection) and measure the time taken.\n   - Clear the in-memory cache and re-compile: Verify the proof is now loaded from the local on-disk cache, resulting in a significantly faster time.\n\n**3. Distributed Cache Test:**\n   - Set up two running instances of the system (Peer A and Peer B) on a local network.\n   - On Peer A, compile code that generates and caches an expensive proof.\n   - On Peer B, compile code that requires the identical proof.\n   - Monitor network traffic and logs to confirm that Peer B successfully queries and retrieves the proof from Peer A without performing the expensive computation itself.\n\n**4. Proof Verification Test:**\n   - Manually inject a malformed or incorrect proof term into the cache of Peer A for a valid proof obligation hash.\n   - Have Peer B request this proof.\n   - Verify that Peer B rejects the invalid proof upon receipt because it fails the verification step, and then proceeds to the next stage of the resolution pipeline (local computation).",
      "status": "pending",
      "dependencies": [
        18,
        20,
        25
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Canonical Serialization and Hashing for Proof Obligations",
          "description": "Develop a stable, canonical serialization format for proof obligations from the constraint system. This serialization must be independent of incidental details like variable names to ensure logically equivalent obligations produce identical hashes. This hash will be the content-addressable key for the cache.",
          "dependencies": [],
          "details": "Use a technique like de Bruijn indexing to abstract away variable names during serialization. The serialization format should be a well-defined, compact byte stream (e.g., using a library like MessagePack or a custom binary format). The final output should be a cryptographic hash (e.g., SHA-256) of this byte stream. This function will be a prerequisite for all caching operations.",
          "status": "pending",
          "testStrategy": "Create multiple logically equivalent but syntactically different proof obligations. Assert that they all produce the same hash. Create two logically distinct obligations and assert they produce different hashes."
        },
        {
          "id": 2,
          "title": "Create a Local On-Disk Proof Cache",
          "description": "Implement a local, persistent cache on the file system to store and retrieve computed proofs. The cache will use the proof obligation hash as the key, enabling fast local lookups.",
          "dependencies": [],
          "details": "The cache should be stored in a standard user cache directory (e.g., `~/.cache/my_system/proofs/`). Proofs should be stored in files named after their obligation hash (e.g., `<hash>.proof`). Implement functions for `put(hash, proof_data)` and `get(hash) -> Option<proof_data>`. Handle file I/O, including creating the directory structure if it doesn't exist.",
          "status": "pending",
          "testStrategy": "Test the `put` and `get` functions. Verify that a proof can be stored with a given hash (from subtask #28) and then retrieved using the same hash. Test edge cases like a cache miss (requesting a hash that doesn't exist) and file system errors."
        },
        {
          "id": 3,
          "title": "Integrate Local Cache Lookup into the Proof Resolution Pipeline",
          "description": "Modify the core proof search mechanism to query the local on-disk cache before attempting to generate a proof. If a proof is generated locally, it should be stored in the cache for future use.",
          "dependencies": [],
          "details": "In the proof search function (from Task 20), first, generate the hash of the proof obligation using the function from subtask #28. Second, attempt to retrieve the proof from the local cache using the `get` function from subtask #29. If a proof is found (cache hit), return it. If not (cache miss), proceed with the existing proof generation logic. Upon successful generation of a new proof, use the `put` function from subtask #29 to store it in the local cache.",
          "status": "pending",
          "testStrategy": "Run a proof obligation twice. The first run should be a cache miss, triggering local computation and populating the cache. The second run for the *same* obligation should be a cache hit, resulting in a significantly faster resolution time. Use logging or metrics to confirm the cache hit."
        },
        {
          "id": 4,
          "title": "Define and Implement a Peer-to-Peer Proof Query Protocol",
          "description": "Design and implement a simple P2P network protocol for nodes to query each other for proofs by hash. This includes both the client-side logic to send a request and the server-side logic to listen for and respond to requests from its local cache.",
          "dependencies": [],
          "details": "Define two primary message types: `QUERY <hash>` and `PROOF <hash> <proof_data>`. A node should listen on a configured port for incoming `QUERY` messages. Upon receiving a query, it should check its local on-disk cache (from subtask #29) for the corresponding proof. If found, it responds with a `PROOF` message. The client logic will involve connecting to a list of known peers and sending a `QUERY` message.",
          "status": "pending",
          "testStrategy": "Set up two instances of the application. On instance A, populate its local cache with a proof. From instance B, send a `QUERY` message for that proof's hash to instance A. Verify that instance B receives the correct `PROOF` message from A. Test the case where A does not have the proof (no response or a `NOT_FOUND` response)."
        },
        {
          "id": 5,
          "title": "Integrate Distributed Lookup and Verification into the Resolution Pipeline",
          "description": "Enhance the proof resolution pipeline to query the network for a proof as the first step. Crucially, any proof received from the network must be formally verified against the obligation before being used or cached locally.",
          "dependencies": [],
          "details": "Modify the pipeline from subtask #30. The new resolution order will be: 1. Query network peers (using the client from subtask #31). 2. If a proof is received, verify it against the original obligation. If valid, use it and store it in the local cache. 3. If no proof is found on the network or the received proof is invalid, proceed with the existing logic (check local cache, then compute). The verification step is critical for security and correctness.",
          "status": "pending",
          "testStrategy": "Set up three nodes (A, B, C). Node A has a valid proof. Node C has an invalid proof for the same hash. Node B requests the proof. Test that B can receive, verify, and use the proof from A. Then, test that if B receives the proof from C, it fails verification, discards it, and falls back to other resolution methods."
        }
      ]
    },
    {
      "id": 28,
      "title": "Minimize Racket Dependencies by Replacing Host-Language Features",
      "description": "Replace Racket-specific features like contracts, pattern matching, and mutable data structures with their HoTT-native equivalents. This task is a major step towards making the language self-hosting and reducing reliance on the Racket ecosystem.",
      "details": "This task involves a systematic refactoring of the existing codebase to eliminate dependencies on Racket-specific functionalities, replacing them with features native to the HoTT-based language.\n\n1.  **Replace Racket Contracts with Dependent Types**: Identify all uses of Racket's contract system (`provide/contract`, `contract-out`). These runtime checks must be replaced with compile-time proofs. For function signatures, this involves using dependent function types (Π-types, from Task 10). For data structures, this means using `deftype` with `:where` clauses to define invariants that are enforced upon construction (from Task 8).\n\n2.  **Replace Racket Pattern Matching with Eliminators**: All instances of Racket's `match` syntax must be removed. For each sum type defined in the language, an eliminator (or \"induction principle\") function should be generated. The logic previously implemented with `match` will be refactored to use these eliminators, ensuring that data is deconstructed in a type-safe, principled manner that is native to the core language.\n\n3.  **Replace Mutable Data Structures with Persistent Ones**: Scan the codebase for any use of mutable data structures, such as those created with `vector`, `hash`, or modified with `set!`. These must be replaced with the language's own persistent data structures, such as the `List` and `NonEmptyList` types defined in Task 17. This change is critical for aligning the implementation with a purely functional, provable paradigm.",
      "testStrategy": "1.  **Static Analysis**: Before starting, run a static analysis tool across the codebase to find and catalog all occurrences of Racket-specific forms (`contract-out`, `match`, `set!`, mutable data structure constructors). The primary success metric is the reduction of this count to zero.\n2.  **Regression Testing**: Ensure the existing comprehensive test suite passes before and after the refactoring. This guarantees that the logical behavior of the system remains unchanged.\n3.  **Contract Replacement Tests**: For each contract that is removed, write a corresponding negative test that attempts to violate the invariant. This test should now fail at type-checking time, demonstrating the successful migration from a runtime check to a compile-time proof.\n4.  **Eliminator Tests**: Write specific unit tests for the generated eliminator functions for each sum type, verifying they correctly deconstruct values and apply the provided functions.\n5.  **Persistence Tests**: Write tests to confirm that the new persistent data structures are used correctly and that no side-effects or mutations are present in the refactored code sections.",
      "status": "in-progress",
      "dependencies": [
        8,
        10,
        17,
        21
      ],
      "priority": "high",
      "subtasks": [
        {
          "id": 1,
          "title": "Refactor Racket Contracts to Compile-Time Dependent Types",
          "description": "Systematically identify and replace all runtime Racket contracts (`provide/contract`, `contract-out`) with the language's native compile-time dependent types. This enforces invariants statically rather than at runtime, a key step in leveraging the HoTT-based type system.",
          "dependencies": [],
          "details": "Use static analysis or text search to locate all occurrences of Racket's contract forms. For function contracts, rewrite the signatures using dependent function types (Π-types). For data structure contracts, refactor the `deftype` definitions to include `:where` clauses that specify the required invariants, which will be checked at construction time. Remove the now-redundant Racket contract definitions.",
          "status": "in-progress",
          "testStrategy": "Ensure all existing tests pass. Add new tests that specifically attempt to violate the new type-level invariants; these should now fail at compile time instead of runtime, confirming the successful migration from runtime checks to static proofs."
        },
        {
          "id": 2,
          "title": "Implement Automatic Generation of Eliminators for Sum Types",
          "description": "Enhance the language's `deftype` macro to automatically generate a principled eliminator function (also known as an induction principle) for every sum type defined. This provides the foundational mechanism for replacing Racket's `match` with a native, type-safe construct.",
          "dependencies": [],
          "details": "Modify the macro or compiler pass that handles `deftype`. For any sum type `(deftype T :is (sum (C1 A1 ...) (C2 B1 ...) ...))`, the macro should generate a corresponding eliminator function. The eliminator's signature should be of the form `(T-elim : (-> T (-> (A1 ...) P) (-> (B1 ...) P) ... P))`, where `P` is a polymorphic return type. The generated function will take an instance of `T` and one function for each constructor, applying the correct function to the deconstructed value.",
          "status": "pending",
          "testStrategy": "For each core sum type in the language, write a unit test that verifies the generated eliminator exists and functions correctly. Test with both simple and polymorphic return types (`P`) to ensure correctness and generality."
        },
        {
          "id": 3,
          "title": "Replace Racket `match` Expressions with Generated Eliminators",
          "description": "With the eliminator generation in place, refactor the entire codebase to replace all instances of Racket's `match` syntax with calls to the corresponding native, type-safe eliminator functions generated in the previous subtask.",
          "dependencies": [
            2
          ],
          "details": "Search the codebase for all `(match ...)` expressions. For each `match` expression over a sum type `T`, replace it with a call to `(T-elim ...)`. The clauses of the `match` expression will be converted into lambda functions passed as arguments to the eliminator. Pay close attention to nested patterns and guards, which may require more complex lambda bodies or nested eliminator calls.",
          "status": "pending",
          "testStrategy": "The primary testing strategy is regression testing. The entire existing test suite must pass after this large-scale refactoring. Code review is critical to ensure the logic of the original `match` is preserved in the new eliminator-based implementation."
        },
        {
          "id": 4,
          "title": "Replace Mutable Racket Data Structures with Persistent Equivalents",
          "description": "Eradicate the use of mutable data structures from the Racket host language, such as vectors and hash tables, and replace them with the language's own purely functional, persistent data structures like `List` and `NonEmptyList`.",
          "dependencies": [],
          "details": "Identify all uses of mutable data structures and operations: `vector`, `vector-set!`, `hash`, `hash-set!`, `box`, `set-box!`, and the general `set!`. Replace uses of mutable vectors and lists with the language's native `List` or `NonEmptyList` types. Refactor algorithms that rely on mutation to use a functional style, such as using recursion and passing updated state as arguments instead of modifying it in place.",
          "status": "pending",
          "testStrategy": "All existing tests must pass. Performance testing may be necessary to identify any significant regressions introduced by the switch to persistent data structures, which can then be addressed with targeted optimizations if needed."
        }
      ]
    },
    {
      "id": 29,
      "title": "Implement Native Host Bridge for Primitive Operations",
      "description": "Design and implement a native host bridge using Rust, Zig, or C++ to replace Racket for primitive operations. This change targets a 10-100x performance increase by eliminating runtime contract overhead while maintaining strict HoTT semantics.",
      "details": "This task involves creating a Foreign Function Interface (FFI) to a native library (preferably Rust, in line with Task #26) to offload performance-critical primitive operations.\n\n1.  **FFI and Bridge Design:**\n    *   Define a stable FFI between the Racket-based runtime and the native library.\n    *   Specify the data marshalling process for converting language-level data (like numbers, strings, and simple data structures) into native representations and back.\n    *   The bridge should be designed to be lightweight, introducing minimal overhead.\n\n2.  **Native Implementation (Rust):**\n    *   Set up a Rust crate and integrate its compilation into the main project's build system (extending the work from Task #21).\n    *   Identify a core set of primitive operations currently handled by Racket to be ported first (e.g., integer arithmetic, floating-point math, string manipulations).\n    *   Re-implement these primitives in Rust. The native functions must be pure and their behavior must be identical to the Racket versions to preserve HoTT semantics.\n\n3.  **Runtime Integration:**\n    *   Modify the core evaluator (from Task #2) to reroute calls for these primitive operations through the FFI to the native library.\n    *   Initially, keep the existing Racket-based conversion and utility functions, focusing the native implementation purely on raw computational primitives to gain the most performance benefit.",
      "testStrategy": "1.  **Unit Testing:** Create a comprehensive suite of unit tests for the native Rust functions in isolation to verify their correctness.\n2.  **Integration Testing:** Develop specific tests for the FFI bridge itself. These tests will involve calling native functions from Racket and asserting that data is marshalled and returned correctly without corruption.\n3.  **Regression Testing:** Run the entire existing language test suite. The behavior and output must be identical to the pure Racket implementation, ensuring that this performance optimization does not introduce functional regressions.\n4.  **Benchmark Analysis:** Create a dedicated performance benchmark suite that measures the execution time of tight loops and computationally-intensive operations. Compare the performance of the new native implementation against the baseline Racket implementation to validate the 10-100x performance goal.",
      "status": "pending",
      "dependencies": [
        28,
        26,
        21,
        2
      ],
      "priority": "low",
      "subtasks": []
    }
  ]
}